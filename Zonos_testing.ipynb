{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c7578b-d52c-4684-bc53-378d85537c0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mzonos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_DEVICE \u001b[38;5;28;01mas\u001b[39;00m device\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-hybrid\", device=device)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mZonos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mZyphra/Zonos-v0.1-transformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m wav, sampling_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massets/exampleaudio.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m speaker \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmake_speaker_embedding(wav, sampling_rate)\n",
      "File \u001b[0;32m~/ttsmodels/zonos/model.py:63\u001b[0m, in \u001b[0;36mZonos.from_pretrained\u001b[0;34m(cls, repo_id, revision, device, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m config_path \u001b[38;5;241m=\u001b[39m hf_hub_download(repo_id\u001b[38;5;241m=\u001b[39mrepo_id, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m     62\u001b[0m model_path \u001b[38;5;241m=\u001b[39m hf_hub_download(repo_id\u001b[38;5;241m=\u001b[39mrepo_id, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ttsmodels/zonos/model.py:79\u001b[0m, in \u001b[0;36mZonos.from_local\u001b[0;34m(cls, config_path, model_path, device, backbone)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_transformer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m BACKBONES:\n\u001b[1;32m     77\u001b[0m         backbone_cls \u001b[38;5;241m=\u001b[39m BACKBONES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 79\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackbone_cls\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device, torch\u001b[38;5;241m.\u001b[39mbfloat16)\n\u001b[1;32m     80\u001b[0m model\u001b[38;5;241m.\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39mdac\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     82\u001b[0m sd \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "File \u001b[0;32m~/ttsmodels/zonos/model.py:31\u001b[0m, in \u001b[0;36mZonos.__init__\u001b[0;34m(self, config, backbone_cls)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasked_token_id \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmasked_token_id\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder \u001b[38;5;241m=\u001b[39m DACAutoencoder()\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone \u001b[38;5;241m=\u001b[39m \u001b[43mbackbone_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_conditioner \u001b[38;5;241m=\u001b[39m PrefixConditioner(config\u001b[38;5;241m.\u001b[39mprefix_conditioner, dim)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspk_clone_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ttsmodels/zonos/backbone/_torch.py:61\u001b[0m, in \u001b[0;36mTorchZonosBackbone.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModuleList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTransformerBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_layer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_f \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(config\u001b[38;5;241m.\u001b[39md_model, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnorm_epsilon)\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/container.py:300\u001b[0m, in \u001b[0;36mModuleList.__init__\u001b[0;34m(self, modules)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m modules\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/container.py:349\u001b[0m, in \u001b[0;36mModuleList.__iadd__\u001b[0;34m(self, modules)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iadd__\u001b[39m(\u001b[38;5;28mself\u001b[39m, modules: Iterable[Module]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/container.py:432\u001b[0m, in \u001b[0;36mModuleList.extend\u001b[0;34m(self, modules)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModuleList.extend should be called with an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterable, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m(modules)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    431\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 432\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules):\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_module(\u001b[38;5;28mstr\u001b[39m(offset \u001b[38;5;241m+\u001b[39m i), module)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/ttsmodels/zonos/backbone/_torch.py:61\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\u001b[43mTransformerBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mn_layer))\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_f \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(config\u001b[38;5;241m.\u001b[39md_model, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnorm_epsilon)\n",
      "File \u001b[0;32m~/ttsmodels/zonos/backbone/_torch.py:91\u001b[0m, in \u001b[0;36mTransformerBlock.__init__\u001b[0;34m(self, config, layer_idx)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixer \u001b[38;5;241m=\u001b[39m Attention(config, layer_idx)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(config\u001b[38;5;241m.\u001b[39md_model, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnorm_epsilon)\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m \u001b[43mFeedForward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads_kv \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mattn_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_heads_kv\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m config\u001b[38;5;241m.\u001b[39mattn_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/ttsmodels/zonos/backbone/_torch.py:147\u001b[0m, in \u001b[0;36mFeedForward.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: BackboneConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mlp_d_intermediate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mattn_mlp_d_intermediate, config\u001b[38;5;241m.\u001b[39md_model, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/linear.py:112\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/modules/linear.py:118\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/env/lib/python3.10/site-packages/torch/nn/init.py:518\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[1;32m    516\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from zonos.model import Zonos\n",
    "from zonos.conditioning import make_cond_dict\n",
    "from zonos.utils import DEFAULT_DEVICE as device\n",
    "\n",
    "# model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-hybrid\", device=device)\n",
    "model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=device)\n",
    "\n",
    "wav, sampling_rate = torchaudio.load(\"assets/exampleaudio.mp3\")\n",
    "speaker = model.make_speaker_embedding(wav, sampling_rate)\n",
    "\n",
    "cond_dict = make_cond_dict(text=\"Hello, world!\", speaker=speaker, language=\"en-us\")\n",
    "conditioning = model.prepare_conditioning(cond_dict)\n",
    "\n",
    "codes = model.generate(conditioning)\n",
    "\n",
    "wavs = model.autoencoder.decode(codes).cpu()\n",
    "torchaudio.save(\"sample.wav\", wavs[0], model.autoencoder.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab32cc2-46a6-4e57-a117-8b29447833ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Loading model...\n",
      "ðŸ”¹ Loading reference audio...\n",
      "ðŸ”¹ Creating speaker embedding...\n",
      "ðŸ”¹ Preparing conditioning inputs...\n",
      "ðŸ”¹ Generating codes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:   0%|                                                                      | 0/2588 [00:00<?, ?it/s]\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, s0: \"Sym(s0)\", s1: \"Sym(s0*s1)\", s1_0: \"Sym(s1)\", L_input_ids_: \"i64[1, s0, 1][s0*s1, s1, 1]cpu\", L_self_modules_embeddings_modules_0_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_embeddings_modules_1_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_embeddings_modules_2_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_embeddings_modules_3_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_embeddings_modules_4_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_embeddings_modules_5_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_embeddings_modules_6_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_embeddings_modules_7_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_embeddings_modules_8_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", s2: \"Sym(2)\", L_inference_params_lengths_per_sample: \"i32[2][1]cpu\", s3: \"Sym(s3)\", s4: \"Sym(64)\", L_self_modules_backbone_freqs_cis: \"f32[s3, 64, 2][128, 2, 1]cpu\", L_self_modules_backbone_modules_layers_modules_0_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_0_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_0_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", s5: \"Sym(s5)\", s6: \"Sym(s6)\", s7: \"Sym(128)\", L_inference_params_key_value_memory_dict_0_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_inference_params_batch_size_offset: \"Sym(0)\", L_inference_params_seqlen_offset: \"Sym(s9)\", L_self_modules_backbone_modules_layers_modules_0_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_0_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_0_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_0_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_0_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_1_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_1_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_1_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_1_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_1_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_1_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_1_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_1_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_1_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_2_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_2_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_2_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_2_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_2_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_2_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_2_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_2_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_2_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_3_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_3_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_3_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_3_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_3_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_3_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_3_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_3_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_3_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_4_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_4_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_4_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_4_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_4_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_4_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_4_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_4_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_4_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_5_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_5_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_5_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_5_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_5_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_5_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_5_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_5_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_5_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_6_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_6_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_6_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_6_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_6_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_6_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_6_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_6_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_6_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_7_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_7_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_7_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_7_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_7_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_7_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_7_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_7_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_7_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_8_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_8_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_8_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_8_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_8_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_8_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_8_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_8_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_8_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_9_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_9_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_9_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_9_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_9_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_9_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_9_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_9_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_9_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_10_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_10_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_10_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_10_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_10_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_10_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_10_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_10_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_10_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_11_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_11_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_11_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_11_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_11_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_11_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_11_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_11_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_11_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_12_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_12_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_12_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_12_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_12_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_12_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_12_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_12_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_12_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_13_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_13_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_13_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_13_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_13_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_13_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_13_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_13_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_13_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_14_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_14_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_14_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_14_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_14_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_14_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_14_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_14_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_14_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_15_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_15_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_15_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_15_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_15_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_15_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_15_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_15_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_15_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_16_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_16_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_16_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_16_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_16_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_16_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_16_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_16_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_16_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_17_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_17_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_17_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_17_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_17_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_17_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_17_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_17_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_17_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_18_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_18_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_18_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_18_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_18_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_18_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_18_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_18_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_18_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_19_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_19_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_19_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_19_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_19_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_19_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_19_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_19_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_19_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_20_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_20_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_20_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_20_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_20_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_20_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_20_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_20_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_20_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_21_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_21_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_21_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_21_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_21_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_21_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_21_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_21_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_21_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_22_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_22_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_22_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_22_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_22_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_22_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_22_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_22_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_22_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_23_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_23_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_23_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_23_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_23_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_23_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_23_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_23_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_23_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_24_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_24_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_24_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_24_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_24_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_24_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_24_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_24_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_24_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_layers_modules_25_modules_norm_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_25_modules_norm_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_25_modules_mixer_modules_in_proj_parameters_weight_: \"bf16[3072, 2048][2048, 1]cpu\", L_inference_params_key_value_memory_dict_25_0_: \"bf16[2, s5, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\", L_self_modules_backbone_modules_layers_modules_25_modules_mixer_modules_out_proj_parameters_weight_: \"bf16[2048, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_25_modules_norm2_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_25_modules_norm2_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_layers_modules_25_modules_mlp_modules_fc1_parameters_weight_: \"bf16[16384, 2048][2048, 1]cpu\", L_self_modules_backbone_modules_layers_modules_25_modules_mlp_modules_fc2_parameters_weight_: \"bf16[2048, 8192][8192, 1]cpu\", L_self_modules_backbone_modules_norm_f_parameters_weight_: \"bf16[2048][1]cpu\", L_self_modules_backbone_modules_norm_f_parameters_bias_: \"bf16[2048][1]cpu\", L_self_modules_heads_modules_0_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_heads_modules_1_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_heads_modules_2_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_heads_modules_3_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_heads_modules_4_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_heads_modules_5_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_heads_modules_6_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_heads_modules_7_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_self_modules_heads_modules_8_parameters_weight_: \"bf16[1026, 2048][2048, 1]cpu\", L_cfg_scale_: \"f32[][]cpu\"):\n",
      "        l_input_ids_ = L_input_ids_\n",
      "        l_self_modules_embeddings_modules_0_parameters_weight_ = L_self_modules_embeddings_modules_0_parameters_weight_\n",
      "        l_self_modules_embeddings_modules_1_parameters_weight_ = L_self_modules_embeddings_modules_1_parameters_weight_\n",
      "        l_self_modules_embeddings_modules_2_parameters_weight_ = L_self_modules_embeddings_modules_2_parameters_weight_\n",
      "        l_self_modules_embeddings_modules_3_parameters_weight_ = L_self_modules_embeddings_modules_3_parameters_weight_\n",
      "        l_self_modules_embeddings_modules_4_parameters_weight_ = L_self_modules_embeddings_modules_4_parameters_weight_\n",
      "        l_self_modules_embeddings_modules_5_parameters_weight_ = L_self_modules_embeddings_modules_5_parameters_weight_\n",
      "        l_self_modules_embeddings_modules_6_parameters_weight_ = L_self_modules_embeddings_modules_6_parameters_weight_\n",
      "        l_self_modules_embeddings_modules_7_parameters_weight_ = L_self_modules_embeddings_modules_7_parameters_weight_\n",
      "        l_self_modules_embeddings_modules_8_parameters_weight_ = L_self_modules_embeddings_modules_8_parameters_weight_\n",
      "        l_inference_params_lengths_per_sample = L_inference_params_lengths_per_sample\n",
      "        l_self_modules_backbone_freqs_cis = L_self_modules_backbone_freqs_cis\n",
      "        l_self_modules_backbone_modules_layers_modules_0_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_0_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_0_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_0_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_0_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_0_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_0_0_ = L_inference_params_key_value_memory_dict_0_0_\n",
      "        l_inference_params_batch_size_offset = L_inference_params_batch_size_offset\n",
      "        l_inference_params_seqlen_offset = L_inference_params_seqlen_offset\n",
      "        l_self_modules_backbone_modules_layers_modules_0_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_0_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_0_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_0_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_0_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_0_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_0_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_0_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_0_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_0_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_1_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_1_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_1_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_1_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_1_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_1_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_1_0_ = L_inference_params_key_value_memory_dict_1_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_1_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_1_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_1_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_1_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_1_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_1_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_1_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_1_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_1_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_1_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_2_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_2_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_2_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_2_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_2_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_2_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_2_0_ = L_inference_params_key_value_memory_dict_2_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_2_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_2_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_2_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_2_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_2_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_2_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_2_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_2_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_2_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_2_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_3_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_3_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_3_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_3_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_3_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_3_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_3_0_ = L_inference_params_key_value_memory_dict_3_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_3_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_3_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_3_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_3_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_3_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_3_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_3_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_3_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_3_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_3_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_4_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_4_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_4_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_4_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_4_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_4_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_4_0_ = L_inference_params_key_value_memory_dict_4_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_4_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_4_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_4_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_4_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_4_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_4_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_4_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_4_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_4_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_4_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_5_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_5_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_5_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_5_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_5_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_5_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_5_0_ = L_inference_params_key_value_memory_dict_5_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_5_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_5_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_5_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_5_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_5_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_5_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_5_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_5_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_5_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_5_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_6_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_6_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_6_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_6_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_6_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_6_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_6_0_ = L_inference_params_key_value_memory_dict_6_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_6_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_6_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_6_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_6_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_6_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_6_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_6_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_6_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_6_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_6_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_7_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_7_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_7_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_7_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_7_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_7_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_7_0_ = L_inference_params_key_value_memory_dict_7_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_7_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_7_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_7_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_7_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_7_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_7_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_7_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_7_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_7_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_7_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_8_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_8_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_8_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_8_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_8_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_8_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_8_0_ = L_inference_params_key_value_memory_dict_8_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_8_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_8_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_8_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_8_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_8_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_8_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_8_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_8_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_8_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_8_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_9_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_9_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_9_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_9_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_9_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_9_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_9_0_ = L_inference_params_key_value_memory_dict_9_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_9_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_9_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_9_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_9_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_9_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_9_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_9_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_9_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_9_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_9_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_10_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_10_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_10_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_10_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_10_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_10_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_10_0_ = L_inference_params_key_value_memory_dict_10_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_10_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_10_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_10_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_10_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_10_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_10_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_10_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_10_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_10_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_10_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_11_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_11_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_11_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_11_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_11_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_11_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_11_0_ = L_inference_params_key_value_memory_dict_11_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_11_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_11_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_11_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_11_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_11_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_11_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_11_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_11_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_11_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_11_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_12_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_12_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_12_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_12_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_12_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_12_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_12_0_ = L_inference_params_key_value_memory_dict_12_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_12_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_12_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_12_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_12_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_12_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_12_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_12_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_12_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_12_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_12_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_13_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_13_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_13_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_13_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_13_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_13_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_13_0_ = L_inference_params_key_value_memory_dict_13_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_13_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_13_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_13_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_13_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_13_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_13_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_13_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_13_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_13_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_13_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_14_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_14_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_14_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_14_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_14_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_14_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_14_0_ = L_inference_params_key_value_memory_dict_14_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_14_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_14_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_14_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_14_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_14_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_14_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_14_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_14_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_14_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_14_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_15_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_15_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_15_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_15_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_15_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_15_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_15_0_ = L_inference_params_key_value_memory_dict_15_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_15_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_15_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_15_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_15_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_15_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_15_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_15_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_15_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_15_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_15_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_16_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_16_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_16_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_16_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_16_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_16_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_16_0_ = L_inference_params_key_value_memory_dict_16_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_16_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_16_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_16_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_16_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_16_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_16_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_16_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_16_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_16_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_16_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_17_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_17_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_17_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_17_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_17_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_17_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_17_0_ = L_inference_params_key_value_memory_dict_17_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_17_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_17_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_17_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_17_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_17_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_17_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_17_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_17_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_17_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_17_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_18_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_18_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_18_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_18_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_18_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_18_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_18_0_ = L_inference_params_key_value_memory_dict_18_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_18_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_18_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_18_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_18_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_18_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_18_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_18_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_18_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_18_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_18_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_19_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_19_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_19_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_19_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_19_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_19_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_19_0_ = L_inference_params_key_value_memory_dict_19_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_19_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_19_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_19_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_19_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_19_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_19_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_19_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_19_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_19_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_19_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_20_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_20_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_20_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_20_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_20_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_20_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_20_0_ = L_inference_params_key_value_memory_dict_20_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_20_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_20_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_20_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_20_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_20_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_20_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_20_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_20_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_20_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_20_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_21_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_21_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_21_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_21_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_21_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_21_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_21_0_ = L_inference_params_key_value_memory_dict_21_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_21_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_21_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_21_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_21_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_21_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_21_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_21_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_21_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_21_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_21_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_22_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_22_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_22_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_22_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_22_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_22_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_22_0_ = L_inference_params_key_value_memory_dict_22_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_22_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_22_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_22_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_22_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_22_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_22_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_22_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_22_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_22_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_22_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_23_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_23_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_23_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_23_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_23_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_23_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_23_0_ = L_inference_params_key_value_memory_dict_23_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_23_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_23_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_23_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_23_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_23_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_23_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_23_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_23_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_23_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_23_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_24_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_24_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_24_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_24_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_24_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_24_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_24_0_ = L_inference_params_key_value_memory_dict_24_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_24_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_24_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_24_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_24_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_24_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_24_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_24_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_24_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_24_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_24_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_25_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_25_modules_norm_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_25_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_25_modules_norm_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_25_modules_mixer_modules_in_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_25_modules_mixer_modules_in_proj_parameters_weight_\n",
      "        l_inference_params_key_value_memory_dict_25_0_ = L_inference_params_key_value_memory_dict_25_0_\n",
      "        l_self_modules_backbone_modules_layers_modules_25_modules_mixer_modules_out_proj_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_25_modules_mixer_modules_out_proj_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_25_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_25_modules_norm2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_25_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_layers_modules_25_modules_norm2_parameters_bias_\n",
      "        l_self_modules_backbone_modules_layers_modules_25_modules_mlp_modules_fc1_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_25_modules_mlp_modules_fc1_parameters_weight_\n",
      "        l_self_modules_backbone_modules_layers_modules_25_modules_mlp_modules_fc2_parameters_weight_ = L_self_modules_backbone_modules_layers_modules_25_modules_mlp_modules_fc2_parameters_weight_\n",
      "        l_self_modules_backbone_modules_norm_f_parameters_weight_ = L_self_modules_backbone_modules_norm_f_parameters_weight_\n",
      "        l_self_modules_backbone_modules_norm_f_parameters_bias_ = L_self_modules_backbone_modules_norm_f_parameters_bias_\n",
      "        l_self_modules_heads_modules_0_parameters_weight_ = L_self_modules_heads_modules_0_parameters_weight_\n",
      "        l_self_modules_heads_modules_1_parameters_weight_ = L_self_modules_heads_modules_1_parameters_weight_\n",
      "        l_self_modules_heads_modules_2_parameters_weight_ = L_self_modules_heads_modules_2_parameters_weight_\n",
      "        l_self_modules_heads_modules_3_parameters_weight_ = L_self_modules_heads_modules_3_parameters_weight_\n",
      "        l_self_modules_heads_modules_4_parameters_weight_ = L_self_modules_heads_modules_4_parameters_weight_\n",
      "        l_self_modules_heads_modules_5_parameters_weight_ = L_self_modules_heads_modules_5_parameters_weight_\n",
      "        l_self_modules_heads_modules_6_parameters_weight_ = L_self_modules_heads_modules_6_parameters_weight_\n",
      "        l_self_modules_heads_modules_7_parameters_weight_ = L_self_modules_heads_modules_7_parameters_weight_\n",
      "        l_self_modules_heads_modules_8_parameters_weight_ = L_self_modules_heads_modules_8_parameters_weight_\n",
      "        l_cfg_scale_ = L_cfg_scale_\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:98 in <genexpr>, code: return sum(emb(codes[:, i]) for i, emb in enumerate(self.embeddings))\n",
      "        getitem: \"i64[1, 1][s0*s1, 1]cpu\" = l_input_ids_[(slice(None, None, None), 0)]\n",
      "        element: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.embedding(getitem, l_self_modules_embeddings_modules_0_parameters_weight_, None, None, 2.0, False, False);  getitem = l_self_modules_embeddings_modules_0_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/env/lib/python3.10/site-packages/torch/_dynamo/polyfills/functools.py:45 in reduce, code: value = function(value, element)\n",
      "        value: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = 0 + element;  element = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:98 in <genexpr>, code: return sum(emb(codes[:, i]) for i, emb in enumerate(self.embeddings))\n",
      "        getitem_1: \"i64[1, 1][s0*s1, 1]cpu\" = l_input_ids_[(slice(None, None, None), 1)]\n",
      "        element_1: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.embedding(getitem_1, l_self_modules_embeddings_modules_1_parameters_weight_, None, None, 2.0, False, False);  getitem_1 = l_self_modules_embeddings_modules_1_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/env/lib/python3.10/site-packages/torch/_dynamo/polyfills/functools.py:45 in reduce, code: value = function(value, element)\n",
      "        value_1: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = value + element_1;  value = element_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:98 in <genexpr>, code: return sum(emb(codes[:, i]) for i, emb in enumerate(self.embeddings))\n",
      "        getitem_2: \"i64[1, 1][s0*s1, 1]cpu\" = l_input_ids_[(slice(None, None, None), 2)]\n",
      "        element_2: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.embedding(getitem_2, l_self_modules_embeddings_modules_2_parameters_weight_, None, None, 2.0, False, False);  getitem_2 = l_self_modules_embeddings_modules_2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/env/lib/python3.10/site-packages/torch/_dynamo/polyfills/functools.py:45 in reduce, code: value = function(value, element)\n",
      "        value_2: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = value_1 + element_2;  value_1 = element_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:98 in <genexpr>, code: return sum(emb(codes[:, i]) for i, emb in enumerate(self.embeddings))\n",
      "        getitem_3: \"i64[1, 1][s0*s1, 1]cpu\" = l_input_ids_[(slice(None, None, None), 3)]\n",
      "        element_3: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.embedding(getitem_3, l_self_modules_embeddings_modules_3_parameters_weight_, None, None, 2.0, False, False);  getitem_3 = l_self_modules_embeddings_modules_3_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/env/lib/python3.10/site-packages/torch/_dynamo/polyfills/functools.py:45 in reduce, code: value = function(value, element)\n",
      "        value_3: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = value_2 + element_3;  value_2 = element_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:98 in <genexpr>, code: return sum(emb(codes[:, i]) for i, emb in enumerate(self.embeddings))\n",
      "        getitem_4: \"i64[1, 1][s0*s1, 1]cpu\" = l_input_ids_[(slice(None, None, None), 4)]\n",
      "        element_4: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.embedding(getitem_4, l_self_modules_embeddings_modules_4_parameters_weight_, None, None, 2.0, False, False);  getitem_4 = l_self_modules_embeddings_modules_4_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/env/lib/python3.10/site-packages/torch/_dynamo/polyfills/functools.py:45 in reduce, code: value = function(value, element)\n",
      "        value_4: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = value_3 + element_4;  value_3 = element_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:98 in <genexpr>, code: return sum(emb(codes[:, i]) for i, emb in enumerate(self.embeddings))\n",
      "        getitem_5: \"i64[1, 1][s0*s1, 1]cpu\" = l_input_ids_[(slice(None, None, None), 5)]\n",
      "        element_5: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.embedding(getitem_5, l_self_modules_embeddings_modules_5_parameters_weight_, None, None, 2.0, False, False);  getitem_5 = l_self_modules_embeddings_modules_5_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/env/lib/python3.10/site-packages/torch/_dynamo/polyfills/functools.py:45 in reduce, code: value = function(value, element)\n",
      "        value_5: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = value_4 + element_5;  value_4 = element_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:98 in <genexpr>, code: return sum(emb(codes[:, i]) for i, emb in enumerate(self.embeddings))\n",
      "        getitem_6: \"i64[1, 1][s0*s1, 1]cpu\" = l_input_ids_[(slice(None, None, None), 6)]\n",
      "        element_6: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.embedding(getitem_6, l_self_modules_embeddings_modules_6_parameters_weight_, None, None, 2.0, False, False);  getitem_6 = l_self_modules_embeddings_modules_6_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/env/lib/python3.10/site-packages/torch/_dynamo/polyfills/functools.py:45 in reduce, code: value = function(value, element)\n",
      "        value_6: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = value_5 + element_6;  value_5 = element_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:98 in <genexpr>, code: return sum(emb(codes[:, i]) for i, emb in enumerate(self.embeddings))\n",
      "        getitem_7: \"i64[1, 1][s0*s1, 1]cpu\" = l_input_ids_[(slice(None, None, None), 7)]\n",
      "        element_7: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.embedding(getitem_7, l_self_modules_embeddings_modules_7_parameters_weight_, None, None, 2.0, False, False);  getitem_7 = l_self_modules_embeddings_modules_7_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/env/lib/python3.10/site-packages/torch/_dynamo/polyfills/functools.py:45 in reduce, code: value = function(value, element)\n",
      "        value_7: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = value_6 + element_7;  value_6 = element_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:98 in <genexpr>, code: return sum(emb(codes[:, i]) for i, emb in enumerate(self.embeddings))\n",
      "        getitem_8: \"i64[1, 1][s0*s1, 1]cpu\" = l_input_ids_[(slice(None, None, None), 8)];  l_input_ids_ = None\n",
      "        element_8: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.embedding(getitem_8, l_self_modules_embeddings_modules_8_parameters_weight_, None, None, 2.0, False, False);  getitem_8 = l_self_modules_embeddings_modules_8_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/env/lib/python3.10/site-packages/torch/_dynamo/polyfills/functools.py:45 in reduce, code: value = function(value, element)\n",
      "        value_8: \"bf16[1, 1, 2048][2048, 2048, 1]cpu\" = value_7 + element_8;  value_7 = element_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:142 in torch_dynamo_resume_in__decode_one_token_at_134, code: hidden_states_local = hidden_states_local.repeat(2, 1, 1)\n",
      "        hidden_states_local: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = value_8.repeat(2, 1, 1);  value_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:74 in forward, code: input_pos = torch.arange(0, hidden_states.shape[1], device=hidden_states.device)\n",
      "        input_pos: \"i64[1][1]cpu\" = torch.arange(0, 1, device = device(type='cpu'))\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:75 in forward, code: input_pos = input_pos + inference_params.lengths_per_sample.unsqueeze(-1)\n",
      "        unsqueeze: \"i32[2, 1][1, 1]cpu\" = l_inference_params_lengths_per_sample.unsqueeze(-1);  l_inference_params_lengths_per_sample = None\n",
      "        input_pos_1: \"i64[2, 1][1, 1]cpu\" = input_pos + unsqueeze;  input_pos = unsqueeze = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:77 in forward, code: freqs_cis = self.freqs_cis[input_pos].expand(hidden_states.shape[0], -1, -1, -1)\n",
      "        getitem_9: \"f32[2, 1, 64, 2][128, 128, 2, 1]cpu\" = l_self_modules_backbone_freqs_cis[input_pos_1];  l_self_modules_backbone_freqs_cis = input_pos_1 = None\n",
      "        freqs_cis: \"f32[2, 1, 64, 2][128, 128, 2, 1]cpu\" = getitem_9.expand(2, -1, -1, -1);  getitem_9 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(hidden_states_local, (2048,), l_self_modules_backbone_modules_layers_modules_0_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_0_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_0_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_0_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm, l_self_modules_backbone_modules_layers_modules_0_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm = l_self_modules_backbone_modules_layers_modules_0_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split = linear.split([2048, 512, 512], dim = -1);  linear = None\n",
      "        q: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split[0]\n",
      "        k: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split[1]\n",
      "        v: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split[2];  split = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_1: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q.view(2, 1, 16, 128);  q = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_1: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k.view(2, 1, 4, 128);  k = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_1: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v.view(2, 1, 4, 128);  v = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_1: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_1.float()\n",
      "        xshaped: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_1.reshape(2, 1, 16, -1, 2);  float_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_1: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_13: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped[(Ellipsis, 0)]\n",
      "        getitem_14: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_1[(Ellipsis, 0)]\n",
      "        mul: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_13 * getitem_14;  getitem_13 = getitem_14 = None\n",
      "        getitem_15: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped[(Ellipsis, 1)]\n",
      "        getitem_16: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_1[(Ellipsis, 1)]\n",
      "        mul_1: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_15 * getitem_16;  getitem_15 = getitem_16 = None\n",
      "        sub: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul - mul_1;  mul = mul_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_17: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped[(Ellipsis, 1)]\n",
      "        getitem_18: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_1[(Ellipsis, 0)]\n",
      "        mul_2: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_17 * getitem_18;  getitem_17 = getitem_18 = None\n",
      "        getitem_19: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped[(Ellipsis, 0)];  xshaped = None\n",
      "        getitem_20: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_1[(Ellipsis, 1)];  freqs_cis_1 = None\n",
      "        mul_3: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_19 * getitem_20;  getitem_19 = getitem_20 = None\n",
      "        add_10: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_2 + mul_3;  mul_2 = mul_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub, add_10], -1);  sub = add_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_1: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2.flatten(3);  x_out2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_2: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_1.type_as(q_1);  x_out2_1 = q_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_2: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_1.float()\n",
      "        xshaped_1: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_2.reshape(2, 1, 4, -1, 2);  float_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_2: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_21: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_1[(Ellipsis, 0)]\n",
      "        getitem_22: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_2[(Ellipsis, 0)]\n",
      "        mul_4: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_21 * getitem_22;  getitem_21 = getitem_22 = None\n",
      "        getitem_23: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_1[(Ellipsis, 1)]\n",
      "        getitem_24: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_2[(Ellipsis, 1)]\n",
      "        mul_5: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_23 * getitem_24;  getitem_23 = getitem_24 = None\n",
      "        sub_1: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_4 - mul_5;  mul_4 = mul_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_25: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_1[(Ellipsis, 1)]\n",
      "        getitem_26: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_2[(Ellipsis, 0)]\n",
      "        mul_6: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_25 * getitem_26;  getitem_25 = getitem_26 = None\n",
      "        getitem_27: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_1[(Ellipsis, 0)];  xshaped_1 = None\n",
      "        getitem_28: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_2[(Ellipsis, 1)];  freqs_cis_2 = None\n",
      "        mul_7: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_27 * getitem_28;  getitem_27 = getitem_28 = None\n",
      "        add_11: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_6 + mul_7;  mul_6 = mul_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_2: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_1, add_11], -1);  sub_1 = add_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_3: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_2.flatten(3);  x_out2_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_2: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_3.type_as(k_1);  x_out2_3 = k_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_12: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_13: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size = l_inference_params_key_value_memory_dict_0_0_.size()\n",
      "        getitem_29 = size[0];  getitem_29 = None\n",
      "        getitem_30: \"Sym(s5)\" = size[1];  getitem_30 = None\n",
      "        getitem_31 = size[2];  getitem_31 = None\n",
      "        getitem_32: \"Sym(s6)\" = size[3];  getitem_32 = None\n",
      "        getitem_33: \"Sym(128)\" = size[4];  size = getitem_33 = None\n",
      "        le: \"Sym(True)\" = add_12 <= 2;  le = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_1 = l_inference_params_key_value_memory_dict_0_0_.size()\n",
      "        getitem_34 = size_1[0];  getitem_34 = None\n",
      "        getitem_35: \"Sym(s5)\" = size_1[1]\n",
      "        getitem_36 = size_1[2];  getitem_36 = None\n",
      "        getitem_37: \"Sym(s6)\" = size_1[3];  getitem_37 = None\n",
      "        getitem_38: \"Sym(128)\" = size_1[4];  size_1 = getitem_38 = None\n",
      "        le_1: \"Sym(s9 + 1 <= s5)\" = add_13 <= getitem_35;  getitem_35 = le_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_0_0_[(slice(l_inference_params_batch_size_offset, add_12, None), slice(l_inference_params_seqlen_offset, add_13, None), 0, Ellipsis)] = k_2;  setitem = l_inference_params_key_value_memory_dict_0_0_;  k_2 = setitem = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_0_0_[(slice(l_inference_params_batch_size_offset, add_12, None), slice(l_inference_params_seqlen_offset, add_13, None), 1, Ellipsis)] = v_1;  setitem_1 = l_inference_params_key_value_memory_dict_0_0_;  v_1 = setitem_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_0_0_[(slice(l_inference_params_batch_size_offset, add_12, None), slice(None, add_13, None), Ellipsis)];  l_inference_params_key_value_memory_dict_0_0_ = add_12 = add_13 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind = kv.unbind(dim = -3);  kv = None\n",
      "        k_3: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind[0]\n",
      "        v_2: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind[1];  unbind = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_3: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_2.transpose(1, 2);  q_2 = None\n",
      "        k_4: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_3.transpose(1, 2);  k_3 = None\n",
      "        v_3: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_2.transpose(1, 2);  v_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_3, k_4, v_3, is_causal = False, enable_gqa = True);  q_3 = k_4 = v_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_3: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y.transpose(1, 2);  y = None\n",
      "        contiguous: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_3.contiguous();  transpose_3 = None\n",
      "        y_1: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous.view(2, 1, 2048);  contiguous = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_2: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_1, l_self_modules_backbone_modules_layers_modules_0_modules_mixer_modules_out_proj_parameters_weight_, None);  y_1 = l_self_modules_backbone_modules_layers_modules_0_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = hidden_states_local + y_2;  hidden_states_local = y_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_1: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x, (2048,), l_self_modules_backbone_modules_layers_modules_0_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_0_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_0_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_0_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_2: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_1, l_self_modules_backbone_modules_layers_modules_0_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_1 = l_self_modules_backbone_modules_layers_modules_0_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk = linear_2.chunk(2, dim = -1);  linear_2 = None\n",
      "        y_3: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk[0]\n",
      "        gate: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk[1];  chunk = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate);  gate = None\n",
      "        mul_8: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_3 * silu;  y_3 = silu = None\n",
      "        linear_3: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_8, l_self_modules_backbone_modules_layers_modules_0_modules_mlp_modules_fc2_parameters_weight_, None);  mul_8 = l_self_modules_backbone_modules_layers_modules_0_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_1: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x + linear_3;  x = linear_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_2: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_1, (2048,), l_self_modules_backbone_modules_layers_modules_1_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_1_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_1_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_1_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_4: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_2, l_self_modules_backbone_modules_layers_modules_1_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_2 = l_self_modules_backbone_modules_layers_modules_1_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_1 = linear_4.split([2048, 512, 512], dim = -1);  linear_4 = None\n",
      "        q_4: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_1[0]\n",
      "        k_5: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_1[1]\n",
      "        v_4: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_1[2];  split_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_5: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_4.view(2, 1, 16, 128);  q_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_6: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_5.view(2, 1, 4, 128);  k_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_5: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_4.view(2, 1, 4, 128);  v_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_3: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_5.float()\n",
      "        xshaped_2: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_3.reshape(2, 1, 16, -1, 2);  float_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_3: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_47: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_2[(Ellipsis, 0)]\n",
      "        getitem_48: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_3[(Ellipsis, 0)]\n",
      "        mul_9: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_47 * getitem_48;  getitem_47 = getitem_48 = None\n",
      "        getitem_49: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_2[(Ellipsis, 1)]\n",
      "        getitem_50: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_3[(Ellipsis, 1)]\n",
      "        mul_10: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_49 * getitem_50;  getitem_49 = getitem_50 = None\n",
      "        sub_2: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_9 - mul_10;  mul_9 = mul_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_51: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_2[(Ellipsis, 1)]\n",
      "        getitem_52: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_3[(Ellipsis, 0)]\n",
      "        mul_11: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_51 * getitem_52;  getitem_51 = getitem_52 = None\n",
      "        getitem_53: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_2[(Ellipsis, 0)];  xshaped_2 = None\n",
      "        getitem_54: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_3[(Ellipsis, 1)];  freqs_cis_3 = None\n",
      "        mul_12: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_53 * getitem_54;  getitem_53 = getitem_54 = None\n",
      "        add_16: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_11 + mul_12;  mul_11 = mul_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_4: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_2, add_16], -1);  sub_2 = add_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_5: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_4.flatten(3);  x_out2_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_6: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_5.type_as(q_5);  x_out2_5 = q_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_4: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_6.float()\n",
      "        xshaped_3: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_4.reshape(2, 1, 4, -1, 2);  float_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_4: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_55: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_3[(Ellipsis, 0)]\n",
      "        getitem_56: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_4[(Ellipsis, 0)]\n",
      "        mul_13: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_55 * getitem_56;  getitem_55 = getitem_56 = None\n",
      "        getitem_57: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_3[(Ellipsis, 1)]\n",
      "        getitem_58: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_4[(Ellipsis, 1)]\n",
      "        mul_14: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_57 * getitem_58;  getitem_57 = getitem_58 = None\n",
      "        sub_3: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_13 - mul_14;  mul_13 = mul_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_59: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_3[(Ellipsis, 1)]\n",
      "        getitem_60: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_4[(Ellipsis, 0)]\n",
      "        mul_15: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_59 * getitem_60;  getitem_59 = getitem_60 = None\n",
      "        getitem_61: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_3[(Ellipsis, 0)];  xshaped_3 = None\n",
      "        getitem_62: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_4[(Ellipsis, 1)];  freqs_cis_4 = None\n",
      "        mul_16: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_61 * getitem_62;  getitem_61 = getitem_62 = None\n",
      "        add_17: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_15 + mul_16;  mul_15 = mul_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_6: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_3, add_17], -1);  sub_3 = add_17 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_7: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_6.flatten(3);  x_out2_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_7: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_7.type_as(k_6);  x_out2_7 = k_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_18: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_19: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_2 = l_inference_params_key_value_memory_dict_1_0_.size()\n",
      "        getitem_63 = size_2[0];  getitem_63 = None\n",
      "        getitem_64: \"Sym(s5)\" = size_2[1];  getitem_64 = None\n",
      "        getitem_65 = size_2[2];  getitem_65 = None\n",
      "        getitem_66: \"Sym(s6)\" = size_2[3];  getitem_66 = None\n",
      "        getitem_67 = size_2[4];  size_2 = getitem_67 = None\n",
      "        le_2: \"Sym(True)\" = add_18 <= 2;  le_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_3 = l_inference_params_key_value_memory_dict_1_0_.size()\n",
      "        getitem_68 = size_3[0];  getitem_68 = None\n",
      "        getitem_69: \"Sym(s5)\" = size_3[1]\n",
      "        getitem_70 = size_3[2];  getitem_70 = None\n",
      "        getitem_71: \"Sym(s6)\" = size_3[3];  getitem_71 = None\n",
      "        getitem_72 = size_3[4];  size_3 = getitem_72 = None\n",
      "        le_3: \"Sym(s9 + 1 <= s5)\" = add_19 <= getitem_69;  getitem_69 = le_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_1_0_[(slice(l_inference_params_batch_size_offset, add_18, None), slice(l_inference_params_seqlen_offset, add_19, None), 0, Ellipsis)] = k_7;  setitem_2 = l_inference_params_key_value_memory_dict_1_0_;  k_7 = setitem_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_1_0_[(slice(l_inference_params_batch_size_offset, add_18, None), slice(l_inference_params_seqlen_offset, add_19, None), 1, Ellipsis)] = v_5;  setitem_3 = l_inference_params_key_value_memory_dict_1_0_;  v_5 = setitem_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_1: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_1_0_[(slice(l_inference_params_batch_size_offset, add_18, None), slice(None, add_19, None), Ellipsis)];  l_inference_params_key_value_memory_dict_1_0_ = add_18 = add_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_1 = kv_1.unbind(dim = -3);  kv_1 = None\n",
      "        k_8: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_1[0]\n",
      "        v_6: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_1[1];  unbind_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_7: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_6.transpose(1, 2);  q_6 = None\n",
      "        k_9: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_8.transpose(1, 2);  k_8 = None\n",
      "        v_7: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_6.transpose(1, 2);  v_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_4: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_7, k_9, v_7, is_causal = False, enable_gqa = True);  q_7 = k_9 = v_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_7: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_4.transpose(1, 2);  y_4 = None\n",
      "        contiguous_1: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_7.contiguous();  transpose_7 = None\n",
      "        y_5: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_1.view(2, 1, 2048);  contiguous_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_6: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_5, l_self_modules_backbone_modules_layers_modules_1_modules_mixer_modules_out_proj_parameters_weight_, None);  y_5 = l_self_modules_backbone_modules_layers_modules_1_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_2: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_1 + y_6;  x_1 = y_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_3: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_2, (2048,), l_self_modules_backbone_modules_layers_modules_1_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_1_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_1_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_1_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_6: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_3, l_self_modules_backbone_modules_layers_modules_1_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_3 = l_self_modules_backbone_modules_layers_modules_1_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_1 = linear_6.chunk(2, dim = -1);  linear_6 = None\n",
      "        y_7: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_1[0]\n",
      "        gate_1: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_1[1];  chunk_1 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_1: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_1);  gate_1 = None\n",
      "        mul_17: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_7 * silu_1;  y_7 = silu_1 = None\n",
      "        linear_7: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_17, l_self_modules_backbone_modules_layers_modules_1_modules_mlp_modules_fc2_parameters_weight_, None);  mul_17 = l_self_modules_backbone_modules_layers_modules_1_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_3: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_2 + linear_7;  x_2 = linear_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_4: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_3, (2048,), l_self_modules_backbone_modules_layers_modules_2_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_2_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_2_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_2_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_8: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_4, l_self_modules_backbone_modules_layers_modules_2_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_4 = l_self_modules_backbone_modules_layers_modules_2_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_2 = linear_8.split([2048, 512, 512], dim = -1);  linear_8 = None\n",
      "        q_8: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_2[0]\n",
      "        k_10: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_2[1]\n",
      "        v_8: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_2[2];  split_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_9: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_8.view(2, 1, 16, 128);  q_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_11: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_10.view(2, 1, 4, 128);  k_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_9: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_8.view(2, 1, 4, 128);  v_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_5: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_9.float()\n",
      "        xshaped_4: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_5.reshape(2, 1, 16, -1, 2);  float_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_5: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_81: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_4[(Ellipsis, 0)]\n",
      "        getitem_82: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_5[(Ellipsis, 0)]\n",
      "        mul_18: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_81 * getitem_82;  getitem_81 = getitem_82 = None\n",
      "        getitem_83: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_4[(Ellipsis, 1)]\n",
      "        getitem_84: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_5[(Ellipsis, 1)]\n",
      "        mul_19: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_83 * getitem_84;  getitem_83 = getitem_84 = None\n",
      "        sub_4: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_18 - mul_19;  mul_18 = mul_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_85: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_4[(Ellipsis, 1)]\n",
      "        getitem_86: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_5[(Ellipsis, 0)]\n",
      "        mul_20: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_85 * getitem_86;  getitem_85 = getitem_86 = None\n",
      "        getitem_87: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_4[(Ellipsis, 0)];  xshaped_4 = None\n",
      "        getitem_88: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_5[(Ellipsis, 1)];  freqs_cis_5 = None\n",
      "        mul_21: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_87 * getitem_88;  getitem_87 = getitem_88 = None\n",
      "        add_22: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_20 + mul_21;  mul_20 = mul_21 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_8: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_4, add_22], -1);  sub_4 = add_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_9: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_8.flatten(3);  x_out2_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_10: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_9.type_as(q_9);  x_out2_9 = q_9 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_6: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_11.float()\n",
      "        xshaped_5: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_6.reshape(2, 1, 4, -1, 2);  float_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_6: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_89: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_5[(Ellipsis, 0)]\n",
      "        getitem_90: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_6[(Ellipsis, 0)]\n",
      "        mul_22: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_89 * getitem_90;  getitem_89 = getitem_90 = None\n",
      "        getitem_91: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_5[(Ellipsis, 1)]\n",
      "        getitem_92: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_6[(Ellipsis, 1)]\n",
      "        mul_23: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_91 * getitem_92;  getitem_91 = getitem_92 = None\n",
      "        sub_5: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_22 - mul_23;  mul_22 = mul_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_93: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_5[(Ellipsis, 1)]\n",
      "        getitem_94: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_6[(Ellipsis, 0)]\n",
      "        mul_24: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_93 * getitem_94;  getitem_93 = getitem_94 = None\n",
      "        getitem_95: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_5[(Ellipsis, 0)];  xshaped_5 = None\n",
      "        getitem_96: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_6[(Ellipsis, 1)];  freqs_cis_6 = None\n",
      "        mul_25: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_95 * getitem_96;  getitem_95 = getitem_96 = None\n",
      "        add_23: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_24 + mul_25;  mul_24 = mul_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_10: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_5, add_23], -1);  sub_5 = add_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_11: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_10.flatten(3);  x_out2_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_12: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_11.type_as(k_11);  x_out2_11 = k_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_24: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_25: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_4 = l_inference_params_key_value_memory_dict_2_0_.size()\n",
      "        getitem_97 = size_4[0];  getitem_97 = None\n",
      "        getitem_98: \"Sym(s5)\" = size_4[1];  getitem_98 = None\n",
      "        getitem_99 = size_4[2];  getitem_99 = None\n",
      "        getitem_100: \"Sym(s6)\" = size_4[3];  getitem_100 = None\n",
      "        getitem_101 = size_4[4];  size_4 = getitem_101 = None\n",
      "        le_4: \"Sym(True)\" = add_24 <= 2;  le_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_5 = l_inference_params_key_value_memory_dict_2_0_.size()\n",
      "        getitem_102 = size_5[0];  getitem_102 = None\n",
      "        getitem_103: \"Sym(s5)\" = size_5[1]\n",
      "        getitem_104 = size_5[2];  getitem_104 = None\n",
      "        getitem_105: \"Sym(s6)\" = size_5[3];  getitem_105 = None\n",
      "        getitem_106 = size_5[4];  size_5 = getitem_106 = None\n",
      "        le_5: \"Sym(s9 + 1 <= s5)\" = add_25 <= getitem_103;  getitem_103 = le_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_2_0_[(slice(l_inference_params_batch_size_offset, add_24, None), slice(l_inference_params_seqlen_offset, add_25, None), 0, Ellipsis)] = k_12;  setitem_4 = l_inference_params_key_value_memory_dict_2_0_;  k_12 = setitem_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_2_0_[(slice(l_inference_params_batch_size_offset, add_24, None), slice(l_inference_params_seqlen_offset, add_25, None), 1, Ellipsis)] = v_9;  setitem_5 = l_inference_params_key_value_memory_dict_2_0_;  v_9 = setitem_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_2: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_2_0_[(slice(l_inference_params_batch_size_offset, add_24, None), slice(None, add_25, None), Ellipsis)];  l_inference_params_key_value_memory_dict_2_0_ = add_24 = add_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_2 = kv_2.unbind(dim = -3);  kv_2 = None\n",
      "        k_13: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_2[0]\n",
      "        v_10: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_2[1];  unbind_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_11: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_10.transpose(1, 2);  q_10 = None\n",
      "        k_14: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_13.transpose(1, 2);  k_13 = None\n",
      "        v_11: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_10.transpose(1, 2);  v_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_8: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_11, k_14, v_11, is_causal = False, enable_gqa = True);  q_11 = k_14 = v_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_11: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_8.transpose(1, 2);  y_8 = None\n",
      "        contiguous_2: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_11.contiguous();  transpose_11 = None\n",
      "        y_9: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_2.view(2, 1, 2048);  contiguous_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_10: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_9, l_self_modules_backbone_modules_layers_modules_2_modules_mixer_modules_out_proj_parameters_weight_, None);  y_9 = l_self_modules_backbone_modules_layers_modules_2_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_4: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_3 + y_10;  x_3 = y_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_5: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_4, (2048,), l_self_modules_backbone_modules_layers_modules_2_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_2_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_2_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_2_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_10: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_5, l_self_modules_backbone_modules_layers_modules_2_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_5 = l_self_modules_backbone_modules_layers_modules_2_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_2 = linear_10.chunk(2, dim = -1);  linear_10 = None\n",
      "        y_11: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_2[0]\n",
      "        gate_2: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_2[1];  chunk_2 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_2: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_2);  gate_2 = None\n",
      "        mul_26: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_11 * silu_2;  y_11 = silu_2 = None\n",
      "        linear_11: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_26, l_self_modules_backbone_modules_layers_modules_2_modules_mlp_modules_fc2_parameters_weight_, None);  mul_26 = l_self_modules_backbone_modules_layers_modules_2_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_5: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_4 + linear_11;  x_4 = linear_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_6: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_5, (2048,), l_self_modules_backbone_modules_layers_modules_3_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_3_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_3_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_3_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_12: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_6, l_self_modules_backbone_modules_layers_modules_3_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_6 = l_self_modules_backbone_modules_layers_modules_3_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_3 = linear_12.split([2048, 512, 512], dim = -1);  linear_12 = None\n",
      "        q_12: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_3[0]\n",
      "        k_15: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_3[1]\n",
      "        v_12: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_3[2];  split_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_13: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_12.view(2, 1, 16, 128);  q_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_16: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_15.view(2, 1, 4, 128);  k_15 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_13: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_12.view(2, 1, 4, 128);  v_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_7: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_13.float()\n",
      "        xshaped_6: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_7.reshape(2, 1, 16, -1, 2);  float_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_7: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_115: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_6[(Ellipsis, 0)]\n",
      "        getitem_116: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_7[(Ellipsis, 0)]\n",
      "        mul_27: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_115 * getitem_116;  getitem_115 = getitem_116 = None\n",
      "        getitem_117: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_6[(Ellipsis, 1)]\n",
      "        getitem_118: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_7[(Ellipsis, 1)]\n",
      "        mul_28: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_117 * getitem_118;  getitem_117 = getitem_118 = None\n",
      "        sub_6: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_27 - mul_28;  mul_27 = mul_28 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_119: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_6[(Ellipsis, 1)]\n",
      "        getitem_120: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_7[(Ellipsis, 0)]\n",
      "        mul_29: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_119 * getitem_120;  getitem_119 = getitem_120 = None\n",
      "        getitem_121: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_6[(Ellipsis, 0)];  xshaped_6 = None\n",
      "        getitem_122: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_7[(Ellipsis, 1)];  freqs_cis_7 = None\n",
      "        mul_30: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_121 * getitem_122;  getitem_121 = getitem_122 = None\n",
      "        add_28: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_29 + mul_30;  mul_29 = mul_30 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_12: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_6, add_28], -1);  sub_6 = add_28 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_13: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_12.flatten(3);  x_out2_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_14: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_13.type_as(q_13);  x_out2_13 = q_13 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_8: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_16.float()\n",
      "        xshaped_7: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_8.reshape(2, 1, 4, -1, 2);  float_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_8: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_123: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_7[(Ellipsis, 0)]\n",
      "        getitem_124: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_8[(Ellipsis, 0)]\n",
      "        mul_31: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_123 * getitem_124;  getitem_123 = getitem_124 = None\n",
      "        getitem_125: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_7[(Ellipsis, 1)]\n",
      "        getitem_126: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_8[(Ellipsis, 1)]\n",
      "        mul_32: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_125 * getitem_126;  getitem_125 = getitem_126 = None\n",
      "        sub_7: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_31 - mul_32;  mul_31 = mul_32 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_127: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_7[(Ellipsis, 1)]\n",
      "        getitem_128: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_8[(Ellipsis, 0)]\n",
      "        mul_33: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_127 * getitem_128;  getitem_127 = getitem_128 = None\n",
      "        getitem_129: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_7[(Ellipsis, 0)];  xshaped_7 = None\n",
      "        getitem_130: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_8[(Ellipsis, 1)];  freqs_cis_8 = None\n",
      "        mul_34: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_129 * getitem_130;  getitem_129 = getitem_130 = None\n",
      "        add_29: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_33 + mul_34;  mul_33 = mul_34 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_14: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_7, add_29], -1);  sub_7 = add_29 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_15: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_14.flatten(3);  x_out2_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_17: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_15.type_as(k_16);  x_out2_15 = k_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_30: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_31: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_6 = l_inference_params_key_value_memory_dict_3_0_.size()\n",
      "        getitem_131 = size_6[0];  getitem_131 = None\n",
      "        getitem_132: \"Sym(s5)\" = size_6[1];  getitem_132 = None\n",
      "        getitem_133 = size_6[2];  getitem_133 = None\n",
      "        getitem_134: \"Sym(s6)\" = size_6[3];  getitem_134 = None\n",
      "        getitem_135 = size_6[4];  size_6 = getitem_135 = None\n",
      "        le_6: \"Sym(True)\" = add_30 <= 2;  le_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_7 = l_inference_params_key_value_memory_dict_3_0_.size()\n",
      "        getitem_136 = size_7[0];  getitem_136 = None\n",
      "        getitem_137: \"Sym(s5)\" = size_7[1]\n",
      "        getitem_138 = size_7[2];  getitem_138 = None\n",
      "        getitem_139: \"Sym(s6)\" = size_7[3];  getitem_139 = None\n",
      "        getitem_140 = size_7[4];  size_7 = getitem_140 = None\n",
      "        le_7: \"Sym(s9 + 1 <= s5)\" = add_31 <= getitem_137;  getitem_137 = le_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_3_0_[(slice(l_inference_params_batch_size_offset, add_30, None), slice(l_inference_params_seqlen_offset, add_31, None), 0, Ellipsis)] = k_17;  setitem_6 = l_inference_params_key_value_memory_dict_3_0_;  k_17 = setitem_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_3_0_[(slice(l_inference_params_batch_size_offset, add_30, None), slice(l_inference_params_seqlen_offset, add_31, None), 1, Ellipsis)] = v_13;  setitem_7 = l_inference_params_key_value_memory_dict_3_0_;  v_13 = setitem_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_3: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_3_0_[(slice(l_inference_params_batch_size_offset, add_30, None), slice(None, add_31, None), Ellipsis)];  l_inference_params_key_value_memory_dict_3_0_ = add_30 = add_31 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_3 = kv_3.unbind(dim = -3);  kv_3 = None\n",
      "        k_18: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_3[0]\n",
      "        v_14: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_3[1];  unbind_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_15: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_14.transpose(1, 2);  q_14 = None\n",
      "        k_19: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_18.transpose(1, 2);  k_18 = None\n",
      "        v_15: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_14.transpose(1, 2);  v_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_12: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_15, k_19, v_15, is_causal = False, enable_gqa = True);  q_15 = k_19 = v_15 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_15: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_12.transpose(1, 2);  y_12 = None\n",
      "        contiguous_3: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_15.contiguous();  transpose_15 = None\n",
      "        y_13: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_3.view(2, 1, 2048);  contiguous_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_14: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_13, l_self_modules_backbone_modules_layers_modules_3_modules_mixer_modules_out_proj_parameters_weight_, None);  y_13 = l_self_modules_backbone_modules_layers_modules_3_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_6: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_5 + y_14;  x_5 = y_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_7: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_6, (2048,), l_self_modules_backbone_modules_layers_modules_3_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_3_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_3_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_3_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_14: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_7, l_self_modules_backbone_modules_layers_modules_3_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_7 = l_self_modules_backbone_modules_layers_modules_3_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_3 = linear_14.chunk(2, dim = -1);  linear_14 = None\n",
      "        y_15: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_3[0]\n",
      "        gate_3: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_3[1];  chunk_3 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_3: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_3);  gate_3 = None\n",
      "        mul_35: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_15 * silu_3;  y_15 = silu_3 = None\n",
      "        linear_15: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_35, l_self_modules_backbone_modules_layers_modules_3_modules_mlp_modules_fc2_parameters_weight_, None);  mul_35 = l_self_modules_backbone_modules_layers_modules_3_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_7: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_6 + linear_15;  x_6 = linear_15 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_8: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_7, (2048,), l_self_modules_backbone_modules_layers_modules_4_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_4_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_4_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_4_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_16: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_8, l_self_modules_backbone_modules_layers_modules_4_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_8 = l_self_modules_backbone_modules_layers_modules_4_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_4 = linear_16.split([2048, 512, 512], dim = -1);  linear_16 = None\n",
      "        q_16: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_4[0]\n",
      "        k_20: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_4[1]\n",
      "        v_16: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_4[2];  split_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_17: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_16.view(2, 1, 16, 128);  q_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_21: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_20.view(2, 1, 4, 128);  k_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_17: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_16.view(2, 1, 4, 128);  v_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_9: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_17.float()\n",
      "        xshaped_8: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_9.reshape(2, 1, 16, -1, 2);  float_9 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_9: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_149: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_8[(Ellipsis, 0)]\n",
      "        getitem_150: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_9[(Ellipsis, 0)]\n",
      "        mul_36: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_149 * getitem_150;  getitem_149 = getitem_150 = None\n",
      "        getitem_151: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_8[(Ellipsis, 1)]\n",
      "        getitem_152: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_9[(Ellipsis, 1)]\n",
      "        mul_37: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_151 * getitem_152;  getitem_151 = getitem_152 = None\n",
      "        sub_8: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_36 - mul_37;  mul_36 = mul_37 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_153: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_8[(Ellipsis, 1)]\n",
      "        getitem_154: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_9[(Ellipsis, 0)]\n",
      "        mul_38: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_153 * getitem_154;  getitem_153 = getitem_154 = None\n",
      "        getitem_155: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_8[(Ellipsis, 0)];  xshaped_8 = None\n",
      "        getitem_156: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_9[(Ellipsis, 1)];  freqs_cis_9 = None\n",
      "        mul_39: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_155 * getitem_156;  getitem_155 = getitem_156 = None\n",
      "        add_34: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_38 + mul_39;  mul_38 = mul_39 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_16: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_8, add_34], -1);  sub_8 = add_34 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_17: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_16.flatten(3);  x_out2_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_18: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_17.type_as(q_17);  x_out2_17 = q_17 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_10: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_21.float()\n",
      "        xshaped_9: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_10.reshape(2, 1, 4, -1, 2);  float_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_10: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_157: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_9[(Ellipsis, 0)]\n",
      "        getitem_158: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_10[(Ellipsis, 0)]\n",
      "        mul_40: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_157 * getitem_158;  getitem_157 = getitem_158 = None\n",
      "        getitem_159: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_9[(Ellipsis, 1)]\n",
      "        getitem_160: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_10[(Ellipsis, 1)]\n",
      "        mul_41: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_159 * getitem_160;  getitem_159 = getitem_160 = None\n",
      "        sub_9: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_40 - mul_41;  mul_40 = mul_41 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_161: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_9[(Ellipsis, 1)]\n",
      "        getitem_162: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_10[(Ellipsis, 0)]\n",
      "        mul_42: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_161 * getitem_162;  getitem_161 = getitem_162 = None\n",
      "        getitem_163: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_9[(Ellipsis, 0)];  xshaped_9 = None\n",
      "        getitem_164: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_10[(Ellipsis, 1)];  freqs_cis_10 = None\n",
      "        mul_43: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_163 * getitem_164;  getitem_163 = getitem_164 = None\n",
      "        add_35: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_42 + mul_43;  mul_42 = mul_43 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_18: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_9, add_35], -1);  sub_9 = add_35 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_19: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_18.flatten(3);  x_out2_18 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_22: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_19.type_as(k_21);  x_out2_19 = k_21 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_36: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_37: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_8 = l_inference_params_key_value_memory_dict_4_0_.size()\n",
      "        getitem_165 = size_8[0];  getitem_165 = None\n",
      "        getitem_166: \"Sym(s5)\" = size_8[1];  getitem_166 = None\n",
      "        getitem_167 = size_8[2];  getitem_167 = None\n",
      "        getitem_168: \"Sym(s6)\" = size_8[3];  getitem_168 = None\n",
      "        getitem_169 = size_8[4];  size_8 = getitem_169 = None\n",
      "        le_8: \"Sym(True)\" = add_36 <= 2;  le_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_9 = l_inference_params_key_value_memory_dict_4_0_.size()\n",
      "        getitem_170 = size_9[0];  getitem_170 = None\n",
      "        getitem_171: \"Sym(s5)\" = size_9[1]\n",
      "        getitem_172 = size_9[2];  getitem_172 = None\n",
      "        getitem_173: \"Sym(s6)\" = size_9[3];  getitem_173 = None\n",
      "        getitem_174 = size_9[4];  size_9 = getitem_174 = None\n",
      "        le_9: \"Sym(s9 + 1 <= s5)\" = add_37 <= getitem_171;  getitem_171 = le_9 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_4_0_[(slice(l_inference_params_batch_size_offset, add_36, None), slice(l_inference_params_seqlen_offset, add_37, None), 0, Ellipsis)] = k_22;  setitem_8 = l_inference_params_key_value_memory_dict_4_0_;  k_22 = setitem_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_4_0_[(slice(l_inference_params_batch_size_offset, add_36, None), slice(l_inference_params_seqlen_offset, add_37, None), 1, Ellipsis)] = v_17;  setitem_9 = l_inference_params_key_value_memory_dict_4_0_;  v_17 = setitem_9 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_4: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_4_0_[(slice(l_inference_params_batch_size_offset, add_36, None), slice(None, add_37, None), Ellipsis)];  l_inference_params_key_value_memory_dict_4_0_ = add_36 = add_37 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_4 = kv_4.unbind(dim = -3);  kv_4 = None\n",
      "        k_23: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_4[0]\n",
      "        v_18: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_4[1];  unbind_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_19: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_18.transpose(1, 2);  q_18 = None\n",
      "        k_24: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_23.transpose(1, 2);  k_23 = None\n",
      "        v_19: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_18.transpose(1, 2);  v_18 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_16: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_19, k_24, v_19, is_causal = False, enable_gqa = True);  q_19 = k_24 = v_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_19: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_16.transpose(1, 2);  y_16 = None\n",
      "        contiguous_4: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_19.contiguous();  transpose_19 = None\n",
      "        y_17: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_4.view(2, 1, 2048);  contiguous_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_18: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_17, l_self_modules_backbone_modules_layers_modules_4_modules_mixer_modules_out_proj_parameters_weight_, None);  y_17 = l_self_modules_backbone_modules_layers_modules_4_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_8: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_7 + y_18;  x_7 = y_18 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_9: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_8, (2048,), l_self_modules_backbone_modules_layers_modules_4_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_4_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_4_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_4_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_18: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_9, l_self_modules_backbone_modules_layers_modules_4_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_9 = l_self_modules_backbone_modules_layers_modules_4_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_4 = linear_18.chunk(2, dim = -1);  linear_18 = None\n",
      "        y_19: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_4[0]\n",
      "        gate_4: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_4[1];  chunk_4 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_4: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_4);  gate_4 = None\n",
      "        mul_44: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_19 * silu_4;  y_19 = silu_4 = None\n",
      "        linear_19: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_44, l_self_modules_backbone_modules_layers_modules_4_modules_mlp_modules_fc2_parameters_weight_, None);  mul_44 = l_self_modules_backbone_modules_layers_modules_4_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_9: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_8 + linear_19;  x_8 = linear_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_10: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_9, (2048,), l_self_modules_backbone_modules_layers_modules_5_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_5_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_5_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_5_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_20: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_10, l_self_modules_backbone_modules_layers_modules_5_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_10 = l_self_modules_backbone_modules_layers_modules_5_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_5 = linear_20.split([2048, 512, 512], dim = -1);  linear_20 = None\n",
      "        q_20: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_5[0]\n",
      "        k_25: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_5[1]\n",
      "        v_20: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_5[2];  split_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_21: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_20.view(2, 1, 16, 128);  q_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_26: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_25.view(2, 1, 4, 128);  k_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_21: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_20.view(2, 1, 4, 128);  v_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_11: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_21.float()\n",
      "        xshaped_10: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_11.reshape(2, 1, 16, -1, 2);  float_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_11: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_183: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_10[(Ellipsis, 0)]\n",
      "        getitem_184: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_11[(Ellipsis, 0)]\n",
      "        mul_45: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_183 * getitem_184;  getitem_183 = getitem_184 = None\n",
      "        getitem_185: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_10[(Ellipsis, 1)]\n",
      "        getitem_186: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_11[(Ellipsis, 1)]\n",
      "        mul_46: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_185 * getitem_186;  getitem_185 = getitem_186 = None\n",
      "        sub_10: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_45 - mul_46;  mul_45 = mul_46 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_187: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_10[(Ellipsis, 1)]\n",
      "        getitem_188: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_11[(Ellipsis, 0)]\n",
      "        mul_47: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_187 * getitem_188;  getitem_187 = getitem_188 = None\n",
      "        getitem_189: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_10[(Ellipsis, 0)];  xshaped_10 = None\n",
      "        getitem_190: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_11[(Ellipsis, 1)];  freqs_cis_11 = None\n",
      "        mul_48: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_189 * getitem_190;  getitem_189 = getitem_190 = None\n",
      "        add_40: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_47 + mul_48;  mul_47 = mul_48 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_20: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_10, add_40], -1);  sub_10 = add_40 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_21: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_20.flatten(3);  x_out2_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_22: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_21.type_as(q_21);  x_out2_21 = q_21 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_12: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_26.float()\n",
      "        xshaped_11: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_12.reshape(2, 1, 4, -1, 2);  float_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_12: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_191: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_11[(Ellipsis, 0)]\n",
      "        getitem_192: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_12[(Ellipsis, 0)]\n",
      "        mul_49: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_191 * getitem_192;  getitem_191 = getitem_192 = None\n",
      "        getitem_193: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_11[(Ellipsis, 1)]\n",
      "        getitem_194: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_12[(Ellipsis, 1)]\n",
      "        mul_50: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_193 * getitem_194;  getitem_193 = getitem_194 = None\n",
      "        sub_11: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_49 - mul_50;  mul_49 = mul_50 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_195: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_11[(Ellipsis, 1)]\n",
      "        getitem_196: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_12[(Ellipsis, 0)]\n",
      "        mul_51: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_195 * getitem_196;  getitem_195 = getitem_196 = None\n",
      "        getitem_197: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_11[(Ellipsis, 0)];  xshaped_11 = None\n",
      "        getitem_198: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_12[(Ellipsis, 1)];  freqs_cis_12 = None\n",
      "        mul_52: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_197 * getitem_198;  getitem_197 = getitem_198 = None\n",
      "        add_41: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_51 + mul_52;  mul_51 = mul_52 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_22: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_11, add_41], -1);  sub_11 = add_41 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_23: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_22.flatten(3);  x_out2_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_27: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_23.type_as(k_26);  x_out2_23 = k_26 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_42: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_43: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_10 = l_inference_params_key_value_memory_dict_5_0_.size()\n",
      "        getitem_199 = size_10[0];  getitem_199 = None\n",
      "        getitem_200: \"Sym(s5)\" = size_10[1];  getitem_200 = None\n",
      "        getitem_201 = size_10[2];  getitem_201 = None\n",
      "        getitem_202: \"Sym(s6)\" = size_10[3];  getitem_202 = None\n",
      "        getitem_203 = size_10[4];  size_10 = getitem_203 = None\n",
      "        le_10: \"Sym(True)\" = add_42 <= 2;  le_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_11 = l_inference_params_key_value_memory_dict_5_0_.size()\n",
      "        getitem_204 = size_11[0];  getitem_204 = None\n",
      "        getitem_205: \"Sym(s5)\" = size_11[1]\n",
      "        getitem_206 = size_11[2];  getitem_206 = None\n",
      "        getitem_207: \"Sym(s6)\" = size_11[3];  getitem_207 = None\n",
      "        getitem_208 = size_11[4];  size_11 = getitem_208 = None\n",
      "        le_11: \"Sym(s9 + 1 <= s5)\" = add_43 <= getitem_205;  getitem_205 = le_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_5_0_[(slice(l_inference_params_batch_size_offset, add_42, None), slice(l_inference_params_seqlen_offset, add_43, None), 0, Ellipsis)] = k_27;  setitem_10 = l_inference_params_key_value_memory_dict_5_0_;  k_27 = setitem_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_5_0_[(slice(l_inference_params_batch_size_offset, add_42, None), slice(l_inference_params_seqlen_offset, add_43, None), 1, Ellipsis)] = v_21;  setitem_11 = l_inference_params_key_value_memory_dict_5_0_;  v_21 = setitem_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_5: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_5_0_[(slice(l_inference_params_batch_size_offset, add_42, None), slice(None, add_43, None), Ellipsis)];  l_inference_params_key_value_memory_dict_5_0_ = add_42 = add_43 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_5 = kv_5.unbind(dim = -3);  kv_5 = None\n",
      "        k_28: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_5[0]\n",
      "        v_22: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_5[1];  unbind_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_23: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_22.transpose(1, 2);  q_22 = None\n",
      "        k_29: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_28.transpose(1, 2);  k_28 = None\n",
      "        v_23: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_22.transpose(1, 2);  v_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_20: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_23, k_29, v_23, is_causal = False, enable_gqa = True);  q_23 = k_29 = v_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_23: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_20.transpose(1, 2);  y_20 = None\n",
      "        contiguous_5: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_23.contiguous();  transpose_23 = None\n",
      "        y_21: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_5.view(2, 1, 2048);  contiguous_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_22: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_21, l_self_modules_backbone_modules_layers_modules_5_modules_mixer_modules_out_proj_parameters_weight_, None);  y_21 = l_self_modules_backbone_modules_layers_modules_5_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_10: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_9 + y_22;  x_9 = y_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_11: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_10, (2048,), l_self_modules_backbone_modules_layers_modules_5_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_5_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_5_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_5_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_22: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_11, l_self_modules_backbone_modules_layers_modules_5_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_11 = l_self_modules_backbone_modules_layers_modules_5_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_5 = linear_22.chunk(2, dim = -1);  linear_22 = None\n",
      "        y_23: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_5[0]\n",
      "        gate_5: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_5[1];  chunk_5 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_5: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_5);  gate_5 = None\n",
      "        mul_53: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_23 * silu_5;  y_23 = silu_5 = None\n",
      "        linear_23: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_53, l_self_modules_backbone_modules_layers_modules_5_modules_mlp_modules_fc2_parameters_weight_, None);  mul_53 = l_self_modules_backbone_modules_layers_modules_5_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_11: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_10 + linear_23;  x_10 = linear_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_12: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_11, (2048,), l_self_modules_backbone_modules_layers_modules_6_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_6_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_6_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_6_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_24: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_12, l_self_modules_backbone_modules_layers_modules_6_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_12 = l_self_modules_backbone_modules_layers_modules_6_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_6 = linear_24.split([2048, 512, 512], dim = -1);  linear_24 = None\n",
      "        q_24: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_6[0]\n",
      "        k_30: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_6[1]\n",
      "        v_24: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_6[2];  split_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_25: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_24.view(2, 1, 16, 128);  q_24 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_31: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_30.view(2, 1, 4, 128);  k_30 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_25: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_24.view(2, 1, 4, 128);  v_24 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_13: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_25.float()\n",
      "        xshaped_12: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_13.reshape(2, 1, 16, -1, 2);  float_13 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_13: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_217: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_12[(Ellipsis, 0)]\n",
      "        getitem_218: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_13[(Ellipsis, 0)]\n",
      "        mul_54: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_217 * getitem_218;  getitem_217 = getitem_218 = None\n",
      "        getitem_219: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_12[(Ellipsis, 1)]\n",
      "        getitem_220: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_13[(Ellipsis, 1)]\n",
      "        mul_55: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_219 * getitem_220;  getitem_219 = getitem_220 = None\n",
      "        sub_12: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_54 - mul_55;  mul_54 = mul_55 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_221: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_12[(Ellipsis, 1)]\n",
      "        getitem_222: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_13[(Ellipsis, 0)]\n",
      "        mul_56: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_221 * getitem_222;  getitem_221 = getitem_222 = None\n",
      "        getitem_223: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_12[(Ellipsis, 0)];  xshaped_12 = None\n",
      "        getitem_224: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_13[(Ellipsis, 1)];  freqs_cis_13 = None\n",
      "        mul_57: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_223 * getitem_224;  getitem_223 = getitem_224 = None\n",
      "        add_46: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_56 + mul_57;  mul_56 = mul_57 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_24: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_12, add_46], -1);  sub_12 = add_46 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_25: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_24.flatten(3);  x_out2_24 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_26: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_25.type_as(q_25);  x_out2_25 = q_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_14: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_31.float()\n",
      "        xshaped_13: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_14.reshape(2, 1, 4, -1, 2);  float_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_14: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_225: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_13[(Ellipsis, 0)]\n",
      "        getitem_226: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_14[(Ellipsis, 0)]\n",
      "        mul_58: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_225 * getitem_226;  getitem_225 = getitem_226 = None\n",
      "        getitem_227: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_13[(Ellipsis, 1)]\n",
      "        getitem_228: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_14[(Ellipsis, 1)]\n",
      "        mul_59: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_227 * getitem_228;  getitem_227 = getitem_228 = None\n",
      "        sub_13: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_58 - mul_59;  mul_58 = mul_59 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_229: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_13[(Ellipsis, 1)]\n",
      "        getitem_230: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_14[(Ellipsis, 0)]\n",
      "        mul_60: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_229 * getitem_230;  getitem_229 = getitem_230 = None\n",
      "        getitem_231: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_13[(Ellipsis, 0)];  xshaped_13 = None\n",
      "        getitem_232: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_14[(Ellipsis, 1)];  freqs_cis_14 = None\n",
      "        mul_61: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_231 * getitem_232;  getitem_231 = getitem_232 = None\n",
      "        add_47: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_60 + mul_61;  mul_60 = mul_61 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_26: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_13, add_47], -1);  sub_13 = add_47 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_27: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_26.flatten(3);  x_out2_26 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_32: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_27.type_as(k_31);  x_out2_27 = k_31 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_48: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_49: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_12 = l_inference_params_key_value_memory_dict_6_0_.size()\n",
      "        getitem_233 = size_12[0];  getitem_233 = None\n",
      "        getitem_234: \"Sym(s5)\" = size_12[1];  getitem_234 = None\n",
      "        getitem_235 = size_12[2];  getitem_235 = None\n",
      "        getitem_236: \"Sym(s6)\" = size_12[3];  getitem_236 = None\n",
      "        getitem_237 = size_12[4];  size_12 = getitem_237 = None\n",
      "        le_12: \"Sym(True)\" = add_48 <= 2;  le_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_13 = l_inference_params_key_value_memory_dict_6_0_.size()\n",
      "        getitem_238 = size_13[0];  getitem_238 = None\n",
      "        getitem_239: \"Sym(s5)\" = size_13[1]\n",
      "        getitem_240 = size_13[2];  getitem_240 = None\n",
      "        getitem_241: \"Sym(s6)\" = size_13[3];  getitem_241 = None\n",
      "        getitem_242 = size_13[4];  size_13 = getitem_242 = None\n",
      "        le_13: \"Sym(s9 + 1 <= s5)\" = add_49 <= getitem_239;  getitem_239 = le_13 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_6_0_[(slice(l_inference_params_batch_size_offset, add_48, None), slice(l_inference_params_seqlen_offset, add_49, None), 0, Ellipsis)] = k_32;  setitem_12 = l_inference_params_key_value_memory_dict_6_0_;  k_32 = setitem_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_6_0_[(slice(l_inference_params_batch_size_offset, add_48, None), slice(l_inference_params_seqlen_offset, add_49, None), 1, Ellipsis)] = v_25;  setitem_13 = l_inference_params_key_value_memory_dict_6_0_;  v_25 = setitem_13 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_6: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_6_0_[(slice(l_inference_params_batch_size_offset, add_48, None), slice(None, add_49, None), Ellipsis)];  l_inference_params_key_value_memory_dict_6_0_ = add_48 = add_49 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_6 = kv_6.unbind(dim = -3);  kv_6 = None\n",
      "        k_33: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_6[0]\n",
      "        v_26: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_6[1];  unbind_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_27: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_26.transpose(1, 2);  q_26 = None\n",
      "        k_34: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_33.transpose(1, 2);  k_33 = None\n",
      "        v_27: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_26.transpose(1, 2);  v_26 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_24: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_27, k_34, v_27, is_causal = False, enable_gqa = True);  q_27 = k_34 = v_27 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_27: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_24.transpose(1, 2);  y_24 = None\n",
      "        contiguous_6: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_27.contiguous();  transpose_27 = None\n",
      "        y_25: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_6.view(2, 1, 2048);  contiguous_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_26: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_25, l_self_modules_backbone_modules_layers_modules_6_modules_mixer_modules_out_proj_parameters_weight_, None);  y_25 = l_self_modules_backbone_modules_layers_modules_6_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_12: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_11 + y_26;  x_11 = y_26 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_13: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_12, (2048,), l_self_modules_backbone_modules_layers_modules_6_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_6_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_6_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_6_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_26: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_13, l_self_modules_backbone_modules_layers_modules_6_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_13 = l_self_modules_backbone_modules_layers_modules_6_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_6 = linear_26.chunk(2, dim = -1);  linear_26 = None\n",
      "        y_27: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_6[0]\n",
      "        gate_6: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_6[1];  chunk_6 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_6: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_6);  gate_6 = None\n",
      "        mul_62: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_27 * silu_6;  y_27 = silu_6 = None\n",
      "        linear_27: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_62, l_self_modules_backbone_modules_layers_modules_6_modules_mlp_modules_fc2_parameters_weight_, None);  mul_62 = l_self_modules_backbone_modules_layers_modules_6_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_13: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_12 + linear_27;  x_12 = linear_27 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_14: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_13, (2048,), l_self_modules_backbone_modules_layers_modules_7_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_7_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_7_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_7_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_28: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_14, l_self_modules_backbone_modules_layers_modules_7_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_14 = l_self_modules_backbone_modules_layers_modules_7_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_7 = linear_28.split([2048, 512, 512], dim = -1);  linear_28 = None\n",
      "        q_28: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_7[0]\n",
      "        k_35: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_7[1]\n",
      "        v_28: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_7[2];  split_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_29: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_28.view(2, 1, 16, 128);  q_28 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_36: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_35.view(2, 1, 4, 128);  k_35 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_29: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_28.view(2, 1, 4, 128);  v_28 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_15: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_29.float()\n",
      "        xshaped_14: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_15.reshape(2, 1, 16, -1, 2);  float_15 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_15: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_251: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_14[(Ellipsis, 0)]\n",
      "        getitem_252: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_15[(Ellipsis, 0)]\n",
      "        mul_63: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_251 * getitem_252;  getitem_251 = getitem_252 = None\n",
      "        getitem_253: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_14[(Ellipsis, 1)]\n",
      "        getitem_254: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_15[(Ellipsis, 1)]\n",
      "        mul_64: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_253 * getitem_254;  getitem_253 = getitem_254 = None\n",
      "        sub_14: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_63 - mul_64;  mul_63 = mul_64 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_255: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_14[(Ellipsis, 1)]\n",
      "        getitem_256: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_15[(Ellipsis, 0)]\n",
      "        mul_65: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_255 * getitem_256;  getitem_255 = getitem_256 = None\n",
      "        getitem_257: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_14[(Ellipsis, 0)];  xshaped_14 = None\n",
      "        getitem_258: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_15[(Ellipsis, 1)];  freqs_cis_15 = None\n",
      "        mul_66: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_257 * getitem_258;  getitem_257 = getitem_258 = None\n",
      "        add_52: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_65 + mul_66;  mul_65 = mul_66 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_28: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_14, add_52], -1);  sub_14 = add_52 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_29: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_28.flatten(3);  x_out2_28 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_30: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_29.type_as(q_29);  x_out2_29 = q_29 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_16: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_36.float()\n",
      "        xshaped_15: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_16.reshape(2, 1, 4, -1, 2);  float_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_16: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_259: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_15[(Ellipsis, 0)]\n",
      "        getitem_260: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_16[(Ellipsis, 0)]\n",
      "        mul_67: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_259 * getitem_260;  getitem_259 = getitem_260 = None\n",
      "        getitem_261: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_15[(Ellipsis, 1)]\n",
      "        getitem_262: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_16[(Ellipsis, 1)]\n",
      "        mul_68: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_261 * getitem_262;  getitem_261 = getitem_262 = None\n",
      "        sub_15: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_67 - mul_68;  mul_67 = mul_68 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_263: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_15[(Ellipsis, 1)]\n",
      "        getitem_264: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_16[(Ellipsis, 0)]\n",
      "        mul_69: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_263 * getitem_264;  getitem_263 = getitem_264 = None\n",
      "        getitem_265: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_15[(Ellipsis, 0)];  xshaped_15 = None\n",
      "        getitem_266: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_16[(Ellipsis, 1)];  freqs_cis_16 = None\n",
      "        mul_70: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_265 * getitem_266;  getitem_265 = getitem_266 = None\n",
      "        add_53: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_69 + mul_70;  mul_69 = mul_70 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_30: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_15, add_53], -1);  sub_15 = add_53 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_31: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_30.flatten(3);  x_out2_30 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_37: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_31.type_as(k_36);  x_out2_31 = k_36 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_54: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_55: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_14 = l_inference_params_key_value_memory_dict_7_0_.size()\n",
      "        getitem_267 = size_14[0];  getitem_267 = None\n",
      "        getitem_268: \"Sym(s5)\" = size_14[1];  getitem_268 = None\n",
      "        getitem_269 = size_14[2];  getitem_269 = None\n",
      "        getitem_270: \"Sym(s6)\" = size_14[3];  getitem_270 = None\n",
      "        getitem_271 = size_14[4];  size_14 = getitem_271 = None\n",
      "        le_14: \"Sym(True)\" = add_54 <= 2;  le_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_15 = l_inference_params_key_value_memory_dict_7_0_.size()\n",
      "        getitem_272 = size_15[0];  getitem_272 = None\n",
      "        getitem_273: \"Sym(s5)\" = size_15[1]\n",
      "        getitem_274 = size_15[2];  getitem_274 = None\n",
      "        getitem_275: \"Sym(s6)\" = size_15[3];  getitem_275 = None\n",
      "        getitem_276 = size_15[4];  size_15 = getitem_276 = None\n",
      "        le_15: \"Sym(s9 + 1 <= s5)\" = add_55 <= getitem_273;  getitem_273 = le_15 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_7_0_[(slice(l_inference_params_batch_size_offset, add_54, None), slice(l_inference_params_seqlen_offset, add_55, None), 0, Ellipsis)] = k_37;  setitem_14 = l_inference_params_key_value_memory_dict_7_0_;  k_37 = setitem_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_7_0_[(slice(l_inference_params_batch_size_offset, add_54, None), slice(l_inference_params_seqlen_offset, add_55, None), 1, Ellipsis)] = v_29;  setitem_15 = l_inference_params_key_value_memory_dict_7_0_;  v_29 = setitem_15 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_7: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_7_0_[(slice(l_inference_params_batch_size_offset, add_54, None), slice(None, add_55, None), Ellipsis)];  l_inference_params_key_value_memory_dict_7_0_ = add_54 = add_55 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_7 = kv_7.unbind(dim = -3);  kv_7 = None\n",
      "        k_38: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_7[0]\n",
      "        v_30: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_7[1];  unbind_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_31: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_30.transpose(1, 2);  q_30 = None\n",
      "        k_39: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_38.transpose(1, 2);  k_38 = None\n",
      "        v_31: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_30.transpose(1, 2);  v_30 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_28: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_31, k_39, v_31, is_causal = False, enable_gqa = True);  q_31 = k_39 = v_31 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_31: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_28.transpose(1, 2);  y_28 = None\n",
      "        contiguous_7: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_31.contiguous();  transpose_31 = None\n",
      "        y_29: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_7.view(2, 1, 2048);  contiguous_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_30: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_29, l_self_modules_backbone_modules_layers_modules_7_modules_mixer_modules_out_proj_parameters_weight_, None);  y_29 = l_self_modules_backbone_modules_layers_modules_7_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_14: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_13 + y_30;  x_13 = y_30 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_15: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_14, (2048,), l_self_modules_backbone_modules_layers_modules_7_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_7_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_7_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_7_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_30: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_15, l_self_modules_backbone_modules_layers_modules_7_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_15 = l_self_modules_backbone_modules_layers_modules_7_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_7 = linear_30.chunk(2, dim = -1);  linear_30 = None\n",
      "        y_31: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_7[0]\n",
      "        gate_7: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_7[1];  chunk_7 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_7: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_7);  gate_7 = None\n",
      "        mul_71: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_31 * silu_7;  y_31 = silu_7 = None\n",
      "        linear_31: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_71, l_self_modules_backbone_modules_layers_modules_7_modules_mlp_modules_fc2_parameters_weight_, None);  mul_71 = l_self_modules_backbone_modules_layers_modules_7_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_15: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_14 + linear_31;  x_14 = linear_31 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_16: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_15, (2048,), l_self_modules_backbone_modules_layers_modules_8_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_8_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_8_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_8_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_32: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_16, l_self_modules_backbone_modules_layers_modules_8_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_16 = l_self_modules_backbone_modules_layers_modules_8_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_8 = linear_32.split([2048, 512, 512], dim = -1);  linear_32 = None\n",
      "        q_32: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_8[0]\n",
      "        k_40: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_8[1]\n",
      "        v_32: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_8[2];  split_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_33: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_32.view(2, 1, 16, 128);  q_32 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_41: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_40.view(2, 1, 4, 128);  k_40 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_33: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_32.view(2, 1, 4, 128);  v_32 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_17: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_33.float()\n",
      "        xshaped_16: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_17.reshape(2, 1, 16, -1, 2);  float_17 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_17: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_285: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_16[(Ellipsis, 0)]\n",
      "        getitem_286: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_17[(Ellipsis, 0)]\n",
      "        mul_72: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_285 * getitem_286;  getitem_285 = getitem_286 = None\n",
      "        getitem_287: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_16[(Ellipsis, 1)]\n",
      "        getitem_288: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_17[(Ellipsis, 1)]\n",
      "        mul_73: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_287 * getitem_288;  getitem_287 = getitem_288 = None\n",
      "        sub_16: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_72 - mul_73;  mul_72 = mul_73 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_289: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_16[(Ellipsis, 1)]\n",
      "        getitem_290: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_17[(Ellipsis, 0)]\n",
      "        mul_74: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_289 * getitem_290;  getitem_289 = getitem_290 = None\n",
      "        getitem_291: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_16[(Ellipsis, 0)];  xshaped_16 = None\n",
      "        getitem_292: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_17[(Ellipsis, 1)];  freqs_cis_17 = None\n",
      "        mul_75: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_291 * getitem_292;  getitem_291 = getitem_292 = None\n",
      "        add_58: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_74 + mul_75;  mul_74 = mul_75 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_32: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_16, add_58], -1);  sub_16 = add_58 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_33: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_32.flatten(3);  x_out2_32 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_34: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_33.type_as(q_33);  x_out2_33 = q_33 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_18: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_41.float()\n",
      "        xshaped_17: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_18.reshape(2, 1, 4, -1, 2);  float_18 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_18: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_293: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_17[(Ellipsis, 0)]\n",
      "        getitem_294: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_18[(Ellipsis, 0)]\n",
      "        mul_76: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_293 * getitem_294;  getitem_293 = getitem_294 = None\n",
      "        getitem_295: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_17[(Ellipsis, 1)]\n",
      "        getitem_296: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_18[(Ellipsis, 1)]\n",
      "        mul_77: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_295 * getitem_296;  getitem_295 = getitem_296 = None\n",
      "        sub_17: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_76 - mul_77;  mul_76 = mul_77 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_297: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_17[(Ellipsis, 1)]\n",
      "        getitem_298: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_18[(Ellipsis, 0)]\n",
      "        mul_78: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_297 * getitem_298;  getitem_297 = getitem_298 = None\n",
      "        getitem_299: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_17[(Ellipsis, 0)];  xshaped_17 = None\n",
      "        getitem_300: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_18[(Ellipsis, 1)];  freqs_cis_18 = None\n",
      "        mul_79: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_299 * getitem_300;  getitem_299 = getitem_300 = None\n",
      "        add_59: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_78 + mul_79;  mul_78 = mul_79 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_34: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_17, add_59], -1);  sub_17 = add_59 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_35: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_34.flatten(3);  x_out2_34 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_42: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_35.type_as(k_41);  x_out2_35 = k_41 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_60: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_61: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_16 = l_inference_params_key_value_memory_dict_8_0_.size()\n",
      "        getitem_301 = size_16[0];  getitem_301 = None\n",
      "        getitem_302: \"Sym(s5)\" = size_16[1];  getitem_302 = None\n",
      "        getitem_303 = size_16[2];  getitem_303 = None\n",
      "        getitem_304: \"Sym(s6)\" = size_16[3];  getitem_304 = None\n",
      "        getitem_305 = size_16[4];  size_16 = getitem_305 = None\n",
      "        le_16: \"Sym(True)\" = add_60 <= 2;  le_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_17 = l_inference_params_key_value_memory_dict_8_0_.size()\n",
      "        getitem_306 = size_17[0];  getitem_306 = None\n",
      "        getitem_307: \"Sym(s5)\" = size_17[1]\n",
      "        getitem_308 = size_17[2];  getitem_308 = None\n",
      "        getitem_309: \"Sym(s6)\" = size_17[3];  getitem_309 = None\n",
      "        getitem_310 = size_17[4];  size_17 = getitem_310 = None\n",
      "        le_17: \"Sym(s9 + 1 <= s5)\" = add_61 <= getitem_307;  getitem_307 = le_17 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_8_0_[(slice(l_inference_params_batch_size_offset, add_60, None), slice(l_inference_params_seqlen_offset, add_61, None), 0, Ellipsis)] = k_42;  setitem_16 = l_inference_params_key_value_memory_dict_8_0_;  k_42 = setitem_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_8_0_[(slice(l_inference_params_batch_size_offset, add_60, None), slice(l_inference_params_seqlen_offset, add_61, None), 1, Ellipsis)] = v_33;  setitem_17 = l_inference_params_key_value_memory_dict_8_0_;  v_33 = setitem_17 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_8: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_8_0_[(slice(l_inference_params_batch_size_offset, add_60, None), slice(None, add_61, None), Ellipsis)];  l_inference_params_key_value_memory_dict_8_0_ = add_60 = add_61 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_8 = kv_8.unbind(dim = -3);  kv_8 = None\n",
      "        k_43: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_8[0]\n",
      "        v_34: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_8[1];  unbind_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_35: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_34.transpose(1, 2);  q_34 = None\n",
      "        k_44: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_43.transpose(1, 2);  k_43 = None\n",
      "        v_35: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_34.transpose(1, 2);  v_34 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_32: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_35, k_44, v_35, is_causal = False, enable_gqa = True);  q_35 = k_44 = v_35 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_35: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_32.transpose(1, 2);  y_32 = None\n",
      "        contiguous_8: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_35.contiguous();  transpose_35 = None\n",
      "        y_33: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_8.view(2, 1, 2048);  contiguous_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_34: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_33, l_self_modules_backbone_modules_layers_modules_8_modules_mixer_modules_out_proj_parameters_weight_, None);  y_33 = l_self_modules_backbone_modules_layers_modules_8_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_16: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_15 + y_34;  x_15 = y_34 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_17: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_16, (2048,), l_self_modules_backbone_modules_layers_modules_8_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_8_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_8_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_8_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_34: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_17, l_self_modules_backbone_modules_layers_modules_8_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_17 = l_self_modules_backbone_modules_layers_modules_8_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_8 = linear_34.chunk(2, dim = -1);  linear_34 = None\n",
      "        y_35: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_8[0]\n",
      "        gate_8: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_8[1];  chunk_8 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_8: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_8);  gate_8 = None\n",
      "        mul_80: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_35 * silu_8;  y_35 = silu_8 = None\n",
      "        linear_35: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_80, l_self_modules_backbone_modules_layers_modules_8_modules_mlp_modules_fc2_parameters_weight_, None);  mul_80 = l_self_modules_backbone_modules_layers_modules_8_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_17: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_16 + linear_35;  x_16 = linear_35 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_18: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_17, (2048,), l_self_modules_backbone_modules_layers_modules_9_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_9_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_9_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_9_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_36: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_18, l_self_modules_backbone_modules_layers_modules_9_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_18 = l_self_modules_backbone_modules_layers_modules_9_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_9 = linear_36.split([2048, 512, 512], dim = -1);  linear_36 = None\n",
      "        q_36: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_9[0]\n",
      "        k_45: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_9[1]\n",
      "        v_36: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_9[2];  split_9 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_37: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_36.view(2, 1, 16, 128);  q_36 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_46: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_45.view(2, 1, 4, 128);  k_45 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_37: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_36.view(2, 1, 4, 128);  v_36 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_19: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_37.float()\n",
      "        xshaped_18: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_19.reshape(2, 1, 16, -1, 2);  float_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_19: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_319: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_18[(Ellipsis, 0)]\n",
      "        getitem_320: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_19[(Ellipsis, 0)]\n",
      "        mul_81: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_319 * getitem_320;  getitem_319 = getitem_320 = None\n",
      "        getitem_321: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_18[(Ellipsis, 1)]\n",
      "        getitem_322: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_19[(Ellipsis, 1)]\n",
      "        mul_82: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_321 * getitem_322;  getitem_321 = getitem_322 = None\n",
      "        sub_18: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_81 - mul_82;  mul_81 = mul_82 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_323: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_18[(Ellipsis, 1)]\n",
      "        getitem_324: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_19[(Ellipsis, 0)]\n",
      "        mul_83: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_323 * getitem_324;  getitem_323 = getitem_324 = None\n",
      "        getitem_325: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_18[(Ellipsis, 0)];  xshaped_18 = None\n",
      "        getitem_326: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_19[(Ellipsis, 1)];  freqs_cis_19 = None\n",
      "        mul_84: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_325 * getitem_326;  getitem_325 = getitem_326 = None\n",
      "        add_64: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_83 + mul_84;  mul_83 = mul_84 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_36: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_18, add_64], -1);  sub_18 = add_64 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_37: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_36.flatten(3);  x_out2_36 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_38: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_37.type_as(q_37);  x_out2_37 = q_37 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_20: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_46.float()\n",
      "        xshaped_19: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_20.reshape(2, 1, 4, -1, 2);  float_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_20: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_327: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_19[(Ellipsis, 0)]\n",
      "        getitem_328: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_20[(Ellipsis, 0)]\n",
      "        mul_85: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_327 * getitem_328;  getitem_327 = getitem_328 = None\n",
      "        getitem_329: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_19[(Ellipsis, 1)]\n",
      "        getitem_330: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_20[(Ellipsis, 1)]\n",
      "        mul_86: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_329 * getitem_330;  getitem_329 = getitem_330 = None\n",
      "        sub_19: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_85 - mul_86;  mul_85 = mul_86 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_331: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_19[(Ellipsis, 1)]\n",
      "        getitem_332: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_20[(Ellipsis, 0)]\n",
      "        mul_87: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_331 * getitem_332;  getitem_331 = getitem_332 = None\n",
      "        getitem_333: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_19[(Ellipsis, 0)];  xshaped_19 = None\n",
      "        getitem_334: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_20[(Ellipsis, 1)];  freqs_cis_20 = None\n",
      "        mul_88: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_333 * getitem_334;  getitem_333 = getitem_334 = None\n",
      "        add_65: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_87 + mul_88;  mul_87 = mul_88 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_38: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_19, add_65], -1);  sub_19 = add_65 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_39: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_38.flatten(3);  x_out2_38 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_47: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_39.type_as(k_46);  x_out2_39 = k_46 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_66: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_67: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_18 = l_inference_params_key_value_memory_dict_9_0_.size()\n",
      "        getitem_335 = size_18[0];  getitem_335 = None\n",
      "        getitem_336: \"Sym(s5)\" = size_18[1];  getitem_336 = None\n",
      "        getitem_337 = size_18[2];  getitem_337 = None\n",
      "        getitem_338: \"Sym(s6)\" = size_18[3];  getitem_338 = None\n",
      "        getitem_339 = size_18[4];  size_18 = getitem_339 = None\n",
      "        le_18: \"Sym(True)\" = add_66 <= 2;  le_18 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_19 = l_inference_params_key_value_memory_dict_9_0_.size()\n",
      "        getitem_340 = size_19[0];  getitem_340 = None\n",
      "        getitem_341: \"Sym(s5)\" = size_19[1]\n",
      "        getitem_342 = size_19[2];  getitem_342 = None\n",
      "        getitem_343: \"Sym(s6)\" = size_19[3];  getitem_343 = None\n",
      "        getitem_344 = size_19[4];  size_19 = getitem_344 = None\n",
      "        le_19: \"Sym(s9 + 1 <= s5)\" = add_67 <= getitem_341;  getitem_341 = le_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_9_0_[(slice(l_inference_params_batch_size_offset, add_66, None), slice(l_inference_params_seqlen_offset, add_67, None), 0, Ellipsis)] = k_47;  setitem_18 = l_inference_params_key_value_memory_dict_9_0_;  k_47 = setitem_18 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_9_0_[(slice(l_inference_params_batch_size_offset, add_66, None), slice(l_inference_params_seqlen_offset, add_67, None), 1, Ellipsis)] = v_37;  setitem_19 = l_inference_params_key_value_memory_dict_9_0_;  v_37 = setitem_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_9: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_9_0_[(slice(l_inference_params_batch_size_offset, add_66, None), slice(None, add_67, None), Ellipsis)];  l_inference_params_key_value_memory_dict_9_0_ = add_66 = add_67 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_9 = kv_9.unbind(dim = -3);  kv_9 = None\n",
      "        k_48: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_9[0]\n",
      "        v_38: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_9[1];  unbind_9 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_39: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_38.transpose(1, 2);  q_38 = None\n",
      "        k_49: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_48.transpose(1, 2);  k_48 = None\n",
      "        v_39: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_38.transpose(1, 2);  v_38 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_36: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_39, k_49, v_39, is_causal = False, enable_gqa = True);  q_39 = k_49 = v_39 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_39: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_36.transpose(1, 2);  y_36 = None\n",
      "        contiguous_9: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_39.contiguous();  transpose_39 = None\n",
      "        y_37: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_9.view(2, 1, 2048);  contiguous_9 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_38: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_37, l_self_modules_backbone_modules_layers_modules_9_modules_mixer_modules_out_proj_parameters_weight_, None);  y_37 = l_self_modules_backbone_modules_layers_modules_9_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_18: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_17 + y_38;  x_17 = y_38 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_19: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_18, (2048,), l_self_modules_backbone_modules_layers_modules_9_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_9_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_9_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_9_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_38: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_19, l_self_modules_backbone_modules_layers_modules_9_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_19 = l_self_modules_backbone_modules_layers_modules_9_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_9 = linear_38.chunk(2, dim = -1);  linear_38 = None\n",
      "        y_39: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_9[0]\n",
      "        gate_9: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_9[1];  chunk_9 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_9: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_9);  gate_9 = None\n",
      "        mul_89: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_39 * silu_9;  y_39 = silu_9 = None\n",
      "        linear_39: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_89, l_self_modules_backbone_modules_layers_modules_9_modules_mlp_modules_fc2_parameters_weight_, None);  mul_89 = l_self_modules_backbone_modules_layers_modules_9_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_19: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_18 + linear_39;  x_18 = linear_39 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_20: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_19, (2048,), l_self_modules_backbone_modules_layers_modules_10_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_10_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_10_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_10_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_40: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_20, l_self_modules_backbone_modules_layers_modules_10_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_20 = l_self_modules_backbone_modules_layers_modules_10_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_10 = linear_40.split([2048, 512, 512], dim = -1);  linear_40 = None\n",
      "        q_40: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_10[0]\n",
      "        k_50: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_10[1]\n",
      "        v_40: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_10[2];  split_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_41: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_40.view(2, 1, 16, 128);  q_40 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_51: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_50.view(2, 1, 4, 128);  k_50 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_41: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_40.view(2, 1, 4, 128);  v_40 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_21: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_41.float()\n",
      "        xshaped_20: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_21.reshape(2, 1, 16, -1, 2);  float_21 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_21: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_353: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_20[(Ellipsis, 0)]\n",
      "        getitem_354: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_21[(Ellipsis, 0)]\n",
      "        mul_90: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_353 * getitem_354;  getitem_353 = getitem_354 = None\n",
      "        getitem_355: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_20[(Ellipsis, 1)]\n",
      "        getitem_356: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_21[(Ellipsis, 1)]\n",
      "        mul_91: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_355 * getitem_356;  getitem_355 = getitem_356 = None\n",
      "        sub_20: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_90 - mul_91;  mul_90 = mul_91 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_357: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_20[(Ellipsis, 1)]\n",
      "        getitem_358: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_21[(Ellipsis, 0)]\n",
      "        mul_92: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_357 * getitem_358;  getitem_357 = getitem_358 = None\n",
      "        getitem_359: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_20[(Ellipsis, 0)];  xshaped_20 = None\n",
      "        getitem_360: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_21[(Ellipsis, 1)];  freqs_cis_21 = None\n",
      "        mul_93: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_359 * getitem_360;  getitem_359 = getitem_360 = None\n",
      "        add_70: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_92 + mul_93;  mul_92 = mul_93 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_40: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_20, add_70], -1);  sub_20 = add_70 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_41: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_40.flatten(3);  x_out2_40 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_42: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_41.type_as(q_41);  x_out2_41 = q_41 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_22: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_51.float()\n",
      "        xshaped_21: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_22.reshape(2, 1, 4, -1, 2);  float_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_22: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_361: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_21[(Ellipsis, 0)]\n",
      "        getitem_362: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_22[(Ellipsis, 0)]\n",
      "        mul_94: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_361 * getitem_362;  getitem_361 = getitem_362 = None\n",
      "        getitem_363: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_21[(Ellipsis, 1)]\n",
      "        getitem_364: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_22[(Ellipsis, 1)]\n",
      "        mul_95: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_363 * getitem_364;  getitem_363 = getitem_364 = None\n",
      "        sub_21: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_94 - mul_95;  mul_94 = mul_95 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_365: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_21[(Ellipsis, 1)]\n",
      "        getitem_366: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_22[(Ellipsis, 0)]\n",
      "        mul_96: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_365 * getitem_366;  getitem_365 = getitem_366 = None\n",
      "        getitem_367: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_21[(Ellipsis, 0)];  xshaped_21 = None\n",
      "        getitem_368: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_22[(Ellipsis, 1)];  freqs_cis_22 = None\n",
      "        mul_97: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_367 * getitem_368;  getitem_367 = getitem_368 = None\n",
      "        add_71: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_96 + mul_97;  mul_96 = mul_97 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_42: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_21, add_71], -1);  sub_21 = add_71 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_43: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_42.flatten(3);  x_out2_42 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_52: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_43.type_as(k_51);  x_out2_43 = k_51 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_72: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_73: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_20 = l_inference_params_key_value_memory_dict_10_0_.size()\n",
      "        getitem_369 = size_20[0];  getitem_369 = None\n",
      "        getitem_370: \"Sym(s5)\" = size_20[1];  getitem_370 = None\n",
      "        getitem_371 = size_20[2];  getitem_371 = None\n",
      "        getitem_372: \"Sym(s6)\" = size_20[3];  getitem_372 = None\n",
      "        getitem_373 = size_20[4];  size_20 = getitem_373 = None\n",
      "        le_20: \"Sym(True)\" = add_72 <= 2;  le_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_21 = l_inference_params_key_value_memory_dict_10_0_.size()\n",
      "        getitem_374 = size_21[0];  getitem_374 = None\n",
      "        getitem_375: \"Sym(s5)\" = size_21[1]\n",
      "        getitem_376 = size_21[2];  getitem_376 = None\n",
      "        getitem_377: \"Sym(s6)\" = size_21[3];  getitem_377 = None\n",
      "        getitem_378 = size_21[4];  size_21 = getitem_378 = None\n",
      "        le_21: \"Sym(s9 + 1 <= s5)\" = add_73 <= getitem_375;  getitem_375 = le_21 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_10_0_[(slice(l_inference_params_batch_size_offset, add_72, None), slice(l_inference_params_seqlen_offset, add_73, None), 0, Ellipsis)] = k_52;  setitem_20 = l_inference_params_key_value_memory_dict_10_0_;  k_52 = setitem_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_10_0_[(slice(l_inference_params_batch_size_offset, add_72, None), slice(l_inference_params_seqlen_offset, add_73, None), 1, Ellipsis)] = v_41;  setitem_21 = l_inference_params_key_value_memory_dict_10_0_;  v_41 = setitem_21 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_10: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_10_0_[(slice(l_inference_params_batch_size_offset, add_72, None), slice(None, add_73, None), Ellipsis)];  l_inference_params_key_value_memory_dict_10_0_ = add_72 = add_73 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_10 = kv_10.unbind(dim = -3);  kv_10 = None\n",
      "        k_53: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_10[0]\n",
      "        v_42: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_10[1];  unbind_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_43: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_42.transpose(1, 2);  q_42 = None\n",
      "        k_54: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_53.transpose(1, 2);  k_53 = None\n",
      "        v_43: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_42.transpose(1, 2);  v_42 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_40: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_43, k_54, v_43, is_causal = False, enable_gqa = True);  q_43 = k_54 = v_43 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_43: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_40.transpose(1, 2);  y_40 = None\n",
      "        contiguous_10: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_43.contiguous();  transpose_43 = None\n",
      "        y_41: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_10.view(2, 1, 2048);  contiguous_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_42: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_41, l_self_modules_backbone_modules_layers_modules_10_modules_mixer_modules_out_proj_parameters_weight_, None);  y_41 = l_self_modules_backbone_modules_layers_modules_10_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_20: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_19 + y_42;  x_19 = y_42 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_21: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_20, (2048,), l_self_modules_backbone_modules_layers_modules_10_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_10_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_10_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_10_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_42: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_21, l_self_modules_backbone_modules_layers_modules_10_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_21 = l_self_modules_backbone_modules_layers_modules_10_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_10 = linear_42.chunk(2, dim = -1);  linear_42 = None\n",
      "        y_43: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_10[0]\n",
      "        gate_10: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_10[1];  chunk_10 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_10: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_10);  gate_10 = None\n",
      "        mul_98: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_43 * silu_10;  y_43 = silu_10 = None\n",
      "        linear_43: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_98, l_self_modules_backbone_modules_layers_modules_10_modules_mlp_modules_fc2_parameters_weight_, None);  mul_98 = l_self_modules_backbone_modules_layers_modules_10_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_21: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_20 + linear_43;  x_20 = linear_43 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_22: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_21, (2048,), l_self_modules_backbone_modules_layers_modules_11_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_11_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_11_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_11_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_44: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_22, l_self_modules_backbone_modules_layers_modules_11_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_22 = l_self_modules_backbone_modules_layers_modules_11_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_11 = linear_44.split([2048, 512, 512], dim = -1);  linear_44 = None\n",
      "        q_44: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_11[0]\n",
      "        k_55: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_11[1]\n",
      "        v_44: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_11[2];  split_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_45: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_44.view(2, 1, 16, 128);  q_44 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_56: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_55.view(2, 1, 4, 128);  k_55 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_45: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_44.view(2, 1, 4, 128);  v_44 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_23: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_45.float()\n",
      "        xshaped_22: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_23.reshape(2, 1, 16, -1, 2);  float_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_23: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_387: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_22[(Ellipsis, 0)]\n",
      "        getitem_388: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_23[(Ellipsis, 0)]\n",
      "        mul_99: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_387 * getitem_388;  getitem_387 = getitem_388 = None\n",
      "        getitem_389: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_22[(Ellipsis, 1)]\n",
      "        getitem_390: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_23[(Ellipsis, 1)]\n",
      "        mul_100: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_389 * getitem_390;  getitem_389 = getitem_390 = None\n",
      "        sub_22: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_99 - mul_100;  mul_99 = mul_100 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_391: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_22[(Ellipsis, 1)]\n",
      "        getitem_392: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_23[(Ellipsis, 0)]\n",
      "        mul_101: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_391 * getitem_392;  getitem_391 = getitem_392 = None\n",
      "        getitem_393: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_22[(Ellipsis, 0)];  xshaped_22 = None\n",
      "        getitem_394: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_23[(Ellipsis, 1)];  freqs_cis_23 = None\n",
      "        mul_102: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_393 * getitem_394;  getitem_393 = getitem_394 = None\n",
      "        add_76: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_101 + mul_102;  mul_101 = mul_102 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_44: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_22, add_76], -1);  sub_22 = add_76 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_45: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_44.flatten(3);  x_out2_44 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_46: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_45.type_as(q_45);  x_out2_45 = q_45 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_24: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_56.float()\n",
      "        xshaped_23: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_24.reshape(2, 1, 4, -1, 2);  float_24 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_24: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_395: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_23[(Ellipsis, 0)]\n",
      "        getitem_396: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_24[(Ellipsis, 0)]\n",
      "        mul_103: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_395 * getitem_396;  getitem_395 = getitem_396 = None\n",
      "        getitem_397: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_23[(Ellipsis, 1)]\n",
      "        getitem_398: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_24[(Ellipsis, 1)]\n",
      "        mul_104: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_397 * getitem_398;  getitem_397 = getitem_398 = None\n",
      "        sub_23: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_103 - mul_104;  mul_103 = mul_104 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_399: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_23[(Ellipsis, 1)]\n",
      "        getitem_400: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_24[(Ellipsis, 0)]\n",
      "        mul_105: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_399 * getitem_400;  getitem_399 = getitem_400 = None\n",
      "        getitem_401: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_23[(Ellipsis, 0)];  xshaped_23 = None\n",
      "        getitem_402: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_24[(Ellipsis, 1)];  freqs_cis_24 = None\n",
      "        mul_106: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_401 * getitem_402;  getitem_401 = getitem_402 = None\n",
      "        add_77: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_105 + mul_106;  mul_105 = mul_106 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_46: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_23, add_77], -1);  sub_23 = add_77 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_47: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_46.flatten(3);  x_out2_46 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_57: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_47.type_as(k_56);  x_out2_47 = k_56 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_78: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_79: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_22 = l_inference_params_key_value_memory_dict_11_0_.size()\n",
      "        getitem_403 = size_22[0];  getitem_403 = None\n",
      "        getitem_404: \"Sym(s5)\" = size_22[1];  getitem_404 = None\n",
      "        getitem_405 = size_22[2];  getitem_405 = None\n",
      "        getitem_406: \"Sym(s6)\" = size_22[3];  getitem_406 = None\n",
      "        getitem_407 = size_22[4];  size_22 = getitem_407 = None\n",
      "        le_22: \"Sym(True)\" = add_78 <= 2;  le_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_23 = l_inference_params_key_value_memory_dict_11_0_.size()\n",
      "        getitem_408 = size_23[0];  getitem_408 = None\n",
      "        getitem_409: \"Sym(s5)\" = size_23[1]\n",
      "        getitem_410 = size_23[2];  getitem_410 = None\n",
      "        getitem_411: \"Sym(s6)\" = size_23[3];  getitem_411 = None\n",
      "        getitem_412 = size_23[4];  size_23 = getitem_412 = None\n",
      "        le_23: \"Sym(s9 + 1 <= s5)\" = add_79 <= getitem_409;  getitem_409 = le_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_11_0_[(slice(l_inference_params_batch_size_offset, add_78, None), slice(l_inference_params_seqlen_offset, add_79, None), 0, Ellipsis)] = k_57;  setitem_22 = l_inference_params_key_value_memory_dict_11_0_;  k_57 = setitem_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_11_0_[(slice(l_inference_params_batch_size_offset, add_78, None), slice(l_inference_params_seqlen_offset, add_79, None), 1, Ellipsis)] = v_45;  setitem_23 = l_inference_params_key_value_memory_dict_11_0_;  v_45 = setitem_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_11: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_11_0_[(slice(l_inference_params_batch_size_offset, add_78, None), slice(None, add_79, None), Ellipsis)];  l_inference_params_key_value_memory_dict_11_0_ = add_78 = add_79 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_11 = kv_11.unbind(dim = -3);  kv_11 = None\n",
      "        k_58: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_11[0]\n",
      "        v_46: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_11[1];  unbind_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_47: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_46.transpose(1, 2);  q_46 = None\n",
      "        k_59: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_58.transpose(1, 2);  k_58 = None\n",
      "        v_47: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_46.transpose(1, 2);  v_46 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_44: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_47, k_59, v_47, is_causal = False, enable_gqa = True);  q_47 = k_59 = v_47 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_47: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_44.transpose(1, 2);  y_44 = None\n",
      "        contiguous_11: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_47.contiguous();  transpose_47 = None\n",
      "        y_45: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_11.view(2, 1, 2048);  contiguous_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_46: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_45, l_self_modules_backbone_modules_layers_modules_11_modules_mixer_modules_out_proj_parameters_weight_, None);  y_45 = l_self_modules_backbone_modules_layers_modules_11_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_22: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_21 + y_46;  x_21 = y_46 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_23: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_22, (2048,), l_self_modules_backbone_modules_layers_modules_11_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_11_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_11_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_11_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_46: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_23, l_self_modules_backbone_modules_layers_modules_11_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_23 = l_self_modules_backbone_modules_layers_modules_11_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_11 = linear_46.chunk(2, dim = -1);  linear_46 = None\n",
      "        y_47: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_11[0]\n",
      "        gate_11: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_11[1];  chunk_11 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_11: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_11);  gate_11 = None\n",
      "        mul_107: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_47 * silu_11;  y_47 = silu_11 = None\n",
      "        linear_47: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_107, l_self_modules_backbone_modules_layers_modules_11_modules_mlp_modules_fc2_parameters_weight_, None);  mul_107 = l_self_modules_backbone_modules_layers_modules_11_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_23: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_22 + linear_47;  x_22 = linear_47 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_24: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_23, (2048,), l_self_modules_backbone_modules_layers_modules_12_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_12_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_12_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_12_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_48: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_24, l_self_modules_backbone_modules_layers_modules_12_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_24 = l_self_modules_backbone_modules_layers_modules_12_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_12 = linear_48.split([2048, 512, 512], dim = -1);  linear_48 = None\n",
      "        q_48: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_12[0]\n",
      "        k_60: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_12[1]\n",
      "        v_48: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_12[2];  split_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_49: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_48.view(2, 1, 16, 128);  q_48 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_61: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_60.view(2, 1, 4, 128);  k_60 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_49: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_48.view(2, 1, 4, 128);  v_48 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_25: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_49.float()\n",
      "        xshaped_24: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_25.reshape(2, 1, 16, -1, 2);  float_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_25: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_421: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_24[(Ellipsis, 0)]\n",
      "        getitem_422: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_25[(Ellipsis, 0)]\n",
      "        mul_108: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_421 * getitem_422;  getitem_421 = getitem_422 = None\n",
      "        getitem_423: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_24[(Ellipsis, 1)]\n",
      "        getitem_424: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_25[(Ellipsis, 1)]\n",
      "        mul_109: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_423 * getitem_424;  getitem_423 = getitem_424 = None\n",
      "        sub_24: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_108 - mul_109;  mul_108 = mul_109 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_425: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_24[(Ellipsis, 1)]\n",
      "        getitem_426: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_25[(Ellipsis, 0)]\n",
      "        mul_110: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_425 * getitem_426;  getitem_425 = getitem_426 = None\n",
      "        getitem_427: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_24[(Ellipsis, 0)];  xshaped_24 = None\n",
      "        getitem_428: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_25[(Ellipsis, 1)];  freqs_cis_25 = None\n",
      "        mul_111: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_427 * getitem_428;  getitem_427 = getitem_428 = None\n",
      "        add_82: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_110 + mul_111;  mul_110 = mul_111 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_48: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_24, add_82], -1);  sub_24 = add_82 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_49: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_48.flatten(3);  x_out2_48 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_50: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_49.type_as(q_49);  x_out2_49 = q_49 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_26: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_61.float()\n",
      "        xshaped_25: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_26.reshape(2, 1, 4, -1, 2);  float_26 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_26: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_429: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_25[(Ellipsis, 0)]\n",
      "        getitem_430: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_26[(Ellipsis, 0)]\n",
      "        mul_112: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_429 * getitem_430;  getitem_429 = getitem_430 = None\n",
      "        getitem_431: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_25[(Ellipsis, 1)]\n",
      "        getitem_432: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_26[(Ellipsis, 1)]\n",
      "        mul_113: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_431 * getitem_432;  getitem_431 = getitem_432 = None\n",
      "        sub_25: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_112 - mul_113;  mul_112 = mul_113 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_433: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_25[(Ellipsis, 1)]\n",
      "        getitem_434: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_26[(Ellipsis, 0)]\n",
      "        mul_114: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_433 * getitem_434;  getitem_433 = getitem_434 = None\n",
      "        getitem_435: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_25[(Ellipsis, 0)];  xshaped_25 = None\n",
      "        getitem_436: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_26[(Ellipsis, 1)];  freqs_cis_26 = None\n",
      "        mul_115: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_435 * getitem_436;  getitem_435 = getitem_436 = None\n",
      "        add_83: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_114 + mul_115;  mul_114 = mul_115 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_50: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_25, add_83], -1);  sub_25 = add_83 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_51: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_50.flatten(3);  x_out2_50 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_62: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_51.type_as(k_61);  x_out2_51 = k_61 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_84: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_85: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_24 = l_inference_params_key_value_memory_dict_12_0_.size()\n",
      "        getitem_437 = size_24[0];  getitem_437 = None\n",
      "        getitem_438: \"Sym(s5)\" = size_24[1];  getitem_438 = None\n",
      "        getitem_439 = size_24[2];  getitem_439 = None\n",
      "        getitem_440: \"Sym(s6)\" = size_24[3];  getitem_440 = None\n",
      "        getitem_441 = size_24[4];  size_24 = getitem_441 = None\n",
      "        le_24: \"Sym(True)\" = add_84 <= 2;  le_24 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_25 = l_inference_params_key_value_memory_dict_12_0_.size()\n",
      "        getitem_442 = size_25[0];  getitem_442 = None\n",
      "        getitem_443: \"Sym(s5)\" = size_25[1]\n",
      "        getitem_444 = size_25[2];  getitem_444 = None\n",
      "        getitem_445: \"Sym(s6)\" = size_25[3];  getitem_445 = None\n",
      "        getitem_446 = size_25[4];  size_25 = getitem_446 = None\n",
      "        le_25: \"Sym(s9 + 1 <= s5)\" = add_85 <= getitem_443;  getitem_443 = le_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_12_0_[(slice(l_inference_params_batch_size_offset, add_84, None), slice(l_inference_params_seqlen_offset, add_85, None), 0, Ellipsis)] = k_62;  setitem_24 = l_inference_params_key_value_memory_dict_12_0_;  k_62 = setitem_24 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_12_0_[(slice(l_inference_params_batch_size_offset, add_84, None), slice(l_inference_params_seqlen_offset, add_85, None), 1, Ellipsis)] = v_49;  setitem_25 = l_inference_params_key_value_memory_dict_12_0_;  v_49 = setitem_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_12: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_12_0_[(slice(l_inference_params_batch_size_offset, add_84, None), slice(None, add_85, None), Ellipsis)];  l_inference_params_key_value_memory_dict_12_0_ = add_84 = add_85 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_12 = kv_12.unbind(dim = -3);  kv_12 = None\n",
      "        k_63: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_12[0]\n",
      "        v_50: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_12[1];  unbind_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_51: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_50.transpose(1, 2);  q_50 = None\n",
      "        k_64: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_63.transpose(1, 2);  k_63 = None\n",
      "        v_51: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_50.transpose(1, 2);  v_50 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_48: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_51, k_64, v_51, is_causal = False, enable_gqa = True);  q_51 = k_64 = v_51 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_51: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_48.transpose(1, 2);  y_48 = None\n",
      "        contiguous_12: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_51.contiguous();  transpose_51 = None\n",
      "        y_49: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_12.view(2, 1, 2048);  contiguous_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_50: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_49, l_self_modules_backbone_modules_layers_modules_12_modules_mixer_modules_out_proj_parameters_weight_, None);  y_49 = l_self_modules_backbone_modules_layers_modules_12_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_24: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_23 + y_50;  x_23 = y_50 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_25: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_24, (2048,), l_self_modules_backbone_modules_layers_modules_12_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_12_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_12_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_12_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_50: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_25, l_self_modules_backbone_modules_layers_modules_12_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_25 = l_self_modules_backbone_modules_layers_modules_12_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_12 = linear_50.chunk(2, dim = -1);  linear_50 = None\n",
      "        y_51: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_12[0]\n",
      "        gate_12: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_12[1];  chunk_12 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_12: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_12);  gate_12 = None\n",
      "        mul_116: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_51 * silu_12;  y_51 = silu_12 = None\n",
      "        linear_51: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_116, l_self_modules_backbone_modules_layers_modules_12_modules_mlp_modules_fc2_parameters_weight_, None);  mul_116 = l_self_modules_backbone_modules_layers_modules_12_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_25: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_24 + linear_51;  x_24 = linear_51 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_26: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_25, (2048,), l_self_modules_backbone_modules_layers_modules_13_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_13_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_13_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_13_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_52: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_26, l_self_modules_backbone_modules_layers_modules_13_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_26 = l_self_modules_backbone_modules_layers_modules_13_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_13 = linear_52.split([2048, 512, 512], dim = -1);  linear_52 = None\n",
      "        q_52: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_13[0]\n",
      "        k_65: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_13[1]\n",
      "        v_52: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_13[2];  split_13 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_53: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_52.view(2, 1, 16, 128);  q_52 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_66: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_65.view(2, 1, 4, 128);  k_65 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_53: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_52.view(2, 1, 4, 128);  v_52 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_27: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_53.float()\n",
      "        xshaped_26: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_27.reshape(2, 1, 16, -1, 2);  float_27 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_27: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_455: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_26[(Ellipsis, 0)]\n",
      "        getitem_456: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_27[(Ellipsis, 0)]\n",
      "        mul_117: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_455 * getitem_456;  getitem_455 = getitem_456 = None\n",
      "        getitem_457: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_26[(Ellipsis, 1)]\n",
      "        getitem_458: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_27[(Ellipsis, 1)]\n",
      "        mul_118: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_457 * getitem_458;  getitem_457 = getitem_458 = None\n",
      "        sub_26: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_117 - mul_118;  mul_117 = mul_118 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_459: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_26[(Ellipsis, 1)]\n",
      "        getitem_460: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_27[(Ellipsis, 0)]\n",
      "        mul_119: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_459 * getitem_460;  getitem_459 = getitem_460 = None\n",
      "        getitem_461: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_26[(Ellipsis, 0)];  xshaped_26 = None\n",
      "        getitem_462: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_27[(Ellipsis, 1)];  freqs_cis_27 = None\n",
      "        mul_120: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_461 * getitem_462;  getitem_461 = getitem_462 = None\n",
      "        add_88: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_119 + mul_120;  mul_119 = mul_120 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_52: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_26, add_88], -1);  sub_26 = add_88 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_53: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_52.flatten(3);  x_out2_52 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_54: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_53.type_as(q_53);  x_out2_53 = q_53 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_28: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_66.float()\n",
      "        xshaped_27: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_28.reshape(2, 1, 4, -1, 2);  float_28 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_28: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_463: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_27[(Ellipsis, 0)]\n",
      "        getitem_464: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_28[(Ellipsis, 0)]\n",
      "        mul_121: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_463 * getitem_464;  getitem_463 = getitem_464 = None\n",
      "        getitem_465: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_27[(Ellipsis, 1)]\n",
      "        getitem_466: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_28[(Ellipsis, 1)]\n",
      "        mul_122: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_465 * getitem_466;  getitem_465 = getitem_466 = None\n",
      "        sub_27: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_121 - mul_122;  mul_121 = mul_122 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_467: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_27[(Ellipsis, 1)]\n",
      "        getitem_468: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_28[(Ellipsis, 0)]\n",
      "        mul_123: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_467 * getitem_468;  getitem_467 = getitem_468 = None\n",
      "        getitem_469: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_27[(Ellipsis, 0)];  xshaped_27 = None\n",
      "        getitem_470: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_28[(Ellipsis, 1)];  freqs_cis_28 = None\n",
      "        mul_124: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_469 * getitem_470;  getitem_469 = getitem_470 = None\n",
      "        add_89: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_123 + mul_124;  mul_123 = mul_124 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_54: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_27, add_89], -1);  sub_27 = add_89 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_55: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_54.flatten(3);  x_out2_54 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_67: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_55.type_as(k_66);  x_out2_55 = k_66 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_90: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_91: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_26 = l_inference_params_key_value_memory_dict_13_0_.size()\n",
      "        getitem_471 = size_26[0];  getitem_471 = None\n",
      "        getitem_472: \"Sym(s5)\" = size_26[1];  getitem_472 = None\n",
      "        getitem_473 = size_26[2];  getitem_473 = None\n",
      "        getitem_474: \"Sym(s6)\" = size_26[3];  getitem_474 = None\n",
      "        getitem_475 = size_26[4];  size_26 = getitem_475 = None\n",
      "        le_26: \"Sym(True)\" = add_90 <= 2;  le_26 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_27 = l_inference_params_key_value_memory_dict_13_0_.size()\n",
      "        getitem_476 = size_27[0];  getitem_476 = None\n",
      "        getitem_477: \"Sym(s5)\" = size_27[1]\n",
      "        getitem_478 = size_27[2];  getitem_478 = None\n",
      "        getitem_479: \"Sym(s6)\" = size_27[3];  getitem_479 = None\n",
      "        getitem_480 = size_27[4];  size_27 = getitem_480 = None\n",
      "        le_27: \"Sym(s9 + 1 <= s5)\" = add_91 <= getitem_477;  getitem_477 = le_27 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_13_0_[(slice(l_inference_params_batch_size_offset, add_90, None), slice(l_inference_params_seqlen_offset, add_91, None), 0, Ellipsis)] = k_67;  setitem_26 = l_inference_params_key_value_memory_dict_13_0_;  k_67 = setitem_26 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_13_0_[(slice(l_inference_params_batch_size_offset, add_90, None), slice(l_inference_params_seqlen_offset, add_91, None), 1, Ellipsis)] = v_53;  setitem_27 = l_inference_params_key_value_memory_dict_13_0_;  v_53 = setitem_27 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_13: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_13_0_[(slice(l_inference_params_batch_size_offset, add_90, None), slice(None, add_91, None), Ellipsis)];  l_inference_params_key_value_memory_dict_13_0_ = add_90 = add_91 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_13 = kv_13.unbind(dim = -3);  kv_13 = None\n",
      "        k_68: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_13[0]\n",
      "        v_54: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_13[1];  unbind_13 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_55: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_54.transpose(1, 2);  q_54 = None\n",
      "        k_69: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_68.transpose(1, 2);  k_68 = None\n",
      "        v_55: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_54.transpose(1, 2);  v_54 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_52: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_55, k_69, v_55, is_causal = False, enable_gqa = True);  q_55 = k_69 = v_55 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_55: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_52.transpose(1, 2);  y_52 = None\n",
      "        contiguous_13: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_55.contiguous();  transpose_55 = None\n",
      "        y_53: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_13.view(2, 1, 2048);  contiguous_13 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_54: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_53, l_self_modules_backbone_modules_layers_modules_13_modules_mixer_modules_out_proj_parameters_weight_, None);  y_53 = l_self_modules_backbone_modules_layers_modules_13_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_26: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_25 + y_54;  x_25 = y_54 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_27: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_26, (2048,), l_self_modules_backbone_modules_layers_modules_13_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_13_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_13_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_13_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_54: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_27, l_self_modules_backbone_modules_layers_modules_13_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_27 = l_self_modules_backbone_modules_layers_modules_13_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_13 = linear_54.chunk(2, dim = -1);  linear_54 = None\n",
      "        y_55: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_13[0]\n",
      "        gate_13: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_13[1];  chunk_13 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_13: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_13);  gate_13 = None\n",
      "        mul_125: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_55 * silu_13;  y_55 = silu_13 = None\n",
      "        linear_55: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_125, l_self_modules_backbone_modules_layers_modules_13_modules_mlp_modules_fc2_parameters_weight_, None);  mul_125 = l_self_modules_backbone_modules_layers_modules_13_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_27: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_26 + linear_55;  x_26 = linear_55 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_28: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_27, (2048,), l_self_modules_backbone_modules_layers_modules_14_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_14_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_14_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_14_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_56: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_28, l_self_modules_backbone_modules_layers_modules_14_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_28 = l_self_modules_backbone_modules_layers_modules_14_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_14 = linear_56.split([2048, 512, 512], dim = -1);  linear_56 = None\n",
      "        q_56: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_14[0]\n",
      "        k_70: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_14[1]\n",
      "        v_56: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_14[2];  split_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_57: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_56.view(2, 1, 16, 128);  q_56 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_71: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_70.view(2, 1, 4, 128);  k_70 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_57: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_56.view(2, 1, 4, 128);  v_56 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_29: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_57.float()\n",
      "        xshaped_28: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_29.reshape(2, 1, 16, -1, 2);  float_29 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_29: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_489: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_28[(Ellipsis, 0)]\n",
      "        getitem_490: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_29[(Ellipsis, 0)]\n",
      "        mul_126: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_489 * getitem_490;  getitem_489 = getitem_490 = None\n",
      "        getitem_491: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_28[(Ellipsis, 1)]\n",
      "        getitem_492: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_29[(Ellipsis, 1)]\n",
      "        mul_127: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_491 * getitem_492;  getitem_491 = getitem_492 = None\n",
      "        sub_28: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_126 - mul_127;  mul_126 = mul_127 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_493: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_28[(Ellipsis, 1)]\n",
      "        getitem_494: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_29[(Ellipsis, 0)]\n",
      "        mul_128: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_493 * getitem_494;  getitem_493 = getitem_494 = None\n",
      "        getitem_495: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_28[(Ellipsis, 0)];  xshaped_28 = None\n",
      "        getitem_496: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_29[(Ellipsis, 1)];  freqs_cis_29 = None\n",
      "        mul_129: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_495 * getitem_496;  getitem_495 = getitem_496 = None\n",
      "        add_94: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_128 + mul_129;  mul_128 = mul_129 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_56: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_28, add_94], -1);  sub_28 = add_94 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_57: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_56.flatten(3);  x_out2_56 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_58: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_57.type_as(q_57);  x_out2_57 = q_57 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_30: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_71.float()\n",
      "        xshaped_29: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_30.reshape(2, 1, 4, -1, 2);  float_30 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_30: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_497: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_29[(Ellipsis, 0)]\n",
      "        getitem_498: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_30[(Ellipsis, 0)]\n",
      "        mul_130: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_497 * getitem_498;  getitem_497 = getitem_498 = None\n",
      "        getitem_499: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_29[(Ellipsis, 1)]\n",
      "        getitem_500: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_30[(Ellipsis, 1)]\n",
      "        mul_131: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_499 * getitem_500;  getitem_499 = getitem_500 = None\n",
      "        sub_29: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_130 - mul_131;  mul_130 = mul_131 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_501: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_29[(Ellipsis, 1)]\n",
      "        getitem_502: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_30[(Ellipsis, 0)]\n",
      "        mul_132: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_501 * getitem_502;  getitem_501 = getitem_502 = None\n",
      "        getitem_503: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_29[(Ellipsis, 0)];  xshaped_29 = None\n",
      "        getitem_504: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_30[(Ellipsis, 1)];  freqs_cis_30 = None\n",
      "        mul_133: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_503 * getitem_504;  getitem_503 = getitem_504 = None\n",
      "        add_95: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_132 + mul_133;  mul_132 = mul_133 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_58: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_29, add_95], -1);  sub_29 = add_95 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_59: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_58.flatten(3);  x_out2_58 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_72: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_59.type_as(k_71);  x_out2_59 = k_71 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_96: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_97: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_28 = l_inference_params_key_value_memory_dict_14_0_.size()\n",
      "        getitem_505 = size_28[0];  getitem_505 = None\n",
      "        getitem_506: \"Sym(s5)\" = size_28[1];  getitem_506 = None\n",
      "        getitem_507 = size_28[2];  getitem_507 = None\n",
      "        getitem_508: \"Sym(s6)\" = size_28[3];  getitem_508 = None\n",
      "        getitem_509 = size_28[4];  size_28 = getitem_509 = None\n",
      "        le_28: \"Sym(True)\" = add_96 <= 2;  le_28 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_29 = l_inference_params_key_value_memory_dict_14_0_.size()\n",
      "        getitem_510 = size_29[0];  getitem_510 = None\n",
      "        getitem_511: \"Sym(s5)\" = size_29[1]\n",
      "        getitem_512 = size_29[2];  getitem_512 = None\n",
      "        getitem_513: \"Sym(s6)\" = size_29[3];  getitem_513 = None\n",
      "        getitem_514 = size_29[4];  size_29 = getitem_514 = None\n",
      "        le_29: \"Sym(s9 + 1 <= s5)\" = add_97 <= getitem_511;  getitem_511 = le_29 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_14_0_[(slice(l_inference_params_batch_size_offset, add_96, None), slice(l_inference_params_seqlen_offset, add_97, None), 0, Ellipsis)] = k_72;  setitem_28 = l_inference_params_key_value_memory_dict_14_0_;  k_72 = setitem_28 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_14_0_[(slice(l_inference_params_batch_size_offset, add_96, None), slice(l_inference_params_seqlen_offset, add_97, None), 1, Ellipsis)] = v_57;  setitem_29 = l_inference_params_key_value_memory_dict_14_0_;  v_57 = setitem_29 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_14: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_14_0_[(slice(l_inference_params_batch_size_offset, add_96, None), slice(None, add_97, None), Ellipsis)];  l_inference_params_key_value_memory_dict_14_0_ = add_96 = add_97 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_14 = kv_14.unbind(dim = -3);  kv_14 = None\n",
      "        k_73: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_14[0]\n",
      "        v_58: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_14[1];  unbind_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_59: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_58.transpose(1, 2);  q_58 = None\n",
      "        k_74: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_73.transpose(1, 2);  k_73 = None\n",
      "        v_59: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_58.transpose(1, 2);  v_58 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_56: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_59, k_74, v_59, is_causal = False, enable_gqa = True);  q_59 = k_74 = v_59 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_59: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_56.transpose(1, 2);  y_56 = None\n",
      "        contiguous_14: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_59.contiguous();  transpose_59 = None\n",
      "        y_57: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_14.view(2, 1, 2048);  contiguous_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_58: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_57, l_self_modules_backbone_modules_layers_modules_14_modules_mixer_modules_out_proj_parameters_weight_, None);  y_57 = l_self_modules_backbone_modules_layers_modules_14_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_28: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_27 + y_58;  x_27 = y_58 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_29: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_28, (2048,), l_self_modules_backbone_modules_layers_modules_14_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_14_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_14_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_14_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_58: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_29, l_self_modules_backbone_modules_layers_modules_14_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_29 = l_self_modules_backbone_modules_layers_modules_14_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_14 = linear_58.chunk(2, dim = -1);  linear_58 = None\n",
      "        y_59: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_14[0]\n",
      "        gate_14: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_14[1];  chunk_14 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_14: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_14);  gate_14 = None\n",
      "        mul_134: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_59 * silu_14;  y_59 = silu_14 = None\n",
      "        linear_59: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_134, l_self_modules_backbone_modules_layers_modules_14_modules_mlp_modules_fc2_parameters_weight_, None);  mul_134 = l_self_modules_backbone_modules_layers_modules_14_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_29: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_28 + linear_59;  x_28 = linear_59 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_30: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_29, (2048,), l_self_modules_backbone_modules_layers_modules_15_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_15_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_15_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_15_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_60: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_30, l_self_modules_backbone_modules_layers_modules_15_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_30 = l_self_modules_backbone_modules_layers_modules_15_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_15 = linear_60.split([2048, 512, 512], dim = -1);  linear_60 = None\n",
      "        q_60: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_15[0]\n",
      "        k_75: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_15[1]\n",
      "        v_60: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_15[2];  split_15 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_61: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_60.view(2, 1, 16, 128);  q_60 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_76: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_75.view(2, 1, 4, 128);  k_75 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_61: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_60.view(2, 1, 4, 128);  v_60 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_31: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_61.float()\n",
      "        xshaped_30: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_31.reshape(2, 1, 16, -1, 2);  float_31 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_31: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_523: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_30[(Ellipsis, 0)]\n",
      "        getitem_524: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_31[(Ellipsis, 0)]\n",
      "        mul_135: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_523 * getitem_524;  getitem_523 = getitem_524 = None\n",
      "        getitem_525: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_30[(Ellipsis, 1)]\n",
      "        getitem_526: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_31[(Ellipsis, 1)]\n",
      "        mul_136: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_525 * getitem_526;  getitem_525 = getitem_526 = None\n",
      "        sub_30: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_135 - mul_136;  mul_135 = mul_136 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_527: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_30[(Ellipsis, 1)]\n",
      "        getitem_528: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_31[(Ellipsis, 0)]\n",
      "        mul_137: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_527 * getitem_528;  getitem_527 = getitem_528 = None\n",
      "        getitem_529: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_30[(Ellipsis, 0)];  xshaped_30 = None\n",
      "        getitem_530: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_31[(Ellipsis, 1)];  freqs_cis_31 = None\n",
      "        mul_138: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_529 * getitem_530;  getitem_529 = getitem_530 = None\n",
      "        add_100: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_137 + mul_138;  mul_137 = mul_138 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_60: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_30, add_100], -1);  sub_30 = add_100 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_61: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_60.flatten(3);  x_out2_60 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_62: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_61.type_as(q_61);  x_out2_61 = q_61 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_32: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_76.float()\n",
      "        xshaped_31: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_32.reshape(2, 1, 4, -1, 2);  float_32 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_32: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_531: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_31[(Ellipsis, 0)]\n",
      "        getitem_532: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_32[(Ellipsis, 0)]\n",
      "        mul_139: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_531 * getitem_532;  getitem_531 = getitem_532 = None\n",
      "        getitem_533: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_31[(Ellipsis, 1)]\n",
      "        getitem_534: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_32[(Ellipsis, 1)]\n",
      "        mul_140: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_533 * getitem_534;  getitem_533 = getitem_534 = None\n",
      "        sub_31: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_139 - mul_140;  mul_139 = mul_140 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_535: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_31[(Ellipsis, 1)]\n",
      "        getitem_536: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_32[(Ellipsis, 0)]\n",
      "        mul_141: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_535 * getitem_536;  getitem_535 = getitem_536 = None\n",
      "        getitem_537: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_31[(Ellipsis, 0)];  xshaped_31 = None\n",
      "        getitem_538: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_32[(Ellipsis, 1)];  freqs_cis_32 = None\n",
      "        mul_142: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_537 * getitem_538;  getitem_537 = getitem_538 = None\n",
      "        add_101: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_141 + mul_142;  mul_141 = mul_142 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_62: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_31, add_101], -1);  sub_31 = add_101 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_63: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_62.flatten(3);  x_out2_62 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_77: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_63.type_as(k_76);  x_out2_63 = k_76 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_102: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_103: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_30 = l_inference_params_key_value_memory_dict_15_0_.size()\n",
      "        getitem_539 = size_30[0];  getitem_539 = None\n",
      "        getitem_540: \"Sym(s5)\" = size_30[1];  getitem_540 = None\n",
      "        getitem_541 = size_30[2];  getitem_541 = None\n",
      "        getitem_542: \"Sym(s6)\" = size_30[3];  getitem_542 = None\n",
      "        getitem_543 = size_30[4];  size_30 = getitem_543 = None\n",
      "        le_30: \"Sym(True)\" = add_102 <= 2;  le_30 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_31 = l_inference_params_key_value_memory_dict_15_0_.size()\n",
      "        getitem_544 = size_31[0];  getitem_544 = None\n",
      "        getitem_545: \"Sym(s5)\" = size_31[1]\n",
      "        getitem_546 = size_31[2];  getitem_546 = None\n",
      "        getitem_547: \"Sym(s6)\" = size_31[3];  getitem_547 = None\n",
      "        getitem_548 = size_31[4];  size_31 = getitem_548 = None\n",
      "        le_31: \"Sym(s9 + 1 <= s5)\" = add_103 <= getitem_545;  getitem_545 = le_31 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_15_0_[(slice(l_inference_params_batch_size_offset, add_102, None), slice(l_inference_params_seqlen_offset, add_103, None), 0, Ellipsis)] = k_77;  setitem_30 = l_inference_params_key_value_memory_dict_15_0_;  k_77 = setitem_30 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_15_0_[(slice(l_inference_params_batch_size_offset, add_102, None), slice(l_inference_params_seqlen_offset, add_103, None), 1, Ellipsis)] = v_61;  setitem_31 = l_inference_params_key_value_memory_dict_15_0_;  v_61 = setitem_31 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_15: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_15_0_[(slice(l_inference_params_batch_size_offset, add_102, None), slice(None, add_103, None), Ellipsis)];  l_inference_params_key_value_memory_dict_15_0_ = add_102 = add_103 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_15 = kv_15.unbind(dim = -3);  kv_15 = None\n",
      "        k_78: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_15[0]\n",
      "        v_62: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_15[1];  unbind_15 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_63: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_62.transpose(1, 2);  q_62 = None\n",
      "        k_79: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_78.transpose(1, 2);  k_78 = None\n",
      "        v_63: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_62.transpose(1, 2);  v_62 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_60: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_63, k_79, v_63, is_causal = False, enable_gqa = True);  q_63 = k_79 = v_63 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_63: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_60.transpose(1, 2);  y_60 = None\n",
      "        contiguous_15: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_63.contiguous();  transpose_63 = None\n",
      "        y_61: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_15.view(2, 1, 2048);  contiguous_15 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_62: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_61, l_self_modules_backbone_modules_layers_modules_15_modules_mixer_modules_out_proj_parameters_weight_, None);  y_61 = l_self_modules_backbone_modules_layers_modules_15_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_30: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_29 + y_62;  x_29 = y_62 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_31: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_30, (2048,), l_self_modules_backbone_modules_layers_modules_15_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_15_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_15_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_15_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_62: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_31, l_self_modules_backbone_modules_layers_modules_15_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_31 = l_self_modules_backbone_modules_layers_modules_15_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_15 = linear_62.chunk(2, dim = -1);  linear_62 = None\n",
      "        y_63: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_15[0]\n",
      "        gate_15: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_15[1];  chunk_15 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_15: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_15);  gate_15 = None\n",
      "        mul_143: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_63 * silu_15;  y_63 = silu_15 = None\n",
      "        linear_63: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_143, l_self_modules_backbone_modules_layers_modules_15_modules_mlp_modules_fc2_parameters_weight_, None);  mul_143 = l_self_modules_backbone_modules_layers_modules_15_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_31: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_30 + linear_63;  x_30 = linear_63 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_32: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_31, (2048,), l_self_modules_backbone_modules_layers_modules_16_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_16_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_16_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_16_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_64: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_32, l_self_modules_backbone_modules_layers_modules_16_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_32 = l_self_modules_backbone_modules_layers_modules_16_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_16 = linear_64.split([2048, 512, 512], dim = -1);  linear_64 = None\n",
      "        q_64: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_16[0]\n",
      "        k_80: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_16[1]\n",
      "        v_64: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_16[2];  split_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_65: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_64.view(2, 1, 16, 128);  q_64 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_81: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_80.view(2, 1, 4, 128);  k_80 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_65: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_64.view(2, 1, 4, 128);  v_64 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_33: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_65.float()\n",
      "        xshaped_32: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_33.reshape(2, 1, 16, -1, 2);  float_33 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_33: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_557: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_32[(Ellipsis, 0)]\n",
      "        getitem_558: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_33[(Ellipsis, 0)]\n",
      "        mul_144: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_557 * getitem_558;  getitem_557 = getitem_558 = None\n",
      "        getitem_559: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_32[(Ellipsis, 1)]\n",
      "        getitem_560: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_33[(Ellipsis, 1)]\n",
      "        mul_145: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_559 * getitem_560;  getitem_559 = getitem_560 = None\n",
      "        sub_32: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_144 - mul_145;  mul_144 = mul_145 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_561: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_32[(Ellipsis, 1)]\n",
      "        getitem_562: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_33[(Ellipsis, 0)]\n",
      "        mul_146: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_561 * getitem_562;  getitem_561 = getitem_562 = None\n",
      "        getitem_563: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_32[(Ellipsis, 0)];  xshaped_32 = None\n",
      "        getitem_564: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_33[(Ellipsis, 1)];  freqs_cis_33 = None\n",
      "        mul_147: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_563 * getitem_564;  getitem_563 = getitem_564 = None\n",
      "        add_106: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_146 + mul_147;  mul_146 = mul_147 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_64: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_32, add_106], -1);  sub_32 = add_106 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_65: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_64.flatten(3);  x_out2_64 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_66: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_65.type_as(q_65);  x_out2_65 = q_65 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_34: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_81.float()\n",
      "        xshaped_33: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_34.reshape(2, 1, 4, -1, 2);  float_34 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_34: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_565: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_33[(Ellipsis, 0)]\n",
      "        getitem_566: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_34[(Ellipsis, 0)]\n",
      "        mul_148: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_565 * getitem_566;  getitem_565 = getitem_566 = None\n",
      "        getitem_567: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_33[(Ellipsis, 1)]\n",
      "        getitem_568: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_34[(Ellipsis, 1)]\n",
      "        mul_149: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_567 * getitem_568;  getitem_567 = getitem_568 = None\n",
      "        sub_33: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_148 - mul_149;  mul_148 = mul_149 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_569: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_33[(Ellipsis, 1)]\n",
      "        getitem_570: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_34[(Ellipsis, 0)]\n",
      "        mul_150: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_569 * getitem_570;  getitem_569 = getitem_570 = None\n",
      "        getitem_571: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_33[(Ellipsis, 0)];  xshaped_33 = None\n",
      "        getitem_572: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_34[(Ellipsis, 1)];  freqs_cis_34 = None\n",
      "        mul_151: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_571 * getitem_572;  getitem_571 = getitem_572 = None\n",
      "        add_107: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_150 + mul_151;  mul_150 = mul_151 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_66: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_33, add_107], -1);  sub_33 = add_107 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_67: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_66.flatten(3);  x_out2_66 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_82: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_67.type_as(k_81);  x_out2_67 = k_81 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_108: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_109: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_32 = l_inference_params_key_value_memory_dict_16_0_.size()\n",
      "        getitem_573 = size_32[0];  getitem_573 = None\n",
      "        getitem_574: \"Sym(s5)\" = size_32[1];  getitem_574 = None\n",
      "        getitem_575 = size_32[2];  getitem_575 = None\n",
      "        getitem_576: \"Sym(s6)\" = size_32[3];  getitem_576 = None\n",
      "        getitem_577 = size_32[4];  size_32 = getitem_577 = None\n",
      "        le_32: \"Sym(True)\" = add_108 <= 2;  le_32 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_33 = l_inference_params_key_value_memory_dict_16_0_.size()\n",
      "        getitem_578 = size_33[0];  getitem_578 = None\n",
      "        getitem_579: \"Sym(s5)\" = size_33[1]\n",
      "        getitem_580 = size_33[2];  getitem_580 = None\n",
      "        getitem_581: \"Sym(s6)\" = size_33[3];  getitem_581 = None\n",
      "        getitem_582 = size_33[4];  size_33 = getitem_582 = None\n",
      "        le_33: \"Sym(s9 + 1 <= s5)\" = add_109 <= getitem_579;  getitem_579 = le_33 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_16_0_[(slice(l_inference_params_batch_size_offset, add_108, None), slice(l_inference_params_seqlen_offset, add_109, None), 0, Ellipsis)] = k_82;  setitem_32 = l_inference_params_key_value_memory_dict_16_0_;  k_82 = setitem_32 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_16_0_[(slice(l_inference_params_batch_size_offset, add_108, None), slice(l_inference_params_seqlen_offset, add_109, None), 1, Ellipsis)] = v_65;  setitem_33 = l_inference_params_key_value_memory_dict_16_0_;  v_65 = setitem_33 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_16: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_16_0_[(slice(l_inference_params_batch_size_offset, add_108, None), slice(None, add_109, None), Ellipsis)];  l_inference_params_key_value_memory_dict_16_0_ = add_108 = add_109 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_16 = kv_16.unbind(dim = -3);  kv_16 = None\n",
      "        k_83: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_16[0]\n",
      "        v_66: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_16[1];  unbind_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_67: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_66.transpose(1, 2);  q_66 = None\n",
      "        k_84: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_83.transpose(1, 2);  k_83 = None\n",
      "        v_67: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_66.transpose(1, 2);  v_66 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_64: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_67, k_84, v_67, is_causal = False, enable_gqa = True);  q_67 = k_84 = v_67 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_67: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_64.transpose(1, 2);  y_64 = None\n",
      "        contiguous_16: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_67.contiguous();  transpose_67 = None\n",
      "        y_65: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_16.view(2, 1, 2048);  contiguous_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_66: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_65, l_self_modules_backbone_modules_layers_modules_16_modules_mixer_modules_out_proj_parameters_weight_, None);  y_65 = l_self_modules_backbone_modules_layers_modules_16_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_32: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_31 + y_66;  x_31 = y_66 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_33: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_32, (2048,), l_self_modules_backbone_modules_layers_modules_16_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_16_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_16_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_16_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_66: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_33, l_self_modules_backbone_modules_layers_modules_16_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_33 = l_self_modules_backbone_modules_layers_modules_16_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_16 = linear_66.chunk(2, dim = -1);  linear_66 = None\n",
      "        y_67: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_16[0]\n",
      "        gate_16: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_16[1];  chunk_16 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_16: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_16);  gate_16 = None\n",
      "        mul_152: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_67 * silu_16;  y_67 = silu_16 = None\n",
      "        linear_67: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_152, l_self_modules_backbone_modules_layers_modules_16_modules_mlp_modules_fc2_parameters_weight_, None);  mul_152 = l_self_modules_backbone_modules_layers_modules_16_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_33: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_32 + linear_67;  x_32 = linear_67 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_34: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_33, (2048,), l_self_modules_backbone_modules_layers_modules_17_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_17_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_17_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_17_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_68: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_34, l_self_modules_backbone_modules_layers_modules_17_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_34 = l_self_modules_backbone_modules_layers_modules_17_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_17 = linear_68.split([2048, 512, 512], dim = -1);  linear_68 = None\n",
      "        q_68: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_17[0]\n",
      "        k_85: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_17[1]\n",
      "        v_68: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_17[2];  split_17 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_69: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_68.view(2, 1, 16, 128);  q_68 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_86: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_85.view(2, 1, 4, 128);  k_85 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_69: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_68.view(2, 1, 4, 128);  v_68 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_35: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_69.float()\n",
      "        xshaped_34: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_35.reshape(2, 1, 16, -1, 2);  float_35 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_35: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_591: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_34[(Ellipsis, 0)]\n",
      "        getitem_592: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_35[(Ellipsis, 0)]\n",
      "        mul_153: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_591 * getitem_592;  getitem_591 = getitem_592 = None\n",
      "        getitem_593: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_34[(Ellipsis, 1)]\n",
      "        getitem_594: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_35[(Ellipsis, 1)]\n",
      "        mul_154: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_593 * getitem_594;  getitem_593 = getitem_594 = None\n",
      "        sub_34: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_153 - mul_154;  mul_153 = mul_154 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_595: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_34[(Ellipsis, 1)]\n",
      "        getitem_596: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_35[(Ellipsis, 0)]\n",
      "        mul_155: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_595 * getitem_596;  getitem_595 = getitem_596 = None\n",
      "        getitem_597: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_34[(Ellipsis, 0)];  xshaped_34 = None\n",
      "        getitem_598: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_35[(Ellipsis, 1)];  freqs_cis_35 = None\n",
      "        mul_156: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_597 * getitem_598;  getitem_597 = getitem_598 = None\n",
      "        add_112: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_155 + mul_156;  mul_155 = mul_156 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_68: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_34, add_112], -1);  sub_34 = add_112 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_69: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_68.flatten(3);  x_out2_68 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_70: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_69.type_as(q_69);  x_out2_69 = q_69 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_36: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_86.float()\n",
      "        xshaped_35: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_36.reshape(2, 1, 4, -1, 2);  float_36 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_36: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_599: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_35[(Ellipsis, 0)]\n",
      "        getitem_600: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_36[(Ellipsis, 0)]\n",
      "        mul_157: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_599 * getitem_600;  getitem_599 = getitem_600 = None\n",
      "        getitem_601: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_35[(Ellipsis, 1)]\n",
      "        getitem_602: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_36[(Ellipsis, 1)]\n",
      "        mul_158: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_601 * getitem_602;  getitem_601 = getitem_602 = None\n",
      "        sub_35: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_157 - mul_158;  mul_157 = mul_158 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_603: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_35[(Ellipsis, 1)]\n",
      "        getitem_604: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_36[(Ellipsis, 0)]\n",
      "        mul_159: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_603 * getitem_604;  getitem_603 = getitem_604 = None\n",
      "        getitem_605: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_35[(Ellipsis, 0)];  xshaped_35 = None\n",
      "        getitem_606: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_36[(Ellipsis, 1)];  freqs_cis_36 = None\n",
      "        mul_160: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_605 * getitem_606;  getitem_605 = getitem_606 = None\n",
      "        add_113: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_159 + mul_160;  mul_159 = mul_160 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_70: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_35, add_113], -1);  sub_35 = add_113 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_71: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_70.flatten(3);  x_out2_70 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_87: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_71.type_as(k_86);  x_out2_71 = k_86 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_114: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_115: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_34 = l_inference_params_key_value_memory_dict_17_0_.size()\n",
      "        getitem_607 = size_34[0];  getitem_607 = None\n",
      "        getitem_608: \"Sym(s5)\" = size_34[1];  getitem_608 = None\n",
      "        getitem_609 = size_34[2];  getitem_609 = None\n",
      "        getitem_610: \"Sym(s6)\" = size_34[3];  getitem_610 = None\n",
      "        getitem_611 = size_34[4];  size_34 = getitem_611 = None\n",
      "        le_34: \"Sym(True)\" = add_114 <= 2;  le_34 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_35 = l_inference_params_key_value_memory_dict_17_0_.size()\n",
      "        getitem_612 = size_35[0];  getitem_612 = None\n",
      "        getitem_613: \"Sym(s5)\" = size_35[1]\n",
      "        getitem_614 = size_35[2];  getitem_614 = None\n",
      "        getitem_615: \"Sym(s6)\" = size_35[3];  getitem_615 = None\n",
      "        getitem_616 = size_35[4];  size_35 = getitem_616 = None\n",
      "        le_35: \"Sym(s9 + 1 <= s5)\" = add_115 <= getitem_613;  getitem_613 = le_35 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_17_0_[(slice(l_inference_params_batch_size_offset, add_114, None), slice(l_inference_params_seqlen_offset, add_115, None), 0, Ellipsis)] = k_87;  setitem_34 = l_inference_params_key_value_memory_dict_17_0_;  k_87 = setitem_34 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_17_0_[(slice(l_inference_params_batch_size_offset, add_114, None), slice(l_inference_params_seqlen_offset, add_115, None), 1, Ellipsis)] = v_69;  setitem_35 = l_inference_params_key_value_memory_dict_17_0_;  v_69 = setitem_35 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_17: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_17_0_[(slice(l_inference_params_batch_size_offset, add_114, None), slice(None, add_115, None), Ellipsis)];  l_inference_params_key_value_memory_dict_17_0_ = add_114 = add_115 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_17 = kv_17.unbind(dim = -3);  kv_17 = None\n",
      "        k_88: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_17[0]\n",
      "        v_70: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_17[1];  unbind_17 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_71: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_70.transpose(1, 2);  q_70 = None\n",
      "        k_89: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_88.transpose(1, 2);  k_88 = None\n",
      "        v_71: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_70.transpose(1, 2);  v_70 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_68: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_71, k_89, v_71, is_causal = False, enable_gqa = True);  q_71 = k_89 = v_71 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_71: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_68.transpose(1, 2);  y_68 = None\n",
      "        contiguous_17: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_71.contiguous();  transpose_71 = None\n",
      "        y_69: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_17.view(2, 1, 2048);  contiguous_17 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_70: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_69, l_self_modules_backbone_modules_layers_modules_17_modules_mixer_modules_out_proj_parameters_weight_, None);  y_69 = l_self_modules_backbone_modules_layers_modules_17_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_34: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_33 + y_70;  x_33 = y_70 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_35: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_34, (2048,), l_self_modules_backbone_modules_layers_modules_17_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_17_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_17_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_17_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_70: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_35, l_self_modules_backbone_modules_layers_modules_17_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_35 = l_self_modules_backbone_modules_layers_modules_17_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_17 = linear_70.chunk(2, dim = -1);  linear_70 = None\n",
      "        y_71: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_17[0]\n",
      "        gate_17: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_17[1];  chunk_17 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_17: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_17);  gate_17 = None\n",
      "        mul_161: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_71 * silu_17;  y_71 = silu_17 = None\n",
      "        linear_71: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_161, l_self_modules_backbone_modules_layers_modules_17_modules_mlp_modules_fc2_parameters_weight_, None);  mul_161 = l_self_modules_backbone_modules_layers_modules_17_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_35: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_34 + linear_71;  x_34 = linear_71 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_36: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_35, (2048,), l_self_modules_backbone_modules_layers_modules_18_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_18_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_18_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_18_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_72: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_36, l_self_modules_backbone_modules_layers_modules_18_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_36 = l_self_modules_backbone_modules_layers_modules_18_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_18 = linear_72.split([2048, 512, 512], dim = -1);  linear_72 = None\n",
      "        q_72: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_18[0]\n",
      "        k_90: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_18[1]\n",
      "        v_72: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_18[2];  split_18 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_73: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_72.view(2, 1, 16, 128);  q_72 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_91: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_90.view(2, 1, 4, 128);  k_90 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_73: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_72.view(2, 1, 4, 128);  v_72 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_37: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_73.float()\n",
      "        xshaped_36: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_37.reshape(2, 1, 16, -1, 2);  float_37 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_37: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_625: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_36[(Ellipsis, 0)]\n",
      "        getitem_626: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_37[(Ellipsis, 0)]\n",
      "        mul_162: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_625 * getitem_626;  getitem_625 = getitem_626 = None\n",
      "        getitem_627: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_36[(Ellipsis, 1)]\n",
      "        getitem_628: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_37[(Ellipsis, 1)]\n",
      "        mul_163: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_627 * getitem_628;  getitem_627 = getitem_628 = None\n",
      "        sub_36: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_162 - mul_163;  mul_162 = mul_163 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_629: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_36[(Ellipsis, 1)]\n",
      "        getitem_630: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_37[(Ellipsis, 0)]\n",
      "        mul_164: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_629 * getitem_630;  getitem_629 = getitem_630 = None\n",
      "        getitem_631: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_36[(Ellipsis, 0)];  xshaped_36 = None\n",
      "        getitem_632: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_37[(Ellipsis, 1)];  freqs_cis_37 = None\n",
      "        mul_165: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_631 * getitem_632;  getitem_631 = getitem_632 = None\n",
      "        add_118: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_164 + mul_165;  mul_164 = mul_165 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_72: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_36, add_118], -1);  sub_36 = add_118 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_73: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_72.flatten(3);  x_out2_72 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_74: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_73.type_as(q_73);  x_out2_73 = q_73 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_38: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_91.float()\n",
      "        xshaped_37: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_38.reshape(2, 1, 4, -1, 2);  float_38 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_38: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_633: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_37[(Ellipsis, 0)]\n",
      "        getitem_634: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_38[(Ellipsis, 0)]\n",
      "        mul_166: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_633 * getitem_634;  getitem_633 = getitem_634 = None\n",
      "        getitem_635: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_37[(Ellipsis, 1)]\n",
      "        getitem_636: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_38[(Ellipsis, 1)]\n",
      "        mul_167: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_635 * getitem_636;  getitem_635 = getitem_636 = None\n",
      "        sub_37: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_166 - mul_167;  mul_166 = mul_167 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_637: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_37[(Ellipsis, 1)]\n",
      "        getitem_638: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_38[(Ellipsis, 0)]\n",
      "        mul_168: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_637 * getitem_638;  getitem_637 = getitem_638 = None\n",
      "        getitem_639: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_37[(Ellipsis, 0)];  xshaped_37 = None\n",
      "        getitem_640: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_38[(Ellipsis, 1)];  freqs_cis_38 = None\n",
      "        mul_169: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_639 * getitem_640;  getitem_639 = getitem_640 = None\n",
      "        add_119: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_168 + mul_169;  mul_168 = mul_169 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_74: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_37, add_119], -1);  sub_37 = add_119 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_75: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_74.flatten(3);  x_out2_74 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_92: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_75.type_as(k_91);  x_out2_75 = k_91 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_120: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_121: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_36 = l_inference_params_key_value_memory_dict_18_0_.size()\n",
      "        getitem_641 = size_36[0];  getitem_641 = None\n",
      "        getitem_642: \"Sym(s5)\" = size_36[1];  getitem_642 = None\n",
      "        getitem_643 = size_36[2];  getitem_643 = None\n",
      "        getitem_644: \"Sym(s6)\" = size_36[3];  getitem_644 = None\n",
      "        getitem_645 = size_36[4];  size_36 = getitem_645 = None\n",
      "        le_36: \"Sym(True)\" = add_120 <= 2;  le_36 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_37 = l_inference_params_key_value_memory_dict_18_0_.size()\n",
      "        getitem_646 = size_37[0];  getitem_646 = None\n",
      "        getitem_647: \"Sym(s5)\" = size_37[1]\n",
      "        getitem_648 = size_37[2];  getitem_648 = None\n",
      "        getitem_649: \"Sym(s6)\" = size_37[3];  getitem_649 = None\n",
      "        getitem_650 = size_37[4];  size_37 = getitem_650 = None\n",
      "        le_37: \"Sym(s9 + 1 <= s5)\" = add_121 <= getitem_647;  getitem_647 = le_37 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_18_0_[(slice(l_inference_params_batch_size_offset, add_120, None), slice(l_inference_params_seqlen_offset, add_121, None), 0, Ellipsis)] = k_92;  setitem_36 = l_inference_params_key_value_memory_dict_18_0_;  k_92 = setitem_36 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_18_0_[(slice(l_inference_params_batch_size_offset, add_120, None), slice(l_inference_params_seqlen_offset, add_121, None), 1, Ellipsis)] = v_73;  setitem_37 = l_inference_params_key_value_memory_dict_18_0_;  v_73 = setitem_37 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_18: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_18_0_[(slice(l_inference_params_batch_size_offset, add_120, None), slice(None, add_121, None), Ellipsis)];  l_inference_params_key_value_memory_dict_18_0_ = add_120 = add_121 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_18 = kv_18.unbind(dim = -3);  kv_18 = None\n",
      "        k_93: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_18[0]\n",
      "        v_74: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_18[1];  unbind_18 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_75: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_74.transpose(1, 2);  q_74 = None\n",
      "        k_94: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_93.transpose(1, 2);  k_93 = None\n",
      "        v_75: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_74.transpose(1, 2);  v_74 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_72: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_75, k_94, v_75, is_causal = False, enable_gqa = True);  q_75 = k_94 = v_75 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_75: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_72.transpose(1, 2);  y_72 = None\n",
      "        contiguous_18: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_75.contiguous();  transpose_75 = None\n",
      "        y_73: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_18.view(2, 1, 2048);  contiguous_18 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_74: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_73, l_self_modules_backbone_modules_layers_modules_18_modules_mixer_modules_out_proj_parameters_weight_, None);  y_73 = l_self_modules_backbone_modules_layers_modules_18_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_36: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_35 + y_74;  x_35 = y_74 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_37: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_36, (2048,), l_self_modules_backbone_modules_layers_modules_18_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_18_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_18_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_18_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_74: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_37, l_self_modules_backbone_modules_layers_modules_18_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_37 = l_self_modules_backbone_modules_layers_modules_18_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_18 = linear_74.chunk(2, dim = -1);  linear_74 = None\n",
      "        y_75: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_18[0]\n",
      "        gate_18: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_18[1];  chunk_18 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_18: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_18);  gate_18 = None\n",
      "        mul_170: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_75 * silu_18;  y_75 = silu_18 = None\n",
      "        linear_75: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_170, l_self_modules_backbone_modules_layers_modules_18_modules_mlp_modules_fc2_parameters_weight_, None);  mul_170 = l_self_modules_backbone_modules_layers_modules_18_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_37: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_36 + linear_75;  x_36 = linear_75 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_38: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_37, (2048,), l_self_modules_backbone_modules_layers_modules_19_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_19_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_19_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_19_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_76: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_38, l_self_modules_backbone_modules_layers_modules_19_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_38 = l_self_modules_backbone_modules_layers_modules_19_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_19 = linear_76.split([2048, 512, 512], dim = -1);  linear_76 = None\n",
      "        q_76: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_19[0]\n",
      "        k_95: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_19[1]\n",
      "        v_76: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_19[2];  split_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_77: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_76.view(2, 1, 16, 128);  q_76 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_96: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_95.view(2, 1, 4, 128);  k_95 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_77: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_76.view(2, 1, 4, 128);  v_76 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_39: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_77.float()\n",
      "        xshaped_38: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_39.reshape(2, 1, 16, -1, 2);  float_39 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_39: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_659: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_38[(Ellipsis, 0)]\n",
      "        getitem_660: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_39[(Ellipsis, 0)]\n",
      "        mul_171: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_659 * getitem_660;  getitem_659 = getitem_660 = None\n",
      "        getitem_661: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_38[(Ellipsis, 1)]\n",
      "        getitem_662: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_39[(Ellipsis, 1)]\n",
      "        mul_172: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_661 * getitem_662;  getitem_661 = getitem_662 = None\n",
      "        sub_38: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_171 - mul_172;  mul_171 = mul_172 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_663: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_38[(Ellipsis, 1)]\n",
      "        getitem_664: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_39[(Ellipsis, 0)]\n",
      "        mul_173: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_663 * getitem_664;  getitem_663 = getitem_664 = None\n",
      "        getitem_665: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_38[(Ellipsis, 0)];  xshaped_38 = None\n",
      "        getitem_666: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_39[(Ellipsis, 1)];  freqs_cis_39 = None\n",
      "        mul_174: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_665 * getitem_666;  getitem_665 = getitem_666 = None\n",
      "        add_124: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_173 + mul_174;  mul_173 = mul_174 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_76: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_38, add_124], -1);  sub_38 = add_124 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_77: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_76.flatten(3);  x_out2_76 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_78: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_77.type_as(q_77);  x_out2_77 = q_77 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_40: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_96.float()\n",
      "        xshaped_39: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_40.reshape(2, 1, 4, -1, 2);  float_40 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_40: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_667: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_39[(Ellipsis, 0)]\n",
      "        getitem_668: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_40[(Ellipsis, 0)]\n",
      "        mul_175: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_667 * getitem_668;  getitem_667 = getitem_668 = None\n",
      "        getitem_669: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_39[(Ellipsis, 1)]\n",
      "        getitem_670: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_40[(Ellipsis, 1)]\n",
      "        mul_176: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_669 * getitem_670;  getitem_669 = getitem_670 = None\n",
      "        sub_39: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_175 - mul_176;  mul_175 = mul_176 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_671: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_39[(Ellipsis, 1)]\n",
      "        getitem_672: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_40[(Ellipsis, 0)]\n",
      "        mul_177: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_671 * getitem_672;  getitem_671 = getitem_672 = None\n",
      "        getitem_673: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_39[(Ellipsis, 0)];  xshaped_39 = None\n",
      "        getitem_674: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_40[(Ellipsis, 1)];  freqs_cis_40 = None\n",
      "        mul_178: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_673 * getitem_674;  getitem_673 = getitem_674 = None\n",
      "        add_125: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_177 + mul_178;  mul_177 = mul_178 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_78: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_39, add_125], -1);  sub_39 = add_125 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_79: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_78.flatten(3);  x_out2_78 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_97: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_79.type_as(k_96);  x_out2_79 = k_96 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_126: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_127: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_38 = l_inference_params_key_value_memory_dict_19_0_.size()\n",
      "        getitem_675 = size_38[0];  getitem_675 = None\n",
      "        getitem_676: \"Sym(s5)\" = size_38[1];  getitem_676 = None\n",
      "        getitem_677 = size_38[2];  getitem_677 = None\n",
      "        getitem_678: \"Sym(s6)\" = size_38[3];  getitem_678 = None\n",
      "        getitem_679 = size_38[4];  size_38 = getitem_679 = None\n",
      "        le_38: \"Sym(True)\" = add_126 <= 2;  le_38 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_39 = l_inference_params_key_value_memory_dict_19_0_.size()\n",
      "        getitem_680 = size_39[0];  getitem_680 = None\n",
      "        getitem_681: \"Sym(s5)\" = size_39[1]\n",
      "        getitem_682 = size_39[2];  getitem_682 = None\n",
      "        getitem_683: \"Sym(s6)\" = size_39[3];  getitem_683 = None\n",
      "        getitem_684 = size_39[4];  size_39 = getitem_684 = None\n",
      "        le_39: \"Sym(s9 + 1 <= s5)\" = add_127 <= getitem_681;  getitem_681 = le_39 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_19_0_[(slice(l_inference_params_batch_size_offset, add_126, None), slice(l_inference_params_seqlen_offset, add_127, None), 0, Ellipsis)] = k_97;  setitem_38 = l_inference_params_key_value_memory_dict_19_0_;  k_97 = setitem_38 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_19_0_[(slice(l_inference_params_batch_size_offset, add_126, None), slice(l_inference_params_seqlen_offset, add_127, None), 1, Ellipsis)] = v_77;  setitem_39 = l_inference_params_key_value_memory_dict_19_0_;  v_77 = setitem_39 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_19: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_19_0_[(slice(l_inference_params_batch_size_offset, add_126, None), slice(None, add_127, None), Ellipsis)];  l_inference_params_key_value_memory_dict_19_0_ = add_126 = add_127 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_19 = kv_19.unbind(dim = -3);  kv_19 = None\n",
      "        k_98: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_19[0]\n",
      "        v_78: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_19[1];  unbind_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_79: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_78.transpose(1, 2);  q_78 = None\n",
      "        k_99: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_98.transpose(1, 2);  k_98 = None\n",
      "        v_79: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_78.transpose(1, 2);  v_78 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_76: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_79, k_99, v_79, is_causal = False, enable_gqa = True);  q_79 = k_99 = v_79 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_79: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_76.transpose(1, 2);  y_76 = None\n",
      "        contiguous_19: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_79.contiguous();  transpose_79 = None\n",
      "        y_77: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_19.view(2, 1, 2048);  contiguous_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_78: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_77, l_self_modules_backbone_modules_layers_modules_19_modules_mixer_modules_out_proj_parameters_weight_, None);  y_77 = l_self_modules_backbone_modules_layers_modules_19_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_38: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_37 + y_78;  x_37 = y_78 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_39: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_38, (2048,), l_self_modules_backbone_modules_layers_modules_19_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_19_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_19_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_19_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_78: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_39, l_self_modules_backbone_modules_layers_modules_19_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_39 = l_self_modules_backbone_modules_layers_modules_19_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_19 = linear_78.chunk(2, dim = -1);  linear_78 = None\n",
      "        y_79: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_19[0]\n",
      "        gate_19: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_19[1];  chunk_19 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_19: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_19);  gate_19 = None\n",
      "        mul_179: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_79 * silu_19;  y_79 = silu_19 = None\n",
      "        linear_79: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_179, l_self_modules_backbone_modules_layers_modules_19_modules_mlp_modules_fc2_parameters_weight_, None);  mul_179 = l_self_modules_backbone_modules_layers_modules_19_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_39: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_38 + linear_79;  x_38 = linear_79 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_40: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_39, (2048,), l_self_modules_backbone_modules_layers_modules_20_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_20_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_20_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_20_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_80: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_40, l_self_modules_backbone_modules_layers_modules_20_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_40 = l_self_modules_backbone_modules_layers_modules_20_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_20 = linear_80.split([2048, 512, 512], dim = -1);  linear_80 = None\n",
      "        q_80: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_20[0]\n",
      "        k_100: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_20[1]\n",
      "        v_80: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_20[2];  split_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_81: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_80.view(2, 1, 16, 128);  q_80 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_101: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_100.view(2, 1, 4, 128);  k_100 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_81: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_80.view(2, 1, 4, 128);  v_80 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_41: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_81.float()\n",
      "        xshaped_40: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_41.reshape(2, 1, 16, -1, 2);  float_41 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_41: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_693: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_40[(Ellipsis, 0)]\n",
      "        getitem_694: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_41[(Ellipsis, 0)]\n",
      "        mul_180: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_693 * getitem_694;  getitem_693 = getitem_694 = None\n",
      "        getitem_695: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_40[(Ellipsis, 1)]\n",
      "        getitem_696: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_41[(Ellipsis, 1)]\n",
      "        mul_181: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_695 * getitem_696;  getitem_695 = getitem_696 = None\n",
      "        sub_40: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_180 - mul_181;  mul_180 = mul_181 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_697: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_40[(Ellipsis, 1)]\n",
      "        getitem_698: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_41[(Ellipsis, 0)]\n",
      "        mul_182: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_697 * getitem_698;  getitem_697 = getitem_698 = None\n",
      "        getitem_699: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_40[(Ellipsis, 0)];  xshaped_40 = None\n",
      "        getitem_700: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_41[(Ellipsis, 1)];  freqs_cis_41 = None\n",
      "        mul_183: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_699 * getitem_700;  getitem_699 = getitem_700 = None\n",
      "        add_130: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_182 + mul_183;  mul_182 = mul_183 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_80: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_40, add_130], -1);  sub_40 = add_130 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_81: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_80.flatten(3);  x_out2_80 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_82: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_81.type_as(q_81);  x_out2_81 = q_81 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_42: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_101.float()\n",
      "        xshaped_41: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_42.reshape(2, 1, 4, -1, 2);  float_42 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_42: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_701: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_41[(Ellipsis, 0)]\n",
      "        getitem_702: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_42[(Ellipsis, 0)]\n",
      "        mul_184: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_701 * getitem_702;  getitem_701 = getitem_702 = None\n",
      "        getitem_703: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_41[(Ellipsis, 1)]\n",
      "        getitem_704: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_42[(Ellipsis, 1)]\n",
      "        mul_185: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_703 * getitem_704;  getitem_703 = getitem_704 = None\n",
      "        sub_41: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_184 - mul_185;  mul_184 = mul_185 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_705: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_41[(Ellipsis, 1)]\n",
      "        getitem_706: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_42[(Ellipsis, 0)]\n",
      "        mul_186: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_705 * getitem_706;  getitem_705 = getitem_706 = None\n",
      "        getitem_707: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_41[(Ellipsis, 0)];  xshaped_41 = None\n",
      "        getitem_708: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_42[(Ellipsis, 1)];  freqs_cis_42 = None\n",
      "        mul_187: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_707 * getitem_708;  getitem_707 = getitem_708 = None\n",
      "        add_131: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_186 + mul_187;  mul_186 = mul_187 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_82: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_41, add_131], -1);  sub_41 = add_131 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_83: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_82.flatten(3);  x_out2_82 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_102: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_83.type_as(k_101);  x_out2_83 = k_101 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_132: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_133: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_40 = l_inference_params_key_value_memory_dict_20_0_.size()\n",
      "        getitem_709 = size_40[0];  getitem_709 = None\n",
      "        getitem_710: \"Sym(s5)\" = size_40[1];  getitem_710 = None\n",
      "        getitem_711 = size_40[2];  getitem_711 = None\n",
      "        getitem_712: \"Sym(s6)\" = size_40[3];  getitem_712 = None\n",
      "        getitem_713 = size_40[4];  size_40 = getitem_713 = None\n",
      "        le_40: \"Sym(True)\" = add_132 <= 2;  le_40 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_41 = l_inference_params_key_value_memory_dict_20_0_.size()\n",
      "        getitem_714 = size_41[0];  getitem_714 = None\n",
      "        getitem_715: \"Sym(s5)\" = size_41[1]\n",
      "        getitem_716 = size_41[2];  getitem_716 = None\n",
      "        getitem_717: \"Sym(s6)\" = size_41[3];  getitem_717 = None\n",
      "        getitem_718 = size_41[4];  size_41 = getitem_718 = None\n",
      "        le_41: \"Sym(s9 + 1 <= s5)\" = add_133 <= getitem_715;  getitem_715 = le_41 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_20_0_[(slice(l_inference_params_batch_size_offset, add_132, None), slice(l_inference_params_seqlen_offset, add_133, None), 0, Ellipsis)] = k_102;  setitem_40 = l_inference_params_key_value_memory_dict_20_0_;  k_102 = setitem_40 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_20_0_[(slice(l_inference_params_batch_size_offset, add_132, None), slice(l_inference_params_seqlen_offset, add_133, None), 1, Ellipsis)] = v_81;  setitem_41 = l_inference_params_key_value_memory_dict_20_0_;  v_81 = setitem_41 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_20: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_20_0_[(slice(l_inference_params_batch_size_offset, add_132, None), slice(None, add_133, None), Ellipsis)];  l_inference_params_key_value_memory_dict_20_0_ = add_132 = add_133 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_20 = kv_20.unbind(dim = -3);  kv_20 = None\n",
      "        k_103: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_20[0]\n",
      "        v_82: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_20[1];  unbind_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_83: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_82.transpose(1, 2);  q_82 = None\n",
      "        k_104: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_103.transpose(1, 2);  k_103 = None\n",
      "        v_83: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_82.transpose(1, 2);  v_82 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_80: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_83, k_104, v_83, is_causal = False, enable_gqa = True);  q_83 = k_104 = v_83 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_83: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_80.transpose(1, 2);  y_80 = None\n",
      "        contiguous_20: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_83.contiguous();  transpose_83 = None\n",
      "        y_81: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_20.view(2, 1, 2048);  contiguous_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_82: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_81, l_self_modules_backbone_modules_layers_modules_20_modules_mixer_modules_out_proj_parameters_weight_, None);  y_81 = l_self_modules_backbone_modules_layers_modules_20_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_40: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_39 + y_82;  x_39 = y_82 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_41: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_40, (2048,), l_self_modules_backbone_modules_layers_modules_20_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_20_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_20_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_20_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_82: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_41, l_self_modules_backbone_modules_layers_modules_20_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_41 = l_self_modules_backbone_modules_layers_modules_20_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_20 = linear_82.chunk(2, dim = -1);  linear_82 = None\n",
      "        y_83: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_20[0]\n",
      "        gate_20: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_20[1];  chunk_20 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_20: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_20);  gate_20 = None\n",
      "        mul_188: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_83 * silu_20;  y_83 = silu_20 = None\n",
      "        linear_83: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_188, l_self_modules_backbone_modules_layers_modules_20_modules_mlp_modules_fc2_parameters_weight_, None);  mul_188 = l_self_modules_backbone_modules_layers_modules_20_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_41: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_40 + linear_83;  x_40 = linear_83 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_42: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_41, (2048,), l_self_modules_backbone_modules_layers_modules_21_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_21_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_21_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_21_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_84: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_42, l_self_modules_backbone_modules_layers_modules_21_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_42 = l_self_modules_backbone_modules_layers_modules_21_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_21 = linear_84.split([2048, 512, 512], dim = -1);  linear_84 = None\n",
      "        q_84: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_21[0]\n",
      "        k_105: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_21[1]\n",
      "        v_84: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_21[2];  split_21 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_85: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_84.view(2, 1, 16, 128);  q_84 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_106: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_105.view(2, 1, 4, 128);  k_105 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_85: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_84.view(2, 1, 4, 128);  v_84 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_43: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_85.float()\n",
      "        xshaped_42: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_43.reshape(2, 1, 16, -1, 2);  float_43 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_43: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_727: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_42[(Ellipsis, 0)]\n",
      "        getitem_728: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_43[(Ellipsis, 0)]\n",
      "        mul_189: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_727 * getitem_728;  getitem_727 = getitem_728 = None\n",
      "        getitem_729: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_42[(Ellipsis, 1)]\n",
      "        getitem_730: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_43[(Ellipsis, 1)]\n",
      "        mul_190: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_729 * getitem_730;  getitem_729 = getitem_730 = None\n",
      "        sub_42: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_189 - mul_190;  mul_189 = mul_190 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_731: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_42[(Ellipsis, 1)]\n",
      "        getitem_732: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_43[(Ellipsis, 0)]\n",
      "        mul_191: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_731 * getitem_732;  getitem_731 = getitem_732 = None\n",
      "        getitem_733: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_42[(Ellipsis, 0)];  xshaped_42 = None\n",
      "        getitem_734: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_43[(Ellipsis, 1)];  freqs_cis_43 = None\n",
      "        mul_192: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_733 * getitem_734;  getitem_733 = getitem_734 = None\n",
      "        add_136: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_191 + mul_192;  mul_191 = mul_192 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_84: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_42, add_136], -1);  sub_42 = add_136 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_85: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_84.flatten(3);  x_out2_84 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_86: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_85.type_as(q_85);  x_out2_85 = q_85 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_44: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_106.float()\n",
      "        xshaped_43: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_44.reshape(2, 1, 4, -1, 2);  float_44 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_44: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_735: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_43[(Ellipsis, 0)]\n",
      "        getitem_736: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_44[(Ellipsis, 0)]\n",
      "        mul_193: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_735 * getitem_736;  getitem_735 = getitem_736 = None\n",
      "        getitem_737: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_43[(Ellipsis, 1)]\n",
      "        getitem_738: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_44[(Ellipsis, 1)]\n",
      "        mul_194: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_737 * getitem_738;  getitem_737 = getitem_738 = None\n",
      "        sub_43: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_193 - mul_194;  mul_193 = mul_194 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_739: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_43[(Ellipsis, 1)]\n",
      "        getitem_740: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_44[(Ellipsis, 0)]\n",
      "        mul_195: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_739 * getitem_740;  getitem_739 = getitem_740 = None\n",
      "        getitem_741: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_43[(Ellipsis, 0)];  xshaped_43 = None\n",
      "        getitem_742: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_44[(Ellipsis, 1)];  freqs_cis_44 = None\n",
      "        mul_196: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_741 * getitem_742;  getitem_741 = getitem_742 = None\n",
      "        add_137: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_195 + mul_196;  mul_195 = mul_196 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_86: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_43, add_137], -1);  sub_43 = add_137 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_87: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_86.flatten(3);  x_out2_86 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_107: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_87.type_as(k_106);  x_out2_87 = k_106 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_138: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_139: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_42 = l_inference_params_key_value_memory_dict_21_0_.size()\n",
      "        getitem_743 = size_42[0];  getitem_743 = None\n",
      "        getitem_744: \"Sym(s5)\" = size_42[1];  getitem_744 = None\n",
      "        getitem_745 = size_42[2];  getitem_745 = None\n",
      "        getitem_746: \"Sym(s6)\" = size_42[3];  getitem_746 = None\n",
      "        getitem_747 = size_42[4];  size_42 = getitem_747 = None\n",
      "        le_42: \"Sym(True)\" = add_138 <= 2;  le_42 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_43 = l_inference_params_key_value_memory_dict_21_0_.size()\n",
      "        getitem_748 = size_43[0];  getitem_748 = None\n",
      "        getitem_749: \"Sym(s5)\" = size_43[1]\n",
      "        getitem_750 = size_43[2];  getitem_750 = None\n",
      "        getitem_751: \"Sym(s6)\" = size_43[3];  getitem_751 = None\n",
      "        getitem_752 = size_43[4];  size_43 = getitem_752 = None\n",
      "        le_43: \"Sym(s9 + 1 <= s5)\" = add_139 <= getitem_749;  getitem_749 = le_43 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_21_0_[(slice(l_inference_params_batch_size_offset, add_138, None), slice(l_inference_params_seqlen_offset, add_139, None), 0, Ellipsis)] = k_107;  setitem_42 = l_inference_params_key_value_memory_dict_21_0_;  k_107 = setitem_42 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_21_0_[(slice(l_inference_params_batch_size_offset, add_138, None), slice(l_inference_params_seqlen_offset, add_139, None), 1, Ellipsis)] = v_85;  setitem_43 = l_inference_params_key_value_memory_dict_21_0_;  v_85 = setitem_43 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_21: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_21_0_[(slice(l_inference_params_batch_size_offset, add_138, None), slice(None, add_139, None), Ellipsis)];  l_inference_params_key_value_memory_dict_21_0_ = add_138 = add_139 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_21 = kv_21.unbind(dim = -3);  kv_21 = None\n",
      "        k_108: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_21[0]\n",
      "        v_86: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_21[1];  unbind_21 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_87: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_86.transpose(1, 2);  q_86 = None\n",
      "        k_109: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_108.transpose(1, 2);  k_108 = None\n",
      "        v_87: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_86.transpose(1, 2);  v_86 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_84: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_87, k_109, v_87, is_causal = False, enable_gqa = True);  q_87 = k_109 = v_87 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_87: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_84.transpose(1, 2);  y_84 = None\n",
      "        contiguous_21: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_87.contiguous();  transpose_87 = None\n",
      "        y_85: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_21.view(2, 1, 2048);  contiguous_21 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_86: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_85, l_self_modules_backbone_modules_layers_modules_21_modules_mixer_modules_out_proj_parameters_weight_, None);  y_85 = l_self_modules_backbone_modules_layers_modules_21_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_42: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_41 + y_86;  x_41 = y_86 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_43: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_42, (2048,), l_self_modules_backbone_modules_layers_modules_21_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_21_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_21_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_21_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_86: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_43, l_self_modules_backbone_modules_layers_modules_21_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_43 = l_self_modules_backbone_modules_layers_modules_21_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_21 = linear_86.chunk(2, dim = -1);  linear_86 = None\n",
      "        y_87: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_21[0]\n",
      "        gate_21: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_21[1];  chunk_21 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_21: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_21);  gate_21 = None\n",
      "        mul_197: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_87 * silu_21;  y_87 = silu_21 = None\n",
      "        linear_87: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_197, l_self_modules_backbone_modules_layers_modules_21_modules_mlp_modules_fc2_parameters_weight_, None);  mul_197 = l_self_modules_backbone_modules_layers_modules_21_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_43: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_42 + linear_87;  x_42 = linear_87 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_44: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_43, (2048,), l_self_modules_backbone_modules_layers_modules_22_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_22_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_22_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_22_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_88: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_44, l_self_modules_backbone_modules_layers_modules_22_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_44 = l_self_modules_backbone_modules_layers_modules_22_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_22 = linear_88.split([2048, 512, 512], dim = -1);  linear_88 = None\n",
      "        q_88: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_22[0]\n",
      "        k_110: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_22[1]\n",
      "        v_88: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_22[2];  split_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_89: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_88.view(2, 1, 16, 128);  q_88 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_111: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_110.view(2, 1, 4, 128);  k_110 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_89: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_88.view(2, 1, 4, 128);  v_88 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_45: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_89.float()\n",
      "        xshaped_44: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_45.reshape(2, 1, 16, -1, 2);  float_45 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_45: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_761: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_44[(Ellipsis, 0)]\n",
      "        getitem_762: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_45[(Ellipsis, 0)]\n",
      "        mul_198: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_761 * getitem_762;  getitem_761 = getitem_762 = None\n",
      "        getitem_763: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_44[(Ellipsis, 1)]\n",
      "        getitem_764: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_45[(Ellipsis, 1)]\n",
      "        mul_199: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_763 * getitem_764;  getitem_763 = getitem_764 = None\n",
      "        sub_44: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_198 - mul_199;  mul_198 = mul_199 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_765: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_44[(Ellipsis, 1)]\n",
      "        getitem_766: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_45[(Ellipsis, 0)]\n",
      "        mul_200: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_765 * getitem_766;  getitem_765 = getitem_766 = None\n",
      "        getitem_767: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_44[(Ellipsis, 0)];  xshaped_44 = None\n",
      "        getitem_768: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_45[(Ellipsis, 1)];  freqs_cis_45 = None\n",
      "        mul_201: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_767 * getitem_768;  getitem_767 = getitem_768 = None\n",
      "        add_142: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_200 + mul_201;  mul_200 = mul_201 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_88: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_44, add_142], -1);  sub_44 = add_142 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_89: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_88.flatten(3);  x_out2_88 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_90: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_89.type_as(q_89);  x_out2_89 = q_89 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_46: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_111.float()\n",
      "        xshaped_45: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_46.reshape(2, 1, 4, -1, 2);  float_46 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_46: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_769: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_45[(Ellipsis, 0)]\n",
      "        getitem_770: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_46[(Ellipsis, 0)]\n",
      "        mul_202: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_769 * getitem_770;  getitem_769 = getitem_770 = None\n",
      "        getitem_771: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_45[(Ellipsis, 1)]\n",
      "        getitem_772: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_46[(Ellipsis, 1)]\n",
      "        mul_203: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_771 * getitem_772;  getitem_771 = getitem_772 = None\n",
      "        sub_45: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_202 - mul_203;  mul_202 = mul_203 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_773: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_45[(Ellipsis, 1)]\n",
      "        getitem_774: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_46[(Ellipsis, 0)]\n",
      "        mul_204: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_773 * getitem_774;  getitem_773 = getitem_774 = None\n",
      "        getitem_775: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_45[(Ellipsis, 0)];  xshaped_45 = None\n",
      "        getitem_776: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_46[(Ellipsis, 1)];  freqs_cis_46 = None\n",
      "        mul_205: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_775 * getitem_776;  getitem_775 = getitem_776 = None\n",
      "        add_143: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_204 + mul_205;  mul_204 = mul_205 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_90: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_45, add_143], -1);  sub_45 = add_143 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_91: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_90.flatten(3);  x_out2_90 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_112: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_91.type_as(k_111);  x_out2_91 = k_111 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_144: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_145: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_44 = l_inference_params_key_value_memory_dict_22_0_.size()\n",
      "        getitem_777 = size_44[0];  getitem_777 = None\n",
      "        getitem_778: \"Sym(s5)\" = size_44[1];  getitem_778 = None\n",
      "        getitem_779 = size_44[2];  getitem_779 = None\n",
      "        getitem_780: \"Sym(s6)\" = size_44[3];  getitem_780 = None\n",
      "        getitem_781 = size_44[4];  size_44 = getitem_781 = None\n",
      "        le_44: \"Sym(True)\" = add_144 <= 2;  le_44 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_45 = l_inference_params_key_value_memory_dict_22_0_.size()\n",
      "        getitem_782 = size_45[0];  getitem_782 = None\n",
      "        getitem_783: \"Sym(s5)\" = size_45[1]\n",
      "        getitem_784 = size_45[2];  getitem_784 = None\n",
      "        getitem_785: \"Sym(s6)\" = size_45[3];  getitem_785 = None\n",
      "        getitem_786 = size_45[4];  size_45 = getitem_786 = None\n",
      "        le_45: \"Sym(s9 + 1 <= s5)\" = add_145 <= getitem_783;  getitem_783 = le_45 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_22_0_[(slice(l_inference_params_batch_size_offset, add_144, None), slice(l_inference_params_seqlen_offset, add_145, None), 0, Ellipsis)] = k_112;  setitem_44 = l_inference_params_key_value_memory_dict_22_0_;  k_112 = setitem_44 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_22_0_[(slice(l_inference_params_batch_size_offset, add_144, None), slice(l_inference_params_seqlen_offset, add_145, None), 1, Ellipsis)] = v_89;  setitem_45 = l_inference_params_key_value_memory_dict_22_0_;  v_89 = setitem_45 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_22: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_22_0_[(slice(l_inference_params_batch_size_offset, add_144, None), slice(None, add_145, None), Ellipsis)];  l_inference_params_key_value_memory_dict_22_0_ = add_144 = add_145 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_22 = kv_22.unbind(dim = -3);  kv_22 = None\n",
      "        k_113: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_22[0]\n",
      "        v_90: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_22[1];  unbind_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_91: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_90.transpose(1, 2);  q_90 = None\n",
      "        k_114: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_113.transpose(1, 2);  k_113 = None\n",
      "        v_91: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_90.transpose(1, 2);  v_90 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_88: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_91, k_114, v_91, is_causal = False, enable_gqa = True);  q_91 = k_114 = v_91 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_91: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_88.transpose(1, 2);  y_88 = None\n",
      "        contiguous_22: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_91.contiguous();  transpose_91 = None\n",
      "        y_89: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_22.view(2, 1, 2048);  contiguous_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_90: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_89, l_self_modules_backbone_modules_layers_modules_22_modules_mixer_modules_out_proj_parameters_weight_, None);  y_89 = l_self_modules_backbone_modules_layers_modules_22_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_44: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_43 + y_90;  x_43 = y_90 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_45: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_44, (2048,), l_self_modules_backbone_modules_layers_modules_22_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_22_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_22_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_22_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_90: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_45, l_self_modules_backbone_modules_layers_modules_22_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_45 = l_self_modules_backbone_modules_layers_modules_22_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_22 = linear_90.chunk(2, dim = -1);  linear_90 = None\n",
      "        y_91: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_22[0]\n",
      "        gate_22: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_22[1];  chunk_22 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_22: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_22);  gate_22 = None\n",
      "        mul_206: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_91 * silu_22;  y_91 = silu_22 = None\n",
      "        linear_91: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_206, l_self_modules_backbone_modules_layers_modules_22_modules_mlp_modules_fc2_parameters_weight_, None);  mul_206 = l_self_modules_backbone_modules_layers_modules_22_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_45: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_44 + linear_91;  x_44 = linear_91 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_46: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_45, (2048,), l_self_modules_backbone_modules_layers_modules_23_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_23_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_23_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_23_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_92: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_46, l_self_modules_backbone_modules_layers_modules_23_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_46 = l_self_modules_backbone_modules_layers_modules_23_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_23 = linear_92.split([2048, 512, 512], dim = -1);  linear_92 = None\n",
      "        q_92: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_23[0]\n",
      "        k_115: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_23[1]\n",
      "        v_92: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_23[2];  split_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_93: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_92.view(2, 1, 16, 128);  q_92 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_116: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_115.view(2, 1, 4, 128);  k_115 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_93: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_92.view(2, 1, 4, 128);  v_92 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_47: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_93.float()\n",
      "        xshaped_46: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_47.reshape(2, 1, 16, -1, 2);  float_47 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_47: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_795: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_46[(Ellipsis, 0)]\n",
      "        getitem_796: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_47[(Ellipsis, 0)]\n",
      "        mul_207: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_795 * getitem_796;  getitem_795 = getitem_796 = None\n",
      "        getitem_797: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_46[(Ellipsis, 1)]\n",
      "        getitem_798: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_47[(Ellipsis, 1)]\n",
      "        mul_208: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_797 * getitem_798;  getitem_797 = getitem_798 = None\n",
      "        sub_46: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_207 - mul_208;  mul_207 = mul_208 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_799: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_46[(Ellipsis, 1)]\n",
      "        getitem_800: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_47[(Ellipsis, 0)]\n",
      "        mul_209: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_799 * getitem_800;  getitem_799 = getitem_800 = None\n",
      "        getitem_801: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_46[(Ellipsis, 0)];  xshaped_46 = None\n",
      "        getitem_802: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_47[(Ellipsis, 1)];  freqs_cis_47 = None\n",
      "        mul_210: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_801 * getitem_802;  getitem_801 = getitem_802 = None\n",
      "        add_148: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_209 + mul_210;  mul_209 = mul_210 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_92: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_46, add_148], -1);  sub_46 = add_148 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_93: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_92.flatten(3);  x_out2_92 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_94: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_93.type_as(q_93);  x_out2_93 = q_93 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_48: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_116.float()\n",
      "        xshaped_47: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_48.reshape(2, 1, 4, -1, 2);  float_48 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_48: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_803: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_47[(Ellipsis, 0)]\n",
      "        getitem_804: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_48[(Ellipsis, 0)]\n",
      "        mul_211: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_803 * getitem_804;  getitem_803 = getitem_804 = None\n",
      "        getitem_805: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_47[(Ellipsis, 1)]\n",
      "        getitem_806: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_48[(Ellipsis, 1)]\n",
      "        mul_212: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_805 * getitem_806;  getitem_805 = getitem_806 = None\n",
      "        sub_47: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_211 - mul_212;  mul_211 = mul_212 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_807: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_47[(Ellipsis, 1)]\n",
      "        getitem_808: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_48[(Ellipsis, 0)]\n",
      "        mul_213: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_807 * getitem_808;  getitem_807 = getitem_808 = None\n",
      "        getitem_809: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_47[(Ellipsis, 0)];  xshaped_47 = None\n",
      "        getitem_810: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_48[(Ellipsis, 1)];  freqs_cis_48 = None\n",
      "        mul_214: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_809 * getitem_810;  getitem_809 = getitem_810 = None\n",
      "        add_149: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_213 + mul_214;  mul_213 = mul_214 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_94: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_47, add_149], -1);  sub_47 = add_149 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_95: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_94.flatten(3);  x_out2_94 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_117: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_95.type_as(k_116);  x_out2_95 = k_116 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_150: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_151: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_46 = l_inference_params_key_value_memory_dict_23_0_.size()\n",
      "        getitem_811 = size_46[0];  getitem_811 = None\n",
      "        getitem_812: \"Sym(s5)\" = size_46[1];  getitem_812 = None\n",
      "        getitem_813 = size_46[2];  getitem_813 = None\n",
      "        getitem_814: \"Sym(s6)\" = size_46[3];  getitem_814 = None\n",
      "        getitem_815 = size_46[4];  size_46 = getitem_815 = None\n",
      "        le_46: \"Sym(True)\" = add_150 <= 2;  le_46 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_47 = l_inference_params_key_value_memory_dict_23_0_.size()\n",
      "        getitem_816 = size_47[0];  getitem_816 = None\n",
      "        getitem_817: \"Sym(s5)\" = size_47[1]\n",
      "        getitem_818 = size_47[2];  getitem_818 = None\n",
      "        getitem_819: \"Sym(s6)\" = size_47[3];  getitem_819 = None\n",
      "        getitem_820 = size_47[4];  size_47 = getitem_820 = None\n",
      "        le_47: \"Sym(s9 + 1 <= s5)\" = add_151 <= getitem_817;  getitem_817 = le_47 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_23_0_[(slice(l_inference_params_batch_size_offset, add_150, None), slice(l_inference_params_seqlen_offset, add_151, None), 0, Ellipsis)] = k_117;  setitem_46 = l_inference_params_key_value_memory_dict_23_0_;  k_117 = setitem_46 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_23_0_[(slice(l_inference_params_batch_size_offset, add_150, None), slice(l_inference_params_seqlen_offset, add_151, None), 1, Ellipsis)] = v_93;  setitem_47 = l_inference_params_key_value_memory_dict_23_0_;  v_93 = setitem_47 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_23: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_23_0_[(slice(l_inference_params_batch_size_offset, add_150, None), slice(None, add_151, None), Ellipsis)];  l_inference_params_key_value_memory_dict_23_0_ = add_150 = add_151 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_23 = kv_23.unbind(dim = -3);  kv_23 = None\n",
      "        k_118: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_23[0]\n",
      "        v_94: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_23[1];  unbind_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_95: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_94.transpose(1, 2);  q_94 = None\n",
      "        k_119: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_118.transpose(1, 2);  k_118 = None\n",
      "        v_95: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_94.transpose(1, 2);  v_94 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_92: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_95, k_119, v_95, is_causal = False, enable_gqa = True);  q_95 = k_119 = v_95 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_95: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_92.transpose(1, 2);  y_92 = None\n",
      "        contiguous_23: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_95.contiguous();  transpose_95 = None\n",
      "        y_93: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_23.view(2, 1, 2048);  contiguous_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_94: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_93, l_self_modules_backbone_modules_layers_modules_23_modules_mixer_modules_out_proj_parameters_weight_, None);  y_93 = l_self_modules_backbone_modules_layers_modules_23_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_46: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_45 + y_94;  x_45 = y_94 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_47: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_46, (2048,), l_self_modules_backbone_modules_layers_modules_23_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_23_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_23_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_23_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_94: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_47, l_self_modules_backbone_modules_layers_modules_23_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_47 = l_self_modules_backbone_modules_layers_modules_23_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_23 = linear_94.chunk(2, dim = -1);  linear_94 = None\n",
      "        y_95: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_23[0]\n",
      "        gate_23: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_23[1];  chunk_23 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_23: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_23);  gate_23 = None\n",
      "        mul_215: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_95 * silu_23;  y_95 = silu_23 = None\n",
      "        linear_95: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_215, l_self_modules_backbone_modules_layers_modules_23_modules_mlp_modules_fc2_parameters_weight_, None);  mul_215 = l_self_modules_backbone_modules_layers_modules_23_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_47: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_46 + linear_95;  x_46 = linear_95 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_48: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_47, (2048,), l_self_modules_backbone_modules_layers_modules_24_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_24_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_24_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_24_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_96: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_48, l_self_modules_backbone_modules_layers_modules_24_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_48 = l_self_modules_backbone_modules_layers_modules_24_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_24 = linear_96.split([2048, 512, 512], dim = -1);  linear_96 = None\n",
      "        q_96: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_24[0]\n",
      "        k_120: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_24[1]\n",
      "        v_96: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_24[2];  split_24 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_97: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_96.view(2, 1, 16, 128);  q_96 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_121: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_120.view(2, 1, 4, 128);  k_120 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_97: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_96.view(2, 1, 4, 128);  v_96 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_49: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_97.float()\n",
      "        xshaped_48: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_49.reshape(2, 1, 16, -1, 2);  float_49 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_49: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_829: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_48[(Ellipsis, 0)]\n",
      "        getitem_830: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_49[(Ellipsis, 0)]\n",
      "        mul_216: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_829 * getitem_830;  getitem_829 = getitem_830 = None\n",
      "        getitem_831: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_48[(Ellipsis, 1)]\n",
      "        getitem_832: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_49[(Ellipsis, 1)]\n",
      "        mul_217: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_831 * getitem_832;  getitem_831 = getitem_832 = None\n",
      "        sub_48: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_216 - mul_217;  mul_216 = mul_217 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_833: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_48[(Ellipsis, 1)]\n",
      "        getitem_834: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_49[(Ellipsis, 0)]\n",
      "        mul_218: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_833 * getitem_834;  getitem_833 = getitem_834 = None\n",
      "        getitem_835: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_48[(Ellipsis, 0)];  xshaped_48 = None\n",
      "        getitem_836: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_49[(Ellipsis, 1)];  freqs_cis_49 = None\n",
      "        mul_219: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_835 * getitem_836;  getitem_835 = getitem_836 = None\n",
      "        add_154: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_218 + mul_219;  mul_218 = mul_219 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_96: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_48, add_154], -1);  sub_48 = add_154 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_97: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_96.flatten(3);  x_out2_96 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_98: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_97.type_as(q_97);  x_out2_97 = q_97 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_50: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_121.float()\n",
      "        xshaped_49: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_50.reshape(2, 1, 4, -1, 2);  float_50 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_50: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_837: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_49[(Ellipsis, 0)]\n",
      "        getitem_838: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_50[(Ellipsis, 0)]\n",
      "        mul_220: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_837 * getitem_838;  getitem_837 = getitem_838 = None\n",
      "        getitem_839: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_49[(Ellipsis, 1)]\n",
      "        getitem_840: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_50[(Ellipsis, 1)]\n",
      "        mul_221: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_839 * getitem_840;  getitem_839 = getitem_840 = None\n",
      "        sub_49: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_220 - mul_221;  mul_220 = mul_221 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_841: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_49[(Ellipsis, 1)]\n",
      "        getitem_842: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_50[(Ellipsis, 0)]\n",
      "        mul_222: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_841 * getitem_842;  getitem_841 = getitem_842 = None\n",
      "        getitem_843: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_49[(Ellipsis, 0)];  xshaped_49 = None\n",
      "        getitem_844: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_50[(Ellipsis, 1)];  freqs_cis_50 = None\n",
      "        mul_223: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_843 * getitem_844;  getitem_843 = getitem_844 = None\n",
      "        add_155: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_222 + mul_223;  mul_222 = mul_223 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_98: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_49, add_155], -1);  sub_49 = add_155 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_99: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_98.flatten(3);  x_out2_98 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_122: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_99.type_as(k_121);  x_out2_99 = k_121 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_156: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_157: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_48 = l_inference_params_key_value_memory_dict_24_0_.size()\n",
      "        getitem_845 = size_48[0];  getitem_845 = None\n",
      "        getitem_846: \"Sym(s5)\" = size_48[1];  getitem_846 = None\n",
      "        getitem_847 = size_48[2];  getitem_847 = None\n",
      "        getitem_848: \"Sym(s6)\" = size_48[3];  getitem_848 = None\n",
      "        getitem_849 = size_48[4];  size_48 = getitem_849 = None\n",
      "        le_48: \"Sym(True)\" = add_156 <= 2;  le_48 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_49 = l_inference_params_key_value_memory_dict_24_0_.size()\n",
      "        getitem_850 = size_49[0];  getitem_850 = None\n",
      "        getitem_851: \"Sym(s5)\" = size_49[1]\n",
      "        getitem_852 = size_49[2];  getitem_852 = None\n",
      "        getitem_853: \"Sym(s6)\" = size_49[3];  getitem_853 = None\n",
      "        getitem_854 = size_49[4];  size_49 = getitem_854 = None\n",
      "        le_49: \"Sym(s9 + 1 <= s5)\" = add_157 <= getitem_851;  getitem_851 = le_49 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_24_0_[(slice(l_inference_params_batch_size_offset, add_156, None), slice(l_inference_params_seqlen_offset, add_157, None), 0, Ellipsis)] = k_122;  setitem_48 = l_inference_params_key_value_memory_dict_24_0_;  k_122 = setitem_48 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_24_0_[(slice(l_inference_params_batch_size_offset, add_156, None), slice(l_inference_params_seqlen_offset, add_157, None), 1, Ellipsis)] = v_97;  setitem_49 = l_inference_params_key_value_memory_dict_24_0_;  v_97 = setitem_49 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_24: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_24_0_[(slice(l_inference_params_batch_size_offset, add_156, None), slice(None, add_157, None), Ellipsis)];  l_inference_params_key_value_memory_dict_24_0_ = add_156 = add_157 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_24 = kv_24.unbind(dim = -3);  kv_24 = None\n",
      "        k_123: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_24[0]\n",
      "        v_98: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_24[1];  unbind_24 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_99: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_98.transpose(1, 2);  q_98 = None\n",
      "        k_124: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_123.transpose(1, 2);  k_123 = None\n",
      "        v_99: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_98.transpose(1, 2);  v_98 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_96: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_99, k_124, v_99, is_causal = False, enable_gqa = True);  q_99 = k_124 = v_99 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_99: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_96.transpose(1, 2);  y_96 = None\n",
      "        contiguous_24: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_99.contiguous();  transpose_99 = None\n",
      "        y_97: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_24.view(2, 1, 2048);  contiguous_24 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_98: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_97, l_self_modules_backbone_modules_layers_modules_24_modules_mixer_modules_out_proj_parameters_weight_, None);  y_97 = l_self_modules_backbone_modules_layers_modules_24_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_48: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_47 + y_98;  x_47 = y_98 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_49: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_48, (2048,), l_self_modules_backbone_modules_layers_modules_24_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_24_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_24_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_24_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_98: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_49, l_self_modules_backbone_modules_layers_modules_24_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_49 = l_self_modules_backbone_modules_layers_modules_24_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_24 = linear_98.chunk(2, dim = -1);  linear_98 = None\n",
      "        y_99: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_24[0]\n",
      "        gate_24: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_24[1];  chunk_24 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_24: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_24);  gate_24 = None\n",
      "        mul_224: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_99 * silu_24;  y_99 = silu_24 = None\n",
      "        linear_99: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_224, l_self_modules_backbone_modules_layers_modules_24_modules_mlp_modules_fc2_parameters_weight_, None);  mul_224 = l_self_modules_backbone_modules_layers_modules_24_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_49: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_48 + linear_99;  x_48 = linear_99 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        layer_norm_50: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_49, (2048,), l_self_modules_backbone_modules_layers_modules_25_modules_norm_parameters_weight_, l_self_modules_backbone_modules_layers_modules_25_modules_norm_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_25_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_25_modules_norm_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:122 in forward, code: q, k, v = self.in_proj(x).split([q_size, kv_size, kv_size], dim=-1)\n",
      "        linear_100: \"bf16[2, 1, 3072][3072, 3072, 1]cpu\" = torch._C._nn.linear(layer_norm_50, l_self_modules_backbone_modules_layers_modules_25_modules_mixer_modules_in_proj_parameters_weight_, None);  layer_norm_50 = l_self_modules_backbone_modules_layers_modules_25_modules_mixer_modules_in_proj_parameters_weight_ = None\n",
      "        split_25 = linear_100.split([2048, 512, 512], dim = -1);  linear_100 = None\n",
      "        q_100: \"bf16[2, 1, 2048][3072, 3072, 1]cpu\" = split_25[0]\n",
      "        k_125: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_25[1]\n",
      "        v_100: \"bf16[2, 1, 512][3072, 3072, 1]cpu\" = split_25[2];  split_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:124 in forward, code: q = q.view(batch_size, seqlen, self.num_heads, self.head_dim)\n",
      "        q_101: \"bf16[2, 1, 16, 128][3072, 3072, 128, 1]cpu\" = q_100.view(2, 1, 16, 128);  q_100 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:125 in forward, code: k = k.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        k_126: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = k_125.view(2, 1, 4, 128);  k_125 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:126 in forward, code: v = v.view(batch_size, seqlen, self.num_heads_kv, self.head_dim)\n",
      "        v_101: \"bf16[2, 1, 4, 128][3072, 3072, 128, 1]cpu\" = v_100.view(2, 1, 4, 128);  v_100 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_51: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = q_101.float()\n",
      "        xshaped_50: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = float_51.reshape(2, 1, 16, -1, 2);  float_51 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_51: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2)\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_863: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_50[(Ellipsis, 0)]\n",
      "        getitem_864: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_51[(Ellipsis, 0)]\n",
      "        mul_225: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_863 * getitem_864;  getitem_863 = getitem_864 = None\n",
      "        getitem_865: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_50[(Ellipsis, 1)]\n",
      "        getitem_866: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_51[(Ellipsis, 1)]\n",
      "        mul_226: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_865 * getitem_866;  getitem_865 = getitem_866 = None\n",
      "        sub_50: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_225 - mul_226;  mul_225 = mul_226 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_867: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_50[(Ellipsis, 1)]\n",
      "        getitem_868: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_51[(Ellipsis, 0)]\n",
      "        mul_227: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_867 * getitem_868;  getitem_867 = getitem_868 = None\n",
      "        getitem_869: \"f32[2, 1, 16, 64][2048, 2048, 128, 2]cpu\" = xshaped_50[(Ellipsis, 0)];  xshaped_50 = None\n",
      "        getitem_870: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_51[(Ellipsis, 1)];  freqs_cis_51 = None\n",
      "        mul_228: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = getitem_869 * getitem_870;  getitem_869 = getitem_870 = None\n",
      "        add_160: \"f32[2, 1, 16, 64][1024, 1024, 64, 1]cpu\" = mul_227 + mul_228;  mul_227 = mul_228 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_100: \"f32[2, 1, 16, 64, 2][2048, 2048, 128, 2, 1]cpu\" = torch.stack([sub_50, add_160], -1);  sub_50 = add_160 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_101: \"f32[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_100.flatten(3);  x_out2_100 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        q_102: \"bf16[2, 1, 16, 128][2048, 2048, 128, 1]cpu\" = x_out2_101.type_as(q_101);  x_out2_101 = q_101 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:19 in apply_rotary_emb, code: xshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
      "        float_52: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = k_126.float()\n",
      "        xshaped_51: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = float_52.reshape(2, 1, 4, -1, 2);  float_52 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:20 in apply_rotary_emb, code: freqs_cis = freqs_cis.view(-1, xshaped.size(1), 1, xshaped.size(3), 2)\n",
      "        freqs_cis_52: \"f32[2, 1, 1, 64, 2][128, 128, 128, 2, 1]cpu\" = freqs_cis.view(-1, 1, 1, 64, 2);  freqs_cis = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:23 in apply_rotary_emb, code: xshaped[..., 0] * freqs_cis[..., 0] - xshaped[..., 1] * freqs_cis[..., 1],\n",
      "        getitem_871: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_51[(Ellipsis, 0)]\n",
      "        getitem_872: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_52[(Ellipsis, 0)]\n",
      "        mul_229: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_871 * getitem_872;  getitem_871 = getitem_872 = None\n",
      "        getitem_873: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_51[(Ellipsis, 1)]\n",
      "        getitem_874: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_52[(Ellipsis, 1)]\n",
      "        mul_230: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_873 * getitem_874;  getitem_873 = getitem_874 = None\n",
      "        sub_51: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_229 - mul_230;  mul_229 = mul_230 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:24 in apply_rotary_emb, code: xshaped[..., 1] * freqs_cis[..., 0] + xshaped[..., 0] * freqs_cis[..., 1],\n",
      "        getitem_875: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_51[(Ellipsis, 1)]\n",
      "        getitem_876: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_52[(Ellipsis, 0)]\n",
      "        mul_231: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_875 * getitem_876;  getitem_875 = getitem_876 = None\n",
      "        getitem_877: \"f32[2, 1, 4, 64][512, 512, 128, 2]cpu\" = xshaped_51[(Ellipsis, 0)];  xshaped_51 = None\n",
      "        getitem_878: \"f32[2, 1, 1, 64][128, 128, 128, 2]cpu\" = freqs_cis_52[(Ellipsis, 1)];  freqs_cis_52 = None\n",
      "        mul_232: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = getitem_877 * getitem_878;  getitem_877 = getitem_878 = None\n",
      "        add_161: \"f32[2, 1, 4, 64][256, 256, 64, 1]cpu\" = mul_231 + mul_232;  mul_231 = mul_232 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:21 in apply_rotary_emb, code: x_out2 = torch.stack(\n",
      "        x_out2_102: \"f32[2, 1, 4, 64, 2][512, 512, 128, 2, 1]cpu\" = torch.stack([sub_51, add_161], -1);  sub_51 = add_161 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:29 in apply_rotary_emb, code: x_out2 = x_out2.flatten(3)\n",
      "        x_out2_103: \"f32[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_102.flatten(3);  x_out2_102 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:30 in apply_rotary_emb, code: return x_out2.type_as(x)\n",
      "        k_127: \"bf16[2, 1, 4, 128][512, 512, 128, 1]cpu\" = x_out2_103.type_as(k_126);  x_out2_103 = k_126 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:41 in _update_kv_cache, code: batch_end = batch_start + k.shape[0]\n",
      "        add_162: \"Sym(2)\" = l_inference_params_batch_size_offset + 2\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:43 in _update_kv_cache, code: sequence_end = sequence_start + k.shape[1]\n",
      "        add_163: \"Sym(s9 + 1)\" = l_inference_params_seqlen_offset + 1\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:44 in _update_kv_cache, code: assert batch_end <= kv_cache.shape[0]\n",
      "        size_50 = l_inference_params_key_value_memory_dict_25_0_.size()\n",
      "        getitem_879 = size_50[0];  getitem_879 = None\n",
      "        getitem_880: \"Sym(s5)\" = size_50[1];  getitem_880 = None\n",
      "        getitem_881 = size_50[2];  getitem_881 = None\n",
      "        getitem_882: \"Sym(s6)\" = size_50[3];  getitem_882 = None\n",
      "        getitem_883 = size_50[4];  size_50 = getitem_883 = None\n",
      "        le_50: \"Sym(True)\" = add_162 <= 2;  le_50 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:45 in _update_kv_cache, code: assert sequence_end <= kv_cache.shape[1]\n",
      "        size_51 = l_inference_params_key_value_memory_dict_25_0_.size()\n",
      "        getitem_884 = size_51[0];  getitem_884 = None\n",
      "        getitem_885: \"Sym(s5)\" = size_51[1]\n",
      "        getitem_886 = size_51[2];  getitem_886 = None\n",
      "        getitem_887: \"Sym(s6)\" = size_51[3];  getitem_887 = None\n",
      "        getitem_888 = size_51[4];  size_51 = getitem_888 = None\n",
      "        le_51: \"Sym(s9 + 1 <= s5)\" = add_163 <= getitem_885;  getitem_885 = le_51 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:47 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 0, ...] = k\n",
      "        l_inference_params_key_value_memory_dict_25_0_[(slice(l_inference_params_batch_size_offset, add_162, None), slice(l_inference_params_seqlen_offset, add_163, None), 0, Ellipsis)] = k_127;  setitem_50 = l_inference_params_key_value_memory_dict_25_0_;  k_127 = setitem_50 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:48 in _update_kv_cache, code: kv_cache[batch_start:batch_end, sequence_start:sequence_end, 1, ...] = v\n",
      "        l_inference_params_key_value_memory_dict_25_0_[(slice(l_inference_params_batch_size_offset, add_162, None), slice(l_inference_params_seqlen_offset, add_163, None), 1, Ellipsis)] = v_101;  setitem_51 = l_inference_params_key_value_memory_dict_25_0_;  l_inference_params_seqlen_offset = v_101 = setitem_51 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:49 in _update_kv_cache, code: return kv_cache[batch_start:batch_end, :sequence_end, ...]\n",
      "        kv_25: \"bf16[2, s9 + 1, 2, s6, 128][256*s5*s6, 256*s6, 128*s6, 128, 1]cpu\" = l_inference_params_key_value_memory_dict_25_0_[(slice(l_inference_params_batch_size_offset, add_162, None), slice(None, add_163, None), Ellipsis)];  l_inference_params_key_value_memory_dict_25_0_ = l_inference_params_batch_size_offset = add_162 = add_163 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:132 in forward, code: k, v = kv.unbind(dim=-3)\n",
      "        unbind_25 = kv_25.unbind(dim = -3);  kv_25 = None\n",
      "        k_128: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_25[0]\n",
      "        v_102: \"bf16[2, s9 + 1, s6, 128][256*s5*s6, 256*s6, 128, 1]cpu\" = unbind_25[1];  unbind_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:134 in <lambda>, code: q, k, v = map(lambda x: x.transpose(1, 2), (q, k, v))\n",
      "        q_103: \"bf16[2, 16, 1, 128][2048, 128, 2048, 1]cpu\" = q_102.transpose(1, 2);  q_102 = None\n",
      "        k_129: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = k_128.transpose(1, 2);  k_128 = None\n",
      "        v_103: \"bf16[2, s6, s9 + 1, 128][256*s5*s6, 128, 256*s6, 1]cpu\" = v_102.transpose(1, 2);  v_102 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:136 in forward, code: y = F.scaled_dot_product_attention(q, k, v, is_causal=seqlen > 1, enable_gqa=True)\n",
      "        y_100: \"bf16[2, 16, 1, 128][2048, 128, 128, 1]cpu\" = torch._C._nn.scaled_dot_product_attention(q_103, k_129, v_103, is_causal = False, enable_gqa = True);  q_103 = k_129 = v_103 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:138 in forward, code: y = y.transpose(1, 2).contiguous().view(batch_size, seqlen, q_size)\n",
      "        transpose_103: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = y_100.transpose(1, 2);  y_100 = None\n",
      "        contiguous_25: \"bf16[2, 1, 16, 128][2048, 128, 128, 1]cpu\" = transpose_103.contiguous();  transpose_103 = None\n",
      "        y_101: \"bf16[2, 1, 2048][2048, 128, 1]cpu\" = contiguous_25.view(2, 1, 2048);  contiguous_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:140 in forward, code: y = self.out_proj(y)\n",
      "        y_102: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(y_101, l_self_modules_backbone_modules_layers_modules_25_modules_mixer_modules_out_proj_parameters_weight_, None);  y_101 = l_self_modules_backbone_modules_layers_modules_25_modules_mixer_modules_out_proj_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:100 in forward, code: x = x + self.mixer(self.norm(x), inference_params, freqs_cis)\n",
      "        x_50: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_49 + y_102;  x_49 = y_102 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        layer_norm_51: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_50, (2048,), l_self_modules_backbone_modules_layers_modules_25_modules_norm2_parameters_weight_, l_self_modules_backbone_modules_layers_modules_25_modules_norm2_parameters_bias_, 1e-05);  l_self_modules_backbone_modules_layers_modules_25_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_layers_modules_25_modules_norm2_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:151 in forward, code: y, gate = self.fc1(x).chunk(2, dim=-1)\n",
      "        linear_102: \"bf16[2, 1, 16384][16384, 16384, 1]cpu\" = torch._C._nn.linear(layer_norm_51, l_self_modules_backbone_modules_layers_modules_25_modules_mlp_modules_fc1_parameters_weight_, None);  layer_norm_51 = l_self_modules_backbone_modules_layers_modules_25_modules_mlp_modules_fc1_parameters_weight_ = None\n",
      "        chunk_25 = linear_102.chunk(2, dim = -1);  linear_102 = None\n",
      "        y_103: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_25[0]\n",
      "        gate_25: \"bf16[2, 1, 8192][16384, 16384, 1]cpu\" = chunk_25[1];  chunk_25 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:152 in forward, code: return self.fc2(y * F.silu(gate))\n",
      "        silu_25: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = torch.nn.functional.silu(gate_25);  gate_25 = None\n",
      "        mul_233: \"bf16[2, 1, 8192][8192, 8192, 1]cpu\" = y_103 * silu_25;  y_103 = silu_25 = None\n",
      "        linear_103: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch._C._nn.linear(mul_233, l_self_modules_backbone_modules_layers_modules_25_modules_mlp_modules_fc2_parameters_weight_, None);  mul_233 = l_self_modules_backbone_modules_layers_modules_25_modules_mlp_modules_fc2_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:101 in forward, code: x = x + self.mlp(self.norm2(x))\n",
      "        x_51: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = x_50 + linear_103;  x_50 = linear_103 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/backbone/_torch.py:80 in forward, code: return self.norm_f(hidden_states)\n",
      "        layer_norm_52: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = torch.nn.functional.layer_norm(x_51, (2048,), l_self_modules_backbone_modules_norm_f_parameters_weight_, l_self_modules_backbone_modules_norm_f_parameters_bias_, 1e-05);  x_51 = l_self_modules_backbone_modules_norm_f_parameters_weight_ = l_self_modules_backbone_modules_norm_f_parameters_bias_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:110 in _compute_logits, code: last_hidden_states = self.backbone(hidden_states, inference_params)[:, -1, :].unsqueeze(1)\n",
      "        getitem_894: \"bf16[2, 2048][2048, 1]cpu\" = layer_norm_52[(slice(None, None, None), -1, slice(None, None, None))];  layer_norm_52 = None\n",
      "        last_hidden_states: \"bf16[2, 1, 2048][2048, 2048, 1]cpu\" = getitem_894.unsqueeze(1);  getitem_894 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:101 in <listcomp>, code: return torch.stack([head(hidden_states) for head in self.heads], dim=1)\n",
      "        linear_104: \"bf16[2, 1, 1026][1026, 1026, 1]cpu\" = torch._C._nn.linear(last_hidden_states, l_self_modules_heads_modules_0_parameters_weight_, None);  l_self_modules_heads_modules_0_parameters_weight_ = None\n",
      "        linear_105: \"bf16[2, 1, 1026][1026, 1026, 1]cpu\" = torch._C._nn.linear(last_hidden_states, l_self_modules_heads_modules_1_parameters_weight_, None);  l_self_modules_heads_modules_1_parameters_weight_ = None\n",
      "        linear_106: \"bf16[2, 1, 1026][1026, 1026, 1]cpu\" = torch._C._nn.linear(last_hidden_states, l_self_modules_heads_modules_2_parameters_weight_, None);  l_self_modules_heads_modules_2_parameters_weight_ = None\n",
      "        linear_107: \"bf16[2, 1, 1026][1026, 1026, 1]cpu\" = torch._C._nn.linear(last_hidden_states, l_self_modules_heads_modules_3_parameters_weight_, None);  l_self_modules_heads_modules_3_parameters_weight_ = None\n",
      "        linear_108: \"bf16[2, 1, 1026][1026, 1026, 1]cpu\" = torch._C._nn.linear(last_hidden_states, l_self_modules_heads_modules_4_parameters_weight_, None);  l_self_modules_heads_modules_4_parameters_weight_ = None\n",
      "        linear_109: \"bf16[2, 1, 1026][1026, 1026, 1]cpu\" = torch._C._nn.linear(last_hidden_states, l_self_modules_heads_modules_5_parameters_weight_, None);  l_self_modules_heads_modules_5_parameters_weight_ = None\n",
      "        linear_110: \"bf16[2, 1, 1026][1026, 1026, 1]cpu\" = torch._C._nn.linear(last_hidden_states, l_self_modules_heads_modules_6_parameters_weight_, None);  l_self_modules_heads_modules_6_parameters_weight_ = None\n",
      "        linear_111: \"bf16[2, 1, 1026][1026, 1026, 1]cpu\" = torch._C._nn.linear(last_hidden_states, l_self_modules_heads_modules_7_parameters_weight_, None);  l_self_modules_heads_modules_7_parameters_weight_ = None\n",
      "        linear_112: \"bf16[2, 1, 1026][1026, 1026, 1]cpu\" = torch._C._nn.linear(last_hidden_states, l_self_modules_heads_modules_8_parameters_weight_, None);  last_hidden_states = l_self_modules_heads_modules_8_parameters_weight_ = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:101 in apply_heads, code: return torch.stack([head(hidden_states) for head in self.heads], dim=1)\n",
      "        stack_52: \"bf16[2, 9, 1, 1026][9234, 1026, 1026, 1]cpu\" = torch.stack([linear_104, linear_105, linear_106, linear_107, linear_108, linear_109, linear_110, linear_111, linear_112], dim = 1);  linear_104 = linear_105 = linear_106 = linear_107 = linear_108 = linear_109 = linear_110 = linear_111 = linear_112 = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:111 in _compute_logits, code: logits = self.apply_heads(last_hidden_states).squeeze(2).float()\n",
      "        squeeze: \"bf16[2, 9, 1026][9234, 1026, 1]cpu\" = stack_52.squeeze(2);  stack_52 = None\n",
      "        logits: \"f32[2, 9, 1026][9234, 1026, 1]cpu\" = squeeze.float();  squeeze = logits = None\n",
      "        \n",
      "         # File: /home/ems2359/ttsmodels/zonos/model.py:112 in _compute_logits, code: if cfg_scale != 1.0:\n",
      "        ne: \"b8[][]cpu\" = l_cfg_scale_ != 1.0;  l_cfg_scale_ = ne = None\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from zonos.model import Zonos\n",
    "from zonos.conditioning import make_cond_dict\n",
    "from zonos.utils import DEFAULT_DEVICE as device\n",
    "\n",
    "print(\"ðŸ”¹ Loading model...\")\n",
    "model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=device)\n",
    "\n",
    "print(\"ðŸ”¹ Loading reference audio...\")\n",
    "wav, sampling_rate = torchaudio.load(\"assets/exampleaudio.mp3\")\n",
    "\n",
    "print(\"ðŸ”¹ Creating speaker embedding...\")\n",
    "speaker = model.make_speaker_embedding(wav, sampling_rate)\n",
    "\n",
    "print(\"ðŸ”¹ Preparing conditioning inputs...\")\n",
    "cond_dict = make_cond_dict(text=\"Hello, world!\", speaker=speaker, language=\"en-us\")\n",
    "conditioning = model.prepare_conditioning(cond_dict)\n",
    "\n",
    "print(\"ðŸ”¹ Generating codes...\")\n",
    "codes = model.generate(conditioning)\n",
    "\n",
    "print(\"ðŸ”¹ Decoding waveform...\")\n",
    "wavs = model.autoencoder.decode(codes).cpu()\n",
    "\n",
    "print(\"ðŸ”¹ Saving audio to 'sample.wav'...\")\n",
    "torchaudio.save(\"sample.wav\", wavs[0], model.autoencoder.sampling_rate)\n",
    "\n",
    "print(\"âœ… Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e14e3-fe6b-43f4-9337-cdbbb536279f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
